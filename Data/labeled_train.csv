,Hiring Company,Job Title,Job Description,Responsibility,Qualification,Skills
2,"Subaru Research and Development, Inc",Data Engineer,"About Subaru Research and Development:Do you care about making social impacts through your job, like eliminating fatal accidents by improving safety driving systems, or reducing carbon emissions by developing new BEVs?Do your personal interests relate to road trips, going outdoors, off-road driving, hands-on work on cars, or rally and racing? If your answer is yes, then this job is right for you!
Subaru R&D is an innovation partner of SUBARU Corporation in Japan, and our mission is to serve as a R&D hub of the SUBARU Group. We strive to create products that ignite the hearts of our customers in North America market. We lead and support Subaru's next generation vehicle development by researching, prototyping, testing, and analyzing.
General Position Summary:Develops and directs software system tests, programming, and documentation. Analyzes North American customer data and technical trends to determine user demands and set target performance goals for future products, and coordinates testing with Japan counterparts.Develops, research, designs, implements, tests, and evaluates software and systems, in conjunction with vehicle hardware development, to enable vehicle compute units to perform their applications.Analyzes software requirements to determine feasibility of design within time and cost constraints.Consults with other vehicle development engineers and engineering staff to evaluate interfacing, operational, and performance requirements of overall systems mainly in cockpit.Formulates and designs software systems, using scientific analysis to measure outcomes of designs.
Responsibilities:Develop internal software solutions for data analysis, data ingestion, or web applications using Google Cloud Platform, Amazon Web Service, or Microsoft Azure.Enable back-end services across the Subaru vehicle connected system.Leverage both public and private cloud environments to ensure a robust and scalable infrastructure.Construct and adapt data models to support analysis work.Design unit and integration tests.Write technical reports and give feedback to Subaru Corporation in Japan by writings, emails, and presentations.Support the maintenance of internal web applications.Construct software tools and internal packages to scale data analysis work for other team members.Plan, conduct and evaluate the Proof of Concept (PoC) stage in developing Subaru's next generation infotainment system, cockpit system including meters, displays, buttons, etc.Plan, propose solutions, test the potential solutions, and evaluate the testing data, regarding how interface between software and vehicle hardware can be improved for big data analysis purposes.Collect data from prototype system, clean/prepare the data, analyze the data, and draw conclusions on the testing results.Collaborate with other technical experts including product managers, UI/UX designers, marketing experts, and other business stakeholders.
Qualifications:1-2 years previous automotive engineering experience including internship.Bachelor‚Äôs degree in mechanical engineering, electrical engineering, computer science, software engineering, or equivalent, or equivalent combination of education and experience.Knowledge and experience of big data analysis or statistical data processing is a plus.Knowledge and experience in Python, C++, or JAVA is a plus.Knowledge and/or certificate around AWS, GCP, or Azure is mandatory.Proof of relevant work via internships or an active Github page in lieu of professional experience is accepted.Communication skills across cultural and language barriers.
Compensation and Benefit:Individual base salary is determined by factors such as job-related skills, experience, and relevant education or training. In addition to competitive salary, Subaru offers an amazing benefits package that includes:Medical, Dental, Vision Plans Medical, Dental, Vision plans available on your first dayPension and 401K Match Offerings12 Vacation days for the first year. (The amount increases with the length of service.)14 Company Holidays, 3 Floating Holidays, and 5 Sick daysEducation Assistance Program/ Gym Membership AssistanceVehicle Discount Program/ Vehicle Lease Program
Equal Opportunity:Subaru R&D is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or expression, pregnancy, age, national origin, disability status, genetic information, protected veteran status, or any other characteristic protected by law.","Develop internal software solutions for data analysis, data ingestion, or web applications using Google Cloud Platform, Amazon Web Service, or Microsoft Azure. Enable back-end services across the Subaru vehicle connected system. Leverage both public and private cloud environments to ensure a robust and scalable infrastructure. Construct and adapt data models to support analysis work. Design unit and integration tests. Write technical reports and give feedback to Subaru Corporation in Japan by writings, emails, and presentations. Support the maintenance of internal web applications. Construct software tools and internal packages to scale data analysis work for other team members. Plan, conduct and evaluate the Proof of Concept (PoC) stage in developing Subaru's next generation infotainment system, cockpit system including meters, displays, buttons, etc. Plan, propose solutions, test the potential solutions, and evaluate the testing data, regarding how interface between software and vehicle hardware can be improved for big data analysis purposes. Collect data from prototype system, clean/prepare the data, analyze the data, and draw conclusions on the testing results. Collaborate with other technical experts including product managers, UI/UX designers, marketing experts, and other business stakeholders.","1-2 years previous automotive engineering experience including internship.Bachelor‚Äôs degree in mechanical engineering, electrical engineering, computer science, software engineering, or equivalent, or equivalent combination of education and experience.Knowledge and experience of big data analysis or statistical data processing is a plus.Knowledge and experience in Python, C++, or JAVA is a plus.Knowledge and/or certificate around AWS, GCP, or Azure is mandatory.Proof of relevant work via internships or an active Github page in lieu of professional experience is accepted.Communication skills across cultural and language barriers.","{' Python': 'MISC', ' C++': 'MISC', ' JAVA': 'MISC', ' AWS': 'MISC', ' GCP': 'MISC', ' Azure': 'MISC'}"
3,Sovrinti,Data Engineer,"Company Overview Sovrinti is a full-service energy storage system supplier and integrator. Using our core strengths of expert service to our customers, unparalleled safety, and excellence in manufacturing, we bring standardized, fully integrated energy storage systems to a rapidly growing worldwide market. Our systems address our customers' needs to reduce capital equipment and installation costs while enhancing system level performance and reliability using automated monitoring systems and analytics across the battery, power conditioning and auxiliary systems. Our AEROS¬Æ energy operating system is the engine of innovation to provide advanced control functions allowing our customers to maximize the value of their energy storage assets. Our service capabilities include advanced monitoring and analytics, scheduled maintenance, augmentation, and auxiliary system upgrades. The combination of excellence in battery technology and production coupled with nearly two decades of energy storage integration makes Sovrinti a leading supplier and integrator in the power and energy markets.Sovrinti empowers and expects its team members to assume responsibility and make good decisions, while maintaining a team environment that fosters collaboration and innovation. Our diverse and growing team enjoys competitive salaries, generous benefits, including 100% employer sponsored medical, dental and vision insurance, and flexible working hours.


Position Overview  Sovrinti is looking for an experienced software engineer at our Westborough, MA head office. We are looking for a candidate, who is a self-starter and brings an entrepreneurial spirit, to join the Data Science and Data Analysis (DSDA) team and contribute to the software products used to solve complex issues and enhance system performance in the Battery Energy Storage System (BESS) industry that is seeing exponential growth. This software engineer will be part of a growing team, which offers plenty of opportunities to work on different technologies to achieve business success.   Primary Responsibilities Be part of the Climate tech revolution and help solve the most complex problems through software engineering. Work closely with cross-functional and diverse teams throughout the software product life cycle to gather requirements, implement new features, fix bugs, participate in quality assurance, and update stakeholders. Design, develop, test, and deploy cloud-based software products used in the energy storage industry. Work in an Agile software development environment Work with customers to train them on product features. Strong documentation skills and communication skills.  Key Knowledge, Skills and Abilities Expert in Python-based software development. Strong proficiency with data manipulation libraries like Pandas, Numpy, Matplotlib, Plotly Proficiency with RESTful APIs. Experience working with services on the cloud platforms (AWS/Azure/Databricks/Snowflake/GCP) and containers (Docker/Kubernetes). Experience with working, debugging, and deploying software on Linux and Windows platforms. Familiarity with CI/CD Pipelines. User-level experience with Jira and version control (git or equivalent). Familiarity with microservices infrastructure on the cloud Good understanding of data science (AI/ML) algorithms and statistical algorithms. Experience with SQL and/or Timeseries databases.  Education and Experience  B.S in Math/Physics/Engineering/Computer Science with software development experience Minimum of 2 years of rich industry experience in developing production-level software. Experience architecting software for modularity, and optimization for memory and run-time. Good understanding of object-oriented programming paradigms.Featured benefitsMedical insuranceVision insuranceDental insurance401(k)Paid maternity leavePaid paternity leaveDisability insurance","Be part of the Climate tech revolution and help solve the most complex problems through software engineering. Work closely with cross-functional and diverse teams throughout the software product life cycle to gather requirements, implement new features, fix bugs, participate in quality assurance, and update stakeholders. Design, develop, test, and deploy cloud-based software products used in the energy storage industry. Work in an Agile software development environment Work with customers to train them on product features. Strong documentation skills and communication skills.","Key Knowledge, Skills and Abilities Expert in Python-based software development. Strong proficiency with data manipulation libraries like Pandas, Numpy, Matplotlib, Plotly Proficiency with RESTful APIs. Experience working with services on the cloud platforms (AWS/Azure/Databricks/Snowflake/GCP) and containers (Docker/Kubernetes). Experience with working, debugging, and deploying software on Linux and Windows platforms. Familiarity with CI/CD Pipelines. User-level experience with Jira and version control (git or equivalent). Familiarity with microservices infrastructure on the cloud Good understanding of data science (AI/ML) algorithms and statistical algorithms. Experience with SQL and/or Timeseries databases.  Education and Experience  B.S in Math/Physics/Engineering/Computer Science with software development experience Minimum of 2 years of rich industry experience in developing production-level software. Experience architecting software for modularity, and optimization for memory and run-time. Good understanding of object-oriented programming paradigms.","{' Python-based': 'MISC', ' Pandas': 'MISC', ' Linux': 'MISC', ' Windows': 'MISC', 'AI': 'MISC', 'ML': 'MISC', ' SQL': 'MISC'}"
4,MDI Imaging & Mail,Data Analyst,"Company DescriptionMDI Imaging & Mail is a full-service direct mail production firm that specializes in 4-color printing, comprehensive data processing, high-speed laser/inkjet personalization, and a wide range of domestic and international mailing services. As a one-stop-shop, we partner with our clients from the creative inception of their mailings to the final delivery to the postal service. We differentiate ourselves in the industry by specializing in expedited and dimensional mail, while also offering traditional direct mail formats to meet all mailing needs.
Role DescriptionWe are seeking a Data Processor to join our team in Cascades, VA. This is a full-time on-site role. As a Data Processor, you will be responsible for processing and organizing large volumes of data for direct mail campaigns. You will collaborate with cross-functional teams to ensure the accuracy and completeness of data, and work closely with our production team to meet project deadlines and quality standards.
Responsibilities:Utilize InDesign, XMPie, and other software to process and prepare high-quality direct mail documents.Manipulate and maintain mailing lists, ensuring accuracy, currency, and proper formatting.Efficiently manage postal presorting in compliance with USPS regulations to optimize cost-effectiveness and delivery.Collaborate with account teams to deliver client-ready documents, meeting all specifications and quality standards.Diagnose and resolve technical challenges, ensuring timely completion of campaigns within budget constraints.Continuously update knowledge of direct mail production trends and technologies to enhance workflow and output quality.Requirements:1 year of experience in direct mail processing, especially with postal presorting, preferredProficiency in Adobe InDesign and the Adobe Creative Suite, with a strong portfolio showcasing skills in creating data-driven documents.Knowledge of postal presorting software and USPS regulations preferred; prior experience is a significant plus.Eagerness to engage in a data-centric working environment and learn new technologies.Outstanding attention to detail and organizational skills, with the ability to manage multiple projects simultaneously.Excellent communication skills and comfort working within a collaborative team structure.Adaptability and enthusiasm for working in a fast-paced environment, meeting tight deadlines.","Utilize InDesign, XMPie, and other software to process and prepare high-quality direct mail documents. Manipulate and maintain mailing lists, ensuring accuracy, currency, and proper formatting. Efficiently manage postal presorting in compliance with USPS regulations to optimize cost-effectiveness and delivery. Collaborate with account teams to deliver client-ready documents, meeting all specifications and quality standards. Diagnose and resolve technical challenges, ensuring timely completion of campaigns within budget constraints. Continuously update knowledge of direct mail production trends and technologies to enhance workflow and output quality.","1 year of experience in direct mail processing, especially with postal presorting, preferred Proficiency in Adobe InDesign and the Adobe Creative Suite, with a strong portfolio showcasing skills in creating data-driven documents. Knowledge of postal presorting software and USPS regulations preferred; prior experience is a significant plus. Eagerness to engage in a data-centric working environment and learn new technologies. Outstanding attention to detail and organizational skills, with the ability to manage multiple projects simultaneously. Excellent communication skills and comfort working within a collaborative team structure. Adaptability and enthusiasm for working in a fast-paced environment, meeting tight deadlines.","{' Adobe InDesign': 'MISC', ' Adobe Creative Suite': 'MISC'}"
6,"Econtenti, Inc",Data Engineer,"Company DescriptionEcontenti, Inc is a leading provider of technology, business consulting, and cloud computing services. Specializing in developing applications on the Force.com platform, Econtenti serves businesses globally from its state-of-the-art development center.
Role DescriptionThis is a full-time on-site role for an Azure Data Engineer located in Seattle, WA. The Azure Data Engineer will be responsible for day-to-day tasks related to data engineering, data modeling, ETL (Extract Transform Load), data warehousing, and data analytics. We are not open to C2C, we are open to candidates who are looking for H1BT and been laid off. 
QualificationsData Engineering, Data Modeling, and ETL (Extract Transform Load) skillsMonitor and support data pipelines and ETL workflowsData Warehousing and Data Analytics skillsExperience with Azure cloud services and toolsStrong problem-solving and analytical skillsProficiency in SQL and other programming languagesExperience with data integration and data migrationExcellent communication and collaboration skillsBachelor's degree in Computer Science, Engineering, or related field
Enterprise Required SkillsPython, Big data, Data warehouse, ETL, Development, azure, Azure Data Factory, Azure Databricks, Azure SQL Server, Snowflake, data pipelines
Top Skills Details1. 3+ years with ETL Development with Azure stack (Azure Data Factory, Azure Databricks, Azure Blob, Azure SQL).  2. 3+ years with Spark, SQL, and Python. This will show up with working with large sets of data in an enterprise environment.  3. Looking for Proactive individuals who have completed projects from start to completion and have an ability to work independently and once ramped up, require minimal handholding.","This is a full-time on-site role for an Azure Data Engineer located in Seattle, WA. The Azure Data Engineer will be responsible for day-to-day tasks related to data engineering, data modeling, ETL (Extract Transform Load), data warehousing, and data analytics.","1. 3+ years with ETL Development with Azure stack (Azure Data Factory, Azure Databricks, Azure Blob, Azure SQL).  2. 3+ years with Spark, SQL, and Python. This will show up with working with large sets of data in an enterprise environment.  3. Looking for Proactive individuals who have completed projects from start to completion and have an ability to work independently and once ramped up, require minimal handholding.","{' Azure': 'MISC', ' Azure SQL': 'MISC', ' Spark': 'MISC', ' SQL': 'MISC', ' Python': 'MISC'}"
7,MCubeSoft,Data Analyst,"Job Title: BUSINESS DATA ANALYST Location: Austin, TX, or Charlotte, NC - (Hybrid 3 days onsite) 
 W2 POSITION
  Technical‚ÄØskills‚ÄØrequirements: ‚Ä¢ Business Data Analysis with Wealth Management experience (10+ years). ‚Ä¢ Strong in AWS and SQL queries and Python. 
Wealth Management Domain knowledge required: ‚Ä¢ Prime broker-dealer business, alternative investments, retirement funds, portfolio management ‚Ä¢ Experience working with ledger book tools like Beta, and Fund Master would be a plus. ‚Ä¢ Trade placing and execution on behalf of clients. Tools like Client worksheet balance, which advisors use to execute trades on behalf of the clients ‚Ä¢ Client portfolio construction, Client portfolio rebalancing as per market conditions, etc.",NaN,"Business Data Analysis with Wealth Management experience (10+ years). ‚ strong in AWS and SQL queries and Python. Wealth Management Domain knowledge required: ‚ Prime broker-dealer business, alternative investments, retirement funds, portfolio management ‚ Experience working with ledger book tools like Beta, and Fund Master would be a plus. ‚ Trade placing and execution on behalf of clients. Tools like Client worksheet balance, which advisors use to execute trades on behalf of the clients ‚Client portfolio construction, Client portfolio rebalancing as per market conditions, etc.","{' AWS': 'MISC', ' SQL': 'MISC', ' Python': 'MISC'}"
9,Armstrong World Industries,Data Scientist,"Primary location: Remote, Remote

Relocation offered: No

Employment status: Full-Time

Travel: <10%

Non-compete: No

Location: Work from home position located in Remote, Remote

The estimated base salary range for this role is $97,060 to $145,580 per year.

Individual pay is based upon location, skills and expertise, experience and other relevant factors (salary may be adjusted based on geographic location)

 What does it mean to work at Armstrong?

It means being immersed in a supportive culture that recognizes you as a key player in Armstrong's future. We are a large company with a local feel, where you will get to know and collaborate with leadership and your colleagues across the company.

By joining us, you'll have the opportunity to make the most of your potential. Alongside a competitive remuneration package, you will receive:

A benefits package including: medical, dental, prescription drug, life insurance, 401k match, long-term disability coverage, vacation and sick time, product discount programs and many more.Personal development to grow your career with us based on your strengths and interests.A working culture that balances individual achievement with teamwork and collaboration. We draw on each other's strengths and allow for different work styles to build engagement and satisfaction to deliver results. 


As a Data Scientist, you will leverage cutting-edge generative AI techniques to extract structured data from diverse document types. From there, you will build models that understand context, domain-specific jargon and generate documents. The output of your work will enable long-term strategic advantages for the company.

Essential Duties and Responsibilities include the following. Other duties may be assigned.

Building AI/ML features to evaluate document quality, account loyalty, market trends, etc.Constructing supervised learning datasetsWriting robust and testable codeDefining and overseeing regular updates to improve precision as the company‚Äôs challenges and data evolveCultivating strong collaborations with teammates and stakeholdersSharing technical solutions and product ideas with the team through design/code reviews and weekly meetings


Qualifications

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Experience transforming natural language data into useful features using NLP techniques to feed classification algorithmsAbility to work with dashboarding and visualization software such as Tableau or Power BIKnowledge of software versioning control repositories such as GitHubAbility to translate data insights into actionable items and communicate findings in a simplistic wayExperience with generative AI would be a plus Enthusiasm for learning new things and going deep into detailed data analysisWorkflow flexibility, team player, and strong collaboration skills


Education And/or Experience

BS in Computer Science, Statistics or Applied Mathematics or equivalent years of experience2+ years in software development, statistical modeling, and machine learning2+ years of experience in an analytical field using tools such as Python, R, SAS, MatlabFamiliarity with SQL or other querying languages is preferred


Why should you join Armstrong World Industries?

Armstrong World Industries (AWI) is a leader in the design and manufacture of innovative commercial and residential ceiling, wall and suspension system solutions in the Americas. With approximately $1B in revenue, AWI has about 2,800 employees and a manufacturing network of fifteen facilities in North America.

At home, at work, in healthcare facilities, classrooms, stores, or restaurants, we offer interior solutions that help to enhance comfort, save time, improve building efficiency and overall performance, and create beautiful spaces.

For more than 150 years, we have built our business on trust and integrity. It set us apart then, and it sets us apart now, along with our ability to collaborate with and innovate for the people we're here to serve - our customers, our shareholders, our communities and our employees.

We are committed to developing new and sustainable ceiling solutions, with design and performance possibilities that make a positive difference in spaces where we live, work, learn, heal and play. It's an exciting, rewarding business to be in, and we're committed to continue to grow and prosper for the benefit of all of our stakeholders. We hope you join us.

Our Sustainability Ambition

""Bringing our Purpose to Life"" - lead a transformation in the design and building of spaces fit for today and tomorrow.

We are committed to:

Engaging a diverse, purpose-driven workforce;Transforming buildings from structures that shelter into structures that serve and preserve the health and well-being of people and planet;Pursuing sustainable, innovative solutions for spaces where we live, work, learn heal and play;Being a catalyst for change with all of our stakeholders; andMaking a positive difference in the environments and communities we impact.


Armstrong is committed to engaging a diverse, purpose-driven workforce. As part of our dedication to diversity, AWI is committed to Equal Employment Opportunity and all qualified applicants receive consideration for employment without regard for race, sex, color, national origin, ethnicity, gender, protected veteran status, disability, sexual orientation, gender identity, or religion. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at by email at AWI talent acquisition and let us know the nature of your request and your contact information. Requests for accommodation will be evaluated on a case-by-case basis. Please note that only inquiries concerning a request for reasonable accommodation will be responded to from this email address.

Come and build your future with us and apply today!","Building AI/ML features to evaluate document quality, account loyalty, market trends, etc. Constructing supervised learning datasets. Writing robust and testable code. Defining and overseeing regular updates to improve precision as the company‚ challenges and data evolve. Cultivating strong collaborations with teammates and stakeholders. Sharing technical solutions and product ideas with the team through design/code reviews and weekly meetings","Experience transforming natural language data into useful features using NLP techniques to feed classification algorithms Ability to work with dashboarding and visualization software such as Tableau or Power BI Knowledge of software versioning control repositories such as GitHubAbility to translate data insights into actionable items and communicate findings in a simplistic way Experience with generative AI would be a plus Enthusiasm for learning new things and going deep into detailed data analysis Workflow flexibility, team player, and strong collaboration skills.BS in Computer Science, Statistics or Applied Mathematics or equivalent years of experience 2+ years in software development, statistical modeling, and machine learning 2+ years of experience in an analytical field using tools such as Python, R, SAS, Matlab. Familiarity with SQL or other querying languages is preferred.","{' GitHub': 'ORG', ' Python': 'MISC', ' R': 'MISC', ' SAS': 'MISC', ' Matlab': 'MISC', ' SQL': 'MISC'}"
12,CBRE,Data Analyst,"About the Role:

As a CBRE Legal Data Analyst, you will perform basic analysis to ensure that recommendations and business conclusions are backed by thorough data research and findings.

This job is part of Legal Support. They are responsible for performing and supporting a variety of law-related activities that does not require a law degree. 

What You‚Äôll Do:

 * Coordinate data aggregation and curate reports using existing business intelligence and reporting applications.
 * Perform ad-hoc, strategic review of structured and unstructured data, reflecting global real estate markets and the operations of real estate assets. 
 * Assist with developing data structures and pipelines to organize, collect, cleanse, and standardize information to generate insights.
 * Define basic data requirements and gather information using judgment and statistical tests. 
 * Use programming and evaluation tools, including open-source programs to plan models and extract insights. 
 * Apply modeling and optimization methods to improve business performance. 
 * Develop ad-hoc reporting based on the review of existing data sources using programs, such as Power BI. 
 * Exhibit rigor, judgment, and ability to present a detailed 'data story' to a business line. 
 * Confirm the quality and integrity of existing data sources.
 * Collaborate with the agile development team to provide recommendations and communications on enhancing existing or new processes and programs.
 * Have some knowledge of standard principles with limited practical experience in applying them.
 * Lead by example and model behaviors that are consistent with CBRE RISE values. 
 * Impact the quality of own work.
 * Work within standardized procedures and practices to achieve objectives and meet deadlines.
 * Exchange straightforward information, ask questions, and check for understanding.","Coordinate data aggregation and curate reports using existing business intelligence and reporting applications. Perform ad-hoc, strategic review of structured and unstructured data, reflecting global real estate markets and the operations of real estate assets. Assist with developing data structures and pipelines to organize, collect, cleanse, and standardize information to generate insights. Define basic data requirements and gather information using judgment and statistical tests. Use programming and evaluation tools, including open-source programs to plan models and extract insights. Apply modeling and optimization methods to improve business performance. Develop ad-hoc reporting based on the review of existing data sources using programs, such as Power BI. Exhibit rigor, judgment, and ability to present a detailed 'data story' to a business line. Confirm the quality and integrity of existing data sources. Collaborate with the agile development team to provide recommendations and communications on enhancing existing or new processes and programs. Have some knowledge of standard principles with limited practical experience in applying them. Lead by example and model behaviors that are consistent with CBRE RISE values. Impact the quality of own work. Work within standardized procedures and practices to achieve objectives and meet deadlines. Exchange straightforward information, ask questions, and check for understanding.","To qualify for the Legal Data Analyst role at CBRE, candidates should ideally hold a bachelor's degree in data analytics, computer science, statistics, or a related field, with prior experience in data analysis being advantageous. A strong foundation in tools such as Power BI and Excel is essential, along with familiarity in programming or data querying languages like SQL, Python, or R. The role requires knowledge of data structures, cleansing techniques, and standardization processes to ensure the integrity and usability of information.","{' Power BI': 'MISC', ' Excel': 'MISC', ' SQL': 'MISC', ' Python': 'MISC', ' R': 'MISC'}"
14,Hedgehog,Data Engineer,"This is a hard-core coding position. The ideal candidate is an experienced software engineer with deep expertise in networking and hard-core real-time and distributed systems programming. The candidate must think like a packet and communicate in BGP.
Prerequisites:7+ years of relevant hardcore dataplane and Linux networking experience.. We don't care what degree you have; what matters is what you've done and what you can do.Languages, frameworks, platforms, and tools:Experience in programming in at least one of the following languages: C, C++, Rust, or Go.Working knowledge and experience with Linux networkingExperience with high-performance dataplanes VPP, eBPF, DPDK, or VPP.Experience with overlay technologies like VxLAN, Geneve, ...Experience with XDPExperience with dataplane acceleration/offload/execution at smartNIC/IPU/DPU. Specifically, NVIDIA Bluefield, Pensando/AMD, Intel, Marvell DPUs/IPUsWorking knowledge of data-plane debug, troubleshooting and testing tools.Network test tools experience requirements (1 or more of the below):Use Keysight, IXIA, Spirent, and other traffic generators to characterize the scale and performance.Experience with SFLOW, NETFLOW tools, and other network monitoring tools.Strong skills in packet decoding, reading pcap files, and analyzing sniffer traces.Network technology experience requirements (a huge plus):Familiarity with open routing stacks, s.a. FRR (previously Quagga, Zebra), Bird, KubeRouter, ExaBGP, FreeRouter, XORP ...Familiarity amd hands-on experience with routing protocols, s.a. BGP, OSPF, ISIS, RIP, ‚Ä¶ is a huge plus.Hands-on experience and familiarity with BGP-based underlays.Hands-on experience and familiarity with BGP EVPNHands-on experience with P4, OpenFlow, OpenConfigFamiliarity with IPTables, OVS, ‚Ä¶Familiarity with CNIs like Calico, OVN, Multus, CilliumCloud(-native) networking technology experience (a huge plus):Hands-on familiarity with Kubernetes networking (Calico, Cilium, etc. CNIs)Hands-on familiarity with Service Mesh and API GatewaysHands-on familiarity with OpenStack networking (ML2, Neutron)Hands-on experience with Wireguard, MetalLB, Traefik, Envoy, etc.Other requirements:Proven experience with cloud, data center, or edge networking productsProven experience with debugging customer issues and locally recreating them in the labStrong solution-level exposure to enterprise deploymentsExperience qualifying high-volume, scalable enterprise software","The primary responsibilities for this role include designing, developing, and implementing high-performance network solutions, troubleshooting and resolving complex network issues, and ensuring that the solutions meet scalability and performance standards. The candidate will be responsible for testing and characterizing network systems using traffic generators and monitoring tools, supporting enterprise deployments, and working closely with customers to debug and recreate issues in lab environments. Additionally, they will ensure that software solutions are thoroughly qualified for high-volume, scalable enterprise environments and provide ongoing support to ensure the reliability and performance of deployed systems.","The ideal candidate for this position should have at least 7 years of extensive experience in dataplane and Linux networking, with proficiency in programming languages such as C, C++, Rust, or Go. They should possess hands-on experience with high-performance dataplanes like VPP, eBPF, and DPDK, and be familiar with overlay technologies such as VxLAN and Geneve, as well as XDP and dataplane acceleration technologies, including NVIDIA Bluefield, Pensando/AMD, Intel, and Marvell DPUs/IPUs. The candidate must be skilled in using network test tools like Keysight, IXIA, and Spirent, and have a strong understanding of packet decoding, analyzing sniffer traces, and network monitoring tools such as SFLOW and NETFLOW. A solid understanding of open routing stacks (e.g., FRR, Bird) and routing protocols like BGP, OSPF, ISIS, and RIP is essential, along with hands-on experience with BGP-based underlays, BGP EVPN, and P4/OpenFlow. Familiarity with CNIs like Calico, OVN, and Cillium, as well as cloud-native networking technologies (e.g., Kubernetes networking, Service Mesh, OpenStack networking), is highly desirable. The candidate should also have experience with enterprise-level deployments and debugging, as well as a proven ability to qualify scalable, high-volume software solutions.","{' Linux': 'MISC', ' C': 'MISC', ' C++': 'MISC', ' Rust': 'MISC', ' Go': 'MISC'}"
16,Data Glacier,Data Scientist,"Unpaid internship hence no compensation or stipendTitle : Data Science InternResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experienceProficient in SQL, Python/R, Data Wrangling, Data Visualization( seaborn, matplotlib, etc)Everything will be done virtuallyThe person may do some productive tasks as part of their learning experience, training, or skill development. But this work will not be claimed by Data Glacier and DG will not utilize this work for their benefit.Data Glacier does not require any time commitment. It is up to interns how much time they give to learn and complete the task.Intern can utilize the code and application developed during the internship for their branding and HR networking.Unpaid internship hence no compensation or stipendPlease write to us if you have any further questions.https://www.dataglacier.org/virtual-internshipEmployment TypeInternshipCompensationNo","Understand the day-to-day issues that our business faces, which can be better understood with data. Compile and analyze data related to business issues Develop clear visualizations to convey complicated data in a straightforward fashion.","Bachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience. Proficient in SQL, Python/R, Data Wrangling, Data Visualization(seaborn, matplotlib, etc)",{' Python/R': 'MISC'}
17,Heartland,Data Engineer,"Every day, Heartland, a Global Payments Company, makes it possible for millions of people to move money between buyers and sellers using our products and unmatched services. Simply, we create meaningful technology centered experiences that enable our customers to prosper. If you want to work like an entrepreneur, support and serve entrepreneurs and bring your expertise to a dynamic team, then Heartland is for you. If it's in your nature to work with a passion to provide tangible solutions for everyone you interact with, then join us and let's see what we can do together.

The Data Base Administrator (DBA) will be responsible for the development, performance, integrity, availability, and security of several of our database systems across multiple products.

Responsibilities:

Database Management:

Monitor database performance, conduct regular performance tuning, and optimize queries for maximum efficiency. Install, configure, and upgrade database software and related tools. Develop and implement database backup and recovery strategies to ensure data reliability and minimize downtime. Perform routine maintenance tasks, such as database backups, index rebuilding, and statistics gathering. Manage and optimize databases to ensure the availability and reliability of critical organizational and future ETL processes to ensure optimization and best practices. DML/DDL Script Review and execution, including authoring/editing when necessaryMicrosoft EntraID provisioning within Azure SQL DatabasePatching/Servicing of Self-Managed (IaaS) database services, including underlying Host OS updates/patchesCoordination/Execution of PaaS/DBaaS upgrades/configuration changes with various product teamsBackup/Recovery configuration for IaaS/PaaS/DBaaS solutions to adhere to data recovery policy

Performance Optimization and Troubleshooting:

Performance TuningIdentify and resolve database performance issues like slow queries, inefficient indexing, or resource contentionConduct database capacity planning to anticipate future storage and performance needsImplement and maintain database monitoring tools to proactively identify and resolve issuesParticipate in product triage / outage events

Documentation and Reporting:

Interpretation of KPIs for PaaS databases, report findings to product teamsGenerate regular reports on database performance, usage, and security compliance for management and stakeholders

Required Qualifications:

Bachelor‚Äôs degree in computer science, Information Technology, or a related fieldMinimum of 3 to 5 years of proven work experience as a Database AdministratorStrong knowledge of multiple databases, such as:Azure SQL DatabaseSQL Server 2019/SSRS 2019SQL Server (AWS RDS)MySQL (AWS RDS/Aurora, Azure MySQL)PostgreSQL (AWS RDS, Azure PostgreSQL)MongoDB (Mongo Atlas)CosmosDBAzure Data Factory Proficiency in writing complex SQL queries and optimizing database performance. Knowledge of Cloud Infrastructure. 

The position listed in this requisition is ineligible for the new hire referral bonus award program. However, it is eligible for the NA Merchant Tech Refer to Win bonus award program.

Heartland is an equal opportunity employer. Heartland, a Global Payments Company, provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, marital status, sexual orientation, gender identity or expression, disability, veteran status, genetic information or any other basis protected by law. Those applicants requiring reasonable accommodation to the application and/or interview process should notify a representative of the Human Resources Department.","The role involves managing and optimizing databases by monitoring performance, conducting regular tuning, and optimizing queries for efficiency. Responsibilities include installing, configuring, and upgrading database software, implementing backup and recovery strategies, performing routine maintenance tasks, and ensuring the reliability and availability of critical organizational and future ETL processes. The candidate will review and execute DML/DDL scripts, manage Microsoft EntraID provisioning within Azure SQL Database, and handle patching and servicing of self-managed (IaaS) database services, including OS updates. They will coordinate PaaS/DBaaS upgrades and configure backup/recovery solutions to adhere to data recovery policies. In addition, they will conduct performance optimization, troubleshoot database issues, plan for future storage and performance needs, implement monitoring tools, and participate in product triage/outage events. Regular reporting on database performance, usage, and security compliance will also be required, with findings shared with product teams and stakeholders.","Bachelor degree in computer science, Information Technology, or a related field. Minimum of 3 to 5 years of proven work experience as a Database Administrator. Strong knowledge of multiple databases, such as: Azure SQL Database SQL Server 2019/SSRS 2019SQL Server (AWS RDS)MySQL (AWS RDS/Aurora, Azure MySQL)PostgreSQL (AWS RDS, Azure PostgreSQL)MongoDB (Mongo Atlas)Cosmos DBAzure Data Factory Proficiency in writing complex SQL queries and optimizing database performance. Knowledge of Cloud Infrastructure.","{' Azure SQL Database SQL Server 2019/SSRS 2019SQL Server': 'MISC', 'MySQL': 'MISC', 'PostgreSQL': 'MISC', 'MongoDB': 'MISC', ' SQL': 'MISC'}"
19,Piper Companies,Data Engineer,"Piper Companies is seeking a Data Engineer to cluster large datasets across various container and data platforms depending on external client needs. The Data Engineer will work hands-on with challenging data engineering, data management, and analytics projects.

Responsibilities of the Data Engineer include:

 Achieve and maintain proficiency with cluster and framework sizing, installation, debugging, performance optimization, migration, security and automation Collaborate with data scientists, analysts, business users, and IT teams to design, implement, and deploy data services and analytics. Use Continuous Integration/Continuous Delivery (CI/CD) concepts to engineer a standardized data environment Recommend and advise on optimal data models for data ingestion, integration, and visualization Integrate data from a variety of data source types

Qualifications for the Data Engineer include: 

 6 years of experience in data engineering Experience with Snowflake, Databricks, Spark SQL, PySpark, and Python 3+ years cloud experience: Azure, AWS, or GCP

Compensation for the Data Engineer include:

 Salary: $135,000-145,000 Benefits: Full Health/Dental/Vision, 401K, Pension, Annual Bonus","Achieve and maintain proficiency with cluster and framework sizing, installation, debugging, performance optimization, migration, security and automation Collaborate with data scientists, analysts, business users, and IT teams to design, implement, and deploy data services and analytics. Use Continuous Integration/Continuous Delivery (CI/CD) concepts to engineer a standardized data environment Recommend and advise on optimal data models for data ingestion, integration, and visualization Integrate data from a variety of data source types","6 years of experience in data engineering Experience with Snowflake, Databricks, Spark SQL, PySpark, and Python 3+ years cloud experience: Azure, AWS, or GCP","{' Databricks': 'MISC', ' Spark SQL': 'MISC', ' PySpark': 'MISC', ' Python': 'MISC', ' AWS': 'MISC'}"
20,Centene Corporation,Data Analyst,"You could be the one who changes everything for our 28 million members. Centene is transforming the health of our communities, one person at a time. As a diversified, national organization, you‚Äôll have access to competitive benefits including a fresh perspective on workplace flexibility.

Position Purpose Responsible for the effective and successful management of capacity, productivity, quality control, and system functionality. Responsible for the creation and ongoing enhancements to the operational procedures, systems, and principles in the areas of information flow & data management, business processes, enhanced executive & stakeholder reporting, and identifying opportunities to expand systems.

Manage day to day requirements for full-time and Vendor staff including hiring, oversee new hire training, performance management, departmental budget, and career development to ensure alignment with company goals.Develop operational systems by determining testing/reconciliation needs and system requirements; develop, implement, enforce, and evaluate policies and procedures; develop and create documented processes for testing utilization, test plan management, and managing escalations; trend production issues for continuous improvement effortsInteract with Product Management, Information Technology and Enrollment, Membership and Billing Teams for user acceptable testing, release readiness and/or reconciliation efforts.Lead highly technical teams to investigate and resolve complex data issues in the test and/or production environment to determine downstream impacts. Operate at a subject matter expert level to support the needs of the business and the team.This position must be self-sufficient in making decisions and changes for their teams that are in alignment with UAT/reconciliation goals. Able to evaluate, troubleshoot, and implement department wide decisions without having a documented process to follow.

Education/Experience Bachelor‚Äôs degree in related field or equivalent experience. 4+ years of User Acceptance Testing or Data Reconciliation (i.e., documenting business process, test plan creation, requirement analysis, external/internal reconciliation) experience in healthcare industry or 3+ years of managed care IT experience. Advanced knowledge of Microsoft Applications, including Excel, PowerPoint and Visio preferred. Experience with User Acceptance, Quality testing or Data Reconciliation in healthcare, preferably managed care or Medicaid. Knowledge of Amisys or other claims system, qTest or any other agile test case management tool, JIRA and HIPAA transactions preferred. Prior supervisory/management experience preferred.

License/Certification 6 Sigma Certification desirable.

Pay Range $67,400.00 - $121,300.00 per year

Centene offers a comprehensive benefits package including competitive pay, health insurance, 401K and stock purchase plans, tuition reimbursement, paid time off plus holidays, and a flexible approach to work with remote, hybrid, field or office work schedules. Actual pay will be adjusted based on an individual's skills, experience, education, and other job-related factors permitted by law. Total compensation may also include additional forms of incentives.

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.","The responsibilities of this position involve managing the overall effectiveness of systems and operations, ensuring the successful execution of capacity, productivity, quality control, and system functionality. The role requires overseeing both full-time and vendor staff, including tasks like hiring, training, performance management, and career development. It also involves developing operational systems, managing testing/reconciliation needs, creating and enforcing policies, and driving continuous improvement efforts. The position works closely with multiple teams (e.g., Product Management, IT, Enrollment) to ensure proper testing, release readiness, and reconciliation. Additionally, the role requires leading technical teams to resolve complex data issues, supporting business needs, and making decisions aligned with UAT/reconciliation goals, even in the absence of predefined processes.","Bachelor degree in related field or equivalent experience. 4+ years of User Acceptance Testing or Data Reconciliation (i.e., documenting business process, test plan creation, requirement analysis, external/internal reconciliation) experience in healthcare industry or 3+ years of managed care IT experience. Advanced knowledge of Microsoft Applications, including Excel, PowerPoint and Visio preferred. Experience with User Acceptance, Quality testing or Data Reconciliation in healthcare, preferably managed care or Medicaid. Knowledge of Amisys or other claims system, qTest or any other agile test case management tool, JIRA and HIPAA transactions preferred. Prior supervisory/management experience preferred.","{' Microsoft Applications': 'MISC', ' Excel': 'MISC', ' PowerPoint': 'MISC', ' Visio': 'MISC'}"
21,Piper Companies,Data Engineer,"Piper Companies is looking for a Data Engineer for an Investment Firm in Wayne, PA for a Hybrid, Full-Time opportunity.

ÔªøResponsibilities of the Data Engineer:

 Conduct data profiling, source-target mappings, ETL development, SQL tunings and optimization, testing and implementation Provide business and technical analysis for initiatives focusing on Data Warehouse and Business Intelligence solutions Collaborate with Business Intelligence Developers through dashboard and application development process for requirements gathering, feedback on proposed designs and models, and acceptance testing

Qualifications of the Data Engineer:

 10 years‚Äô experience, with both hands-on and lead experience in supporting data warehousing solutions Must possess the following technical skills: ETL Tools: Enterprise class ETL tool (Talend is plus) Databases & Utilities: Experience with enterprise relational databases (Snowflake experience preferred) Platforms: Microsoft / Unix Expertise and fluency in SQL language is required Knowledge of scripting languages and job schedulers is required (Powershell, etc.) Experience with various integration patterns (e.g. Flat Files, Web Services, etc.) is required Knowledge of fundamental data modeling concepts (e.g. ER Diagrams, normalization, etc.) is required Familiarity with Python, Snowflake, Talend, XML/XSLT, and Cloud Services (AWS or Azure) are preferred Excellent troubleshooting and problem-solving skills; able to root cause and debug complex code in and efficient manner/with appropriate urgency Bachelor's degree in computer science, information technology or another computer-based discipline

Compensation for the Data Engineer:

 Salary of $120K - $150K Hybrid Scheduling Comprehensive Benefits Package: Medical, Dental, Vision, 401K, PTO

Keywords:

Data, Data analysis, Engineering, Data Engineering, Data Wrangling, Data Manipulation, Data Automation, SQL, MySQL, SQL Server, RDMS, Relational Databases, Relational Database Management Systems, DBA, Database Management, Schemas, Queries, Query, DA, Extract, Transform, Load, scripting, data reports, data visualization, benefits, medical, dental, vision, 401K, pto, vacation, hybrid","Conduct data profiling, source-target mappings, ETL development, SQL tunings and optimization, testing and implementation Provide business and technical analysis for initiatives focusing on Data Warehouse and Business Intelligence solutions Collaborate with Business Intelligence Developers through dashboard and application development process for requirements gathering, feedback on proposed designs and models, and acceptance testing","10 years experience, with both hands-on and lead experience in supporting data warehousing solutions Must possess the following technical skills: ETL Tools: Enterprise class ETL tool (Talend is plus) Databases & Utilities: Experience with enterprise relational databases (Snowflake experience preferred) Platforms: Microsoft / Unix Expertise and fluency in SQL language is required Knowledge of scripting languages and job schedulers is required (Powershell, etc.) Experience with various integration patterns (e.g. Flat Files, Web Services, etc.) is required Knowledge of fundamental data modeling concepts (e.g. ER Diagrams, normalization, etc.) is required Familiarity with Python, Snowflake, Talend, XML/XSLT, and Cloud Services (AWS or Azure) are preferred Excellent troubleshooting and problem-solving skills; able to root cause and debug complex code in and efficient manner/with appropriate urgency Bachelor's degree in computer science, information technology or another computer-based discipline","{'Talend': 'MISC', ' Microsoft': 'MISC', ' Unix': 'MISC', ' SQL': 'MISC', 'Powershell': 'MISC', ' Python': 'MISC', ' Snowflake': 'MISC', ' Talend': 'MISC', 'AWS': 'MISC'}"
23,JPMorgan Chase & Co.,Data Analyst,"Job Description

The Corporate and Investment Bank (CIB) Data Use Team is a center of excellence in the CIB for the usage and governance on how data is used and shared in the organization and plays a critical role to meet our policies and standards. The team works closely with firm wide in order to define standards which drive consistent data management practices and works with multiple LOBs cross-CIB in order to develop technologies and processes to support data management processes and embed data usage best practices and capabilities.

The team is looking for a candidate to provide strong support for CIB Data Use case management for a growing demand of data to support the organizations advancement for AI/ML and data centered initiatives. Additionally, the person will be responsible for multiple data use transformation initiatives and programs across the CIB and in partnership with firm-wide groups, AI/ML groups and LOBs, including implementation of new strategic developments aligned to our maturing capability and in response to new and ongoing policy and standard requirements.

Job Responsibilities

Own case management duties and operate the governance process across all sub-LOBs and all locations globally for the identification, capture, classification, decisioning and monitoring of data use cases within the CIB.Support the strategic vision of enabling data use while protecting data as an asset to the firm, and help to promote this culture with the business.Facilitate the management of the CIB Data Use Council (‚ÄòDUC‚Äô) and Wholesale Data Use Council (WHDUC) including meeting calendar, material and actions.Create and manage project plans, tasks lists and presentations and coordinate cross-functional teams requirements.Ensure engagement with Legal, Compliance, Privacy, Cyber and Tech Controls to establish appropriate guardrails for data use.Continue to build out the existing inventory of how data is used across the firm and by third parties to promote calibrated and well thought-out decision making.Implement standards and protocols for data use within the CIB; embed a risk based framework for decentralized identification and escalation of cases.Provide partner relationship management, including managing interactions and agendas with senior partner executives, defining and prioritizing key issues, gathering information, accessing partner resources, recommending and implementing actionable solutions.Refine existing processes for data use identification, review and decisioning for efficiency gains.

Required Qualifications, Capabilities, And Skills

4+ years of experience in or related to financial services and financial technology with demonstrated appreciation and aptitude for leading disciplined, complex projects within a business-to-business environment with sophisticated parties.Knowledge and understanding of a broad set of CIB products and processes.Demonstrated ability to interact and work effectively with senior management and other stakeholders to support the goals of the business.Experience navigating and mobilizing resources across a large organization.Effective influencing and persuasion skills with groups not directly working for you; ability to build consensus.Strong verbal, written, presentation and communication skills.Excellent PowerPoint and Excel skillsDesire to create structure for data and drive results and utilization of this structure in order to improve the JPM framework/environment.Attention to detail and ability to work independently.Strong data analysis, data management and problem solving skills. Business analysis and reporting skills are a plus.Strong interpersonal and relationship building skills.Ability to thrive in a changing work environment.Ability to execute tasks under aggressive targets and effectively manage changes in planningDemonstrated interest in emerging technology and ‚ÄúBig Data‚Äù in the financial services industry.

ABOUT US

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world‚Äôs most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. We also make reasonable accommodations for applicants‚Äô and employees‚Äô religious practices and beliefs, as well as mental health or physical disability needs. Visit our FAQs for more information about requesting an accommodation.

JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans

About The Team

The Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world‚Äôs most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.","Own case management duties and operate the governance process across all sub-LOBs and all locations globally for the identification, capture, classification, decisioning and monitoring of data use cases within the CIB. Support the strategic vision of enabling data use while protecting data as an asset to the firm, and help to promote this culture with the business. Facilitate the management of the CIB Data Use Council and Wholesale Data Use Council (WHDUC) including meeting calendar, material and actions. Create and manage project plans, tasks lists and presentations and coordinate cross-functional teams requirements. Ensure engagement with Legal, Compliance, Privacy, Cyber and Tech Controls to establish appropriate guardrails for data use. Continue to build out the existing inventory of how data is used across the firm and by third parties to promote calibrated and well thought-out decision making. Implement standards and protocols for data use within the CIB; embed a risk based framework for decentralized identification and escalation of cases. Provide partner relationship management, including managing interactions and agendas with senior partner executives, defining and prioritizing key issues, gathering information, accessing partner resources, recommending and implementing actionable solutions. Refine existing processes for data use identification, review and decisioning for efficiency gains.","4+ years of experience in or related to financial services and financial technology with demonstrated appreciation and aptitude for leading disciplined, complex projects within a business-to-business environment with sophisticated parties. Knowledge and understanding of a broad set of CIB products and processes. Demonstrated ability to interact and work effectively with senior management and other stakeholders to support the goals of the business. Experience navigating and mobilizing resources across a large organization. Effective influencing and persuasion skills with groups not directly working for you; ability to build consensus. Strong verbal, written, presentation and communication skills. Excellent PowerPoint and Excel skills. Desire to create structure for data and drive results and utilization of this structure in order to improve the JPM framework/environment. Attention to detail and ability to work independently. Strong data analysis, data management and problem-solving skills. Business analysis and reporting skills are a plus. Strong interpersonal and relationship building skills. Ability to thrive in a changing work environment. Ability to execute tasks under aggressive targets and effectively manage changes in planning. Demonstrated interest in emerging technology in the financial services industry.","{' PowerPoint': 'MISC', ' Excel': 'MISC'}"
24,Mainz Brady Group,Data Engineer,"Sr. Data Engineer ‚Äì 3-month Contract ‚Äì Remote, United States ‚Äì W2 ONLY, NO C2C

We are seeking an experienced Data Engineer to join our world leading footwear client. The ideal candidate will have 6-7 years of relevant experience, with a focus on practical application in AWS tech stack. Experience with Databricks, Spark, and Python for coding is essential.

W2 ONLY, NO C2C*


Key Responsibilities:

Establish database management systems and standards.Document and communicate database design.Evaluate and install database systems.Code complex programs and build reports.Assist in UI and prototype design.Participate in quality assurance.Provide expertise in database design and optimization.


Qualifications:

Bachelor‚Äôs degree in Computer Science or related field.6-7 years of data engineering experience.Proficiency in AWS, Databricks, Spark, and Python.Ability to work in complex environments with diverse projects.Strong communication and collaboration skills.


Mainz Brady Group is a technology staffing firm with offices in California, Oregon and Washington. We specialize in Information Technology and Engineering placements on a Contract, Contract-to-hire and Direct Hire basis. Mainz Brady Group is the recipient of multiple annual Excellence Awards from the Techserve Alliance, the leading association for IT and engineering staffing firms in the U.S.

Mainz Brady Group is an Equal Opportunity Employer. We are committed to Diversity & Inclusion and incorporate non-discrimination best practices in all of our staffing processes. Mainz Brady Group does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, gender expression, age, disability or any other protected class.",Establish database management systems and standards. Document and communicate database design. Evaluate and install database systems. Code complex programs and build reports. Assist in UI and prototype design. Participate in quality assurance. Provide expertise in database design and optimization.,"Bachelor degree in Computer Science or related field.6-7 years of data engineering experience. Proficiency in AWS, Databricks, Spark, and Python. Ability to work in complex environments with diverse projects. Strong communication and collaboration skills.",{' Python': 'MISC'}
26,Zocdoc,Data Scientist,"Our Mission

Healthcare should work for patients, but it doesn‚Äôt. In their time of need, they call down outdated insurance directories. Then wait on hold. Then wait weeks for the privilege of a visit. Then wait in a room solely designed for waiting. Then wait for a surprise bill. In any other consumer industry, the companies delivering such a poor customer experience would not survive. But in healthcare, patients lack market power. Which means they are expected to accept the unacceptable.

Zocdoc‚Äôs mission is to give power to the patient. To do that, we‚Äôve built the leading healthcare marketplace that makes it easy to find and book in-person or virtual care in all 50 states, across +200 specialties and +12k insurance plans. By giving patients the ability to see and choose, we give them power. In doing so, we can make healthcare work like every other consumer sector, where businesses compete for customers, not the other way around. In time, this will drive quality up and prices down.

We‚Äôre 15 years old and the leader in our space, but we are still just getting started. If you like solving important, complex problems alongside deeply thoughtful, driven, and collaborative teammates, read on.

Your Impact on our Mission

We are looking for a Principal Data Scientist to join our Search team at Zocdoc to work on our core Search product offerings such as our patient facing Provider Recommendation System. Using a variety of machine learning algorithms, you will build and implement models to create algorithms, run simulations and test your results. We are looking for a statistically-minded individual who has the coding skills to independently work on data and interpret research outcomes to help shape the data science strategy. A close collaboration with business partners (including product, engineering, marketing and sales) will enable you to implement data-driven initiatives.

You‚Äôll enjoy this role if you are‚Ä¶

Passionate about leveraging data science to solve real world problems Passionate about communicating important data insights to business stakeholders stories that tell cohesive, logical stories about the value and uses of Data ScienceA product-driven individual who loves working in a highly collaborative and supportive environmentMotivated by building products that make healthcare easierAn individual who enjoys leading and mentoring data scientists 

Your day to day is‚Ä¶

Working closely with our product team to build and iterate on user-facing features using data analytics and machine learning to optimize the results to drive conversion.Applying advanced statistical techniques to measure efficacy of various products, suggesting improvements to the products and our processes as you see themLeading and mentoring a team of Data Scientists within the Search team, sharing your experience and expertise with others who are eager to learn

You‚Äôll be successful in this role if you have‚Ä¶ 

10+ years of experience performing data analysis and a Master‚Äôs degree/PhD in statistics, math, physical sciences, computer science or other STEM related degreesProven experience on leading and implementing data science initiatives on a product using strong domain knowledge combined with data intuition to understand the most impactful opportunities Ability to mentor other data scientists, increasing both technical data ability and business acumenExpertise working with large, complex SQL and NoSQL database infrastructureSolid understanding of statistics and common machine learning techniquesA strong perspective regarding data engineering and the most appropriate infrastructure to use (including trade-offs)An understanding of the nuances and tradeoffs of different types of experiment designBonus if you have a strong understanding of learning to rank recommendation systems.

Zocdoc is committed to fair and equitable compensation practices. Salary ranges are determined through alignment with market data. Base salary offered is determined by a number of factors including the candidate‚Äôs experience, qualifications, and skills. Certain positions are also eligible for variable pay and/or equity; your recruiter will discuss the full compensation package details.

NYC Base Salary Range

$177,000‚Äî$239,000 USD

About Us

Zocdoc is the country‚Äôs leading digital health marketplace that helps patients easily find and book the care they need. Each month, millions of patients use our free service to find nearby, in-network providers, compare choices based on verified patient reviews, and instantly book in-person or video visits online. Providers participate in Zocdoc‚Äôs Marketplace to reach new patients to grow their practice, fill their last-minute openings, and deliver a better healthcare experience. Founded in 2007 with a mission to give power to the patient, our work each day in pursuit of that mission is guided by our six core values. Zocdoc is a private company backed by some of the world‚Äôs leading investors, and we believe we‚Äôre still only scratching the surface of what we plan to accomplish.

Zocdoc is a mission-driven organization dedicated to building teams as diverse as the patients and providers we aim to serve. In the spirit of one of our core values - Together, Not Alone, we are a company that prides itself on being highly collaborative, and we believe that diverse perspectives, experiences and contributors make our community and our platform better. We‚Äôre an equal opportunity employer committed to providing employees with a work environment free of discrimination and harassment. Applicants are considered for employment regardless of race, color, ethnicity, ancestry, religion, national origin, gender, sex, gender identity, gender expression, sexual orientation, age, citizenship, marital or parental status, disability, veteran status, or any other class protected by applicable laws.

Job Applicant Privacy Notice",Project Manager is responsible for providing the technical knowledge and comprehensive management needed to execute Power Systems sales orders per project specifications in a manner that achieves maximum gross profit while promoting the highest level of customer satisfaction. Seeking candidates with minimum two years of industrial/electrical power generation systems equipment project management experience.,"BAS/BMS communication, Protective relaying, Breaker design and functionality, Modbus/Ethernet communication, Generator paralleling, Diesel engine operating requirements/room design, Fuel and Cooling systems, Emissions regulations and testing, applicable electrical and regulatory codes. Functional competency on all associated software and operating systems, including Word, Excel, EBMS, Sales Force, DBS, Cat PowerNet, SIS-WEB, PSQ, Lotus Notes, EOMP, AutoCAD and Adobe Standard. Excellent verbal and written communication skills. Self-starter able to work with limited supervision. Strong mechanical and electrical aptitude required. Strong leadership skills and a commitment to teamwork. Must be able to multi-task while maintaining organized and detailed. Experience in conflict resolution with contractors, consultants, engineers, vendors, utility companies, end-users, etc. Able to travel and work hours required for job and customer demand. Clean driving record and a valid driver‚Äôs license required. Promote a positive customer experience. Uphold the Core Values of Integrity, Commitment, Excellence and Teamwork by embracing The Carter Way.","{' BAS/BMS': 'MISC', ' Modbus': 'MISC', ' Word': 'MISC', ' Excel': 'MISC', ' EBMS': 'MISC', ' Sales Force': 'MISC', ' DBS': 'MISC', ' Cat PowerNet': 'MISC', ' SIS-WEB': 'MISC', ' PSQ': 'MISC', ' Lotus Notes': 'MISC', ' EOMP': 'MISC', ' AutoCAD': 'MISC', ' Adobe Standard': 'MISC', ' The Carter Way': 'MISC'}"
27,Titan America,Data Engineer,"Data Engineer
We are seeking a motivated and detail-oriented Data Engineer to join our team based in Roanoke, Virginia. As a Data Engineer, you will play a crucial role in designing, developing and maintaining scalable data pipelines and transformations for business-critical use cases. In addition, you may take on various Software Development and Data Science responsibilities as we frequently share responsibilities and knowledge across our growing team.
Responsibilities:Design, develop and maintain scalable data pipelines for extracting, transforming, and loading data from various sourcesCollaborate with cross-functional teams to identify data needs and determine the best data solutionsDevelop and implement data models to support business requirements and ensure data qualityEnsure the security and privacy of sensitive data by implementing appropriate access controlsMonitor and optimize data pipeline performance to ensure timely and accurate data deliveryDocument data pipeline processes, data dictionaries, and data storage solutions
Requirements:Bachelor's degree in Computer Science, Computer Engineering, or a related technical fieldMinimum of five years of professional experience working as a Data Engineer or Software DeveloperStrong hands-on experience with data warehouse and transformation solutions, i.e. Domo, Snowflake or similarProficient in at least one scripting language such as Python, JavaScript, or RUnderstanding of data modeling, data integration and data quality processesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformStrong analytical and problem solving skillsFull Stack Software Development experience in a professional setting is highly desired, but not required
This is an excellent opportunity for a driven and collaborative individual to make a significant impact in a dynamic and growing team. If you have a passion for data and a desire to work in a fast-paced and dynamic environment, we want to hear from you!","Design, develop and maintain scalable data pipelines for extracting, transforming, and loading data from various sources Collaborate with cross-functional teams to identify data needs and determine the best data solutionsDevelop and implement data models to support business requirements and ensure data qualityEnsure the security and privacy of sensitive data by implementing appropriate access controlsMonitor and optimize data pipeline performance to ensure timely and accurate data deliveryDocument data pipeline processes, data dictionaries, and data storage solutions","Bachelor's degree in Computer Science, Computer Engineering, or a related technical field. Minimum of five years of professional experience working as a Data Engineer or Software Developer. Strong hands-on experience with data warehouse and transformation solutions, i.e. Domo, Snowflake or similar. Proficient in at least one scripting language such as Python, JavaScript, or R. Understanding of data modeling, data integration and data quality processes. Familiarity with cloud platforms such as AWS, Azure, or Google Cloud Platform. Strong analytical and problem solving skills. Full Stack Software Development experience in a professional setting is highly desired, but not required","{' Python': 'MISC', ' JavaScript': 'MISC', ' R': 'MISC', ' Azure': 'MISC', ' Google Cloud Platform': 'MISC'}"
28,Amazon,Data Engineer,"Description

Do you love building tools and data pipelines? Are you excited by the opportunity to create clear effective reports and data visualizations, and partner with stakeholders to answer key business questions? Do you want to be a part of a fast-paced environment and contribute to one of the most visited sites on the Internet?

If this describes you, consider joining us as a Data Engineer. You will have the opportunity to impact the evolution of Amazon technology as well as lead mission critical projects early in your career. Your work will contribute to solving some of the most complex technical challenges in the company.

Responsibilities

As a data engineer I, you will/may:

Design, implement, and automate deployment of our distributed system for collecting and processing data from multiple upstream sources

Design data schema and operate internal data warehouses and SQL/NoSQL database systems

Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions

Monitor and troubleshoot operational or data issues in the data pipelines

Drive architectural plans and implementation for future data storage, reporting, and analytic solutions

Work collaboratively with TPMs, Product managers, and other internal partners to identify opportunities/problems

Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem

We are open to hiring candidates to work out of one of the following locations:

Seattle, WA, USA

Basic Qualifications

 1+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with SQL Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala) Experience with one or more scripting language (e.g., Python, KornShell) Bachelor's or Master's degree in Engineering with 0-2 years of experience.

Preferred Qualifications

 Experience with big data technologies such as: Hadoop, Hive, Spark, EMR Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.

Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.



Company - Amazon.com Services LLC

Job ID: A2605789","Design, implement, and automate deployment of our distributed system for collecting and processing data from multiple upstream sources. Design data schema and operate internal data warehouses and SQL/NoSQL database systems. Own the design, development, and maintenance of ongoing metrics, reports, analyses, and dashboards to drive key business decisions. Monitor and troubleshoot operational or data issues in the data pipelines. Drive architectural plans and implementation for future data storage, reporting, and analytic solutions. Work collaboratively with TPMs, Product managers, and other internal partners to identify opportunities/problems. Provide assistance to the team with troubleshooting, researching the root cause, and thoroughly resolving defects in the event of a problem.","1+ years of data engineering experience Experience with data modeling, warehousing and building ETL pipelines Experience with SQL Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala) Experience with one or more scripting language (e.g., Python, KornShell) Bachelor's or Master's degree in Engineering with 0-2 years of experience.","{' SQL': 'MISC', ' PL/SQL': 'MISC', ' DDL': 'MISC', ' MDX': 'MISC', ' HiveQL': 'MISC', ' SparkSQL': 'MISC', ' Scala': 'MISC', ' Python': 'MISC', ' KornShell': 'MISC'}"
31,Ascentt,Data Engineer,"Overview:As a Data Engineer specializing in Cloud Image and Edge Device handling, you will play a crucial role inthe development and maintenance of our data infrastructure, particularly focused on managing imagedata from edge devices and processing it efficiently in cloud environments. You will be responsible fordesigning, implementing, and optimizing data pipelines to ensure seamless ingestion, storage, andanalysis of image data from various sources. Additionally, you will collaborate closely with crossfunctionalteams to integrate data-driven solutions into our products and services.Responsibilities:Data Pipeline Development: Design, implement, and maintain scalable data pipelines for ingesting,processing, and analyzing image data from edge devices to cloud-based storage and computingplatforms.Data Architecture: Design and Architect a Data Lake for structured and unstructured data over cloud(e.g., AWS, Azure, Google Cloud) for efficient storage, processing, and retrieval of data, ensuring highavailability, reliability, and performance.Edge Device Integration: Develop strategies and mechanisms for seamless integration of edge deviceswith cloud-based systems, including data synchronization, device management, and security protocols.Image Data Processing: Implement algorithms and techniques for real-time processing, transformation,and analysis of image data, optimizing for speed, accuracy, and resource efficiency.Data Quality and Governance: Implement data quality checks, validation processes, and governanceframeworks to ensure the integrity, consistency, and security of image data throughout its lifecycle.Performance Optimization: Identify performance bottlenecks in data pipelines and cloud infrastructure,and implement optimizations to improve throughput, latency, and cost-effectiveness.Collaboration and Communication: Collaborate with cross-functional teams, including softwareengineers, data scientists, and domain experts, to understand requirements, prioritize tasks, and deliverintegrated solutions.Documentation and Best Practices: Document design decisions, implementation details, and bestpractices for data engineering processes, ensuring knowledge sharing and continuous improvementwithin the team.Qualifications:Bachelor's or Master's degree in Computer Science, Engineering, or related field.Proven experience as a Data Engineer, preferably with specialization in handling image data.Strong proficiency in cloud computing platforms (e.g., AWS, Azure, Google Cloud) and related services(e.g., S3, EC2, Lambda, Kubernetes).Experience with data engineering tools like DataBrick, Snowflake, Glue etc.Proficiency in programming languages commonly used in data engineering (e.g., Python, Scala, Java) andfamiliarity with relevant libraries and frameworks (e.g., Apache Spark, TensorFlow, OpenCV).Solid understanding of data modeling, schema design, and database technologies (e.g., SQL, NoSQL,data warehouses).Familiarity with DevOps practices, CI/CD pipelines, and containerization technologies (e.g., Docker,Kubernetes).Strong problem-solving skills, analytical thinking, and attention to detail.Excellent communication and collaboration skills, with the ability to work effectively in a cross-functionalteam environment.","You will be responsible fordesigning, implementing, and optimizing data pipelines to ensure seamless ingestion, storage, andanalysis of image data from various sources. Additionally, you will collaborate closely with crossfunctionalteams to integrate data-driven solutions into our products and services.Responsibilities:Data Pipeline Development: Design, implement, and maintain scalable data pipelines for ingesting,processing, and analyzing image data from edge devices to cloud-based storage and computingplatforms.Data Architecture: Design and Architect a Data Lake for structured and unstructured data over cloud(e.g., AWS, Azure, Google Cloud) for efficient storage, processing, and retrieval of data, ensuring highavailability, reliability, and performance.Edge Device Integration: Develop strategies and mechanisms for seamless integration of edge deviceswith cloud-based systems, including data synchronization, device management, and security protocols.Image Data Processing: Implement algorithms and techniques for real-time processing, transformation,and analysis of image data, optimizing for speed, accuracy, and resource efficiency.Data Quality and Governance: Implement data quality checks, validation processes, and governanceframeworks to ensure the integrity, consistency, and security of image data throughout its lifecycle.Performance Optimization: Identify performance bottlenecks in data pipelines and cloud infrastructure,and implement optimizations to improve throughput, latency, and cost-effectiveness.Collaboration and Communication: Collaborate with cross-functional teams, including softwareengineers, data scientists, and domain experts, to understand requirements, prioritize tasks, and deliverintegrated solutions.Documentation and Best Practices: Document design decisions, implementation details, and bestpractices for data engineering processes, ensuring knowledge sharing and continuous improvementwithin the team.","Bachelor's or Master's degree in Computer Science, Engineering, or related field.Proven experience as a Data Engineer, preferably with specialization in handling image data.Strong proficiency in cloud computing platforms (e.g., AWS, Azure, Google Cloud) and related services(e.g., S3, EC2, Lambda, Kubernetes).Experience with data engineering tools like DataBrick, Snowflake, Glue etc.Proficiency in programming languages commonly used in data engineering (e.g., Python, Scala, Java) andfamiliarity with relevant libraries and frameworks (e.g., Apache Spark, TensorFlow, OpenCV).Solid understanding of data modeling, schema design, and database technologies (e.g., SQL, NoSQL,data warehouses).Familiarity with DevOps practices, CI/CD pipelines, and containerization technologies (e.g., Docker,Kubernetes).Strong problem-solving skills, analytical thinking, and attention to detail.Excellent communication and collaboration skills, with the ability to work effectively in a cross-functionalteam environment.","{' DataBrick': 'MISC', ' Glue': 'MISC', ' Python': 'MISC', ' Scala': 'MISC', ' Java': 'MISC', ' Apache Spark': 'MISC', ' TensorFlow': 'MISC', ' OpenCV': 'MISC', ' SQL': 'MISC', ' NoSQL': 'MISC'}"
32,ATC,Data Analyst,"Job Title: Entry Level Business Analyst / Product Owner U.S. Citizens and those authorized to work in the U.S. are encouraged to apply. We are able to sponsor at this time.We are a US equal employment opportunity employer. Job Description:Entry Level expertise in gathering, analyzing, and documenting business requirements. If you do not have experience as a Business Analyst or Product Owner, you will be put through a training & Internship program.Experience in Requirement Gathering, Agile methodology, writing user stories, and building and planning roadmaps.Experience in preparing functional and detailed system design documentsDemonstrate expertise with SDLC methodologyAbility to communicate effectively across multiple levels of the organization, including with leadership.Demonstrated leadership, initiative, analytical skills, and sound business acumen, including the ability to understand and analyze recommendationsExperience with all phases of testing (i.e., system, integration, user acceptance), including creating use cases, test conditions, and review of output.Must be able to adjust and work effectively in a dynamic, changing environmentOther:Master‚Äôs Degree.We sponsor H1B or related work visas for eligible candidates on F1/OPT/CPT.We offer health insurance 100% paid.We follow equal employment opportunity.","The role involves gathering, analyzing, and documenting business requirements, with a focus on Agile methodologies such as writing user stories and contributing to product roadmaps. You will assist in preparing functional and detailed system design documents, as well as support all phases of testing including system, integration, and user acceptance testing by creating use cases and reviewing outputs. Effective communication across various levels of the organization, including leadership, is essential. The position also calls for initiative, analytical thinking, and sound business acumen to help translate business needs into actionable solutions.","This is an entry-level position, and candidates without direct experience as a Business Analyst or Product Owner will participate in a training and internship program. A Master’s degree is required. Familiarity with Agile, SDLC methodologies, and experience or understanding of requirement gathering is preferred. Strong communication, leadership potential, adaptability, and a willingness to work in a dynamic environment are key. The company offers H1B or related visa sponsorship for eligible candidates on F1/OPT/CPT, provides 100% employer-paid health insurance, and is an equal opportunity employer.","{' Agile': 'MISC', ' SDLC': 'MISC'}"
37,Celebal Technologies,Data Engineer,"Company DescriptionCelebal Technologies is a premier software services company specializing in Data Science, Big Data, and Enterprise Cloud. Our intelligent data solutions use cutting-edge technology to provide competitive advantages and facilitate smarter decision-making for our clients. With expertise in Robotics, Artificial Intelligence, and Machine Learning, we offer improved business efficiency and help clients transform into data-driven enterprises. Our tailor-made solutions maximize productivity and accuracy across various industries.
Role DescriptionThis is a hybrid internship role with flexibility for remote work. As a Data Engineer at Celebal Technologies, you will be responsible for tasks such as data modeling, data warehousing, and data analytics. You will work with our team of industry experts on projects related to supply chain analytics, media greenlighting, and generating actionable insights through data analysis.
QualificationsCurrently enrolled in a degree program in the United States and eligible for Optional Practical Training (OPT).Strong understanding of SQL with hands-on experience in writing complex queries.Proficiency in Python programming language.Familiarity with Pyspark or similar distributed computing frameworks is a plus.Solid grasp of data structures, algorithms, and software engineering principles.Excellent problem-solving skills and attention to detail.Ability to work independently as well as collaboratively in a team environment.Eagerness to learn new technologies and adapt to changing requirements.","As a Data Engineer Intern at Celebal Technologies, you will contribute to key projects involving data modeling, data warehousing, and data analytics. You'll collaborate with industry experts to support initiatives in areas such as supply chain analytics and media greenlighting, helping generate actionable business insights through advanced data analysis. The role offers a hybrid internship experience with flexibility for remote work, allowing you to apply technical skills while gaining practical exposure to real-world data challenges.","The ideal candidate is currently enrolled in a degree program in the U.S. and eligible for Optional Practical Training (OPT). A strong foundation in SQL, including experience with complex queries, and proficiency in Python are essential. Familiarity with distributed computing frameworks like PySpark is a plus. Candidates should demonstrate solid understanding of data structures, algorithms, and software engineering principles, along with excellent problem-solving skills and attention to detail. A proactive attitude, the ability to work independently or collaboratively, and a willingness to learn new technologies are key to success in this role.","{' SQL': 'MISC', ' Python': 'MISC', ' PySpark': 'MISC'}"
39,Data Glacier,Data Scientist,"Unpaid internship hence no compensation or stipendTitle : Data Science InternResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with dataCompile and analyze data related to business issuesDevelop clear visualizations to convey complicated data in a straightforward fashionQualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experienceProficient in SQL, Python/R, Data Wrangling, Data Visualization( seaborn, matplotlib, etc)Everything will be done virtuallyThe person may do some productive tasks as part of their learning experience, training, or skill development. But this work will not be claimed by Data Glacier and DG will not utilize this work for their benefit.Data Glacier does not require any time commitment. It is up to interns how much time they give to learn and complete the task.Intern can utilize the code and application developed during the internship for their branding and HR networking.Unpaid internship hence no compensation or stipendPlease write to us if you have any further questions.https://www.dataglacier.org/virtual-internshipEmployment TypeInternshipCompensationNo","As a Data Science Intern at Data Glacier, you will explore and analyze real-world business problems through data. Your role involves compiling and interpreting data related to various business challenges and presenting insights through clear, impactful visualizations. This internship is entirely virtual and focuses on providing a learning experience, allowing interns to engage in productive tasks as part of their training and skill development. However, the work completed will not be utilized by the organization for its benefit.","The internship is open to candidates pursuing a Bachelor's or Master's degree in Statistics, Applied Mathematics, or a related field. Applicants should have a good grasp of SQL and programming skills in Python or R, along with experience in data wrangling and visualization tools such as Seaborn and Matplotlib. There are no strict time commitments, making it a flexible opportunity for self-driven learners. While the position is unpaid, interns can use the code and projects developed during the internship for personal branding and networking within the industry.","{' SQL': 'MISC', ' Python': 'MISC', ' R': 'MISC', ' Seaborn': 'MISC'}"
40,Data Glacier,Data Analyst,"The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with data Compile and analyze data related to business' issues Develop clear visualizations to convey complicated data in a straightforward fashion
QualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience 1 - 2 years' Data Analysis experience Proficient in SQL","The ideal candidate will leverage their passion for big data and analytics to uncover actionable insights for the business. They will be responsible for conducting both regular and ad hoc analyses to help address day-to-day business challenges. Key tasks include compiling and analyzing relevant data and creating clear, effective visualizations to communicate complex findings in a straightforward manner.","Candidates should hold a Bachelor's or Master's degree in Statistics, Applied Mathematics, or a related field, along with 1–2 years of experience in data analysis. Proficiency in SQL is required, and familiarity with data visualization and analytical techniques is essential for success in this role.",{' SQL': 'MISC'}
43,Data Glacier,Data Scientist,"The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with data Compile and analyze data related to business' issues Develop clear visualizations to convey complicated data in a straightforward fashion
QualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience 1 - 2 years' Data Analysis experience Proficient in SQL","The ideal candidate will apply their passion for big data and analytics to generate valuable insights across various business areas. They will be responsible for performing both regular and ad hoc analyses to help address business challenges. This includes compiling and analyzing relevant data and creating clear, effective visualizations to simplify complex information for business users.","Candidates should possess a Bachelor's or Master's degree in Statistics, Applied Mathematics, or a related field, along with 1–2 years of hands-on experience in data analysis. Proficiency in SQL is essential, as well as a solid understanding of analytical techniques and the ability to interpret and communicate data findings clearly.",{' SQL': 'MISC'}
44,Capital One,Data Engineer,"Plano 1 (31061), United States of America, Plano, TexasData Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you‚Äôll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You‚Äôll Do:

 Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies  Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems  Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake  Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community  Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment  Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance 

Basic Qualifications:

 Bachelor‚Äôs Degree  At least 2 years of experience in application development (Internship experience does not apply)  At least 1 year of experience in big data technologies 

Preferred Qualifications: 

 3+ years of experience in application development including Python, SQL, Scala, or Java  1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)  2+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)  1+ years experience working on real-time data and streaming applications  1+ years of experience with NoSQL implementation (Mongo, Cassandra)  1+ years of data warehousing experience (Redshift or Snowflake)  2+ years of experience with UNIX/Linux including basic commands and shell scripting  1+ years of experience with Agile engineering practices 

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York City (Hybrid On-Site): $138,500 - $158,100 for Data Engineer

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate‚Äôs offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City‚Äôs Fair Chance Act; Philadelphia‚Äôs Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).","As a Data Engineer at Capital One, you will design, develop, and support full-stack data solutions in a fast-paced, Agile environment. You'll work with a team of developers experienced in machine learning, microservices, and cloud technologies. Your responsibilities include building scalable systems using tools like Python, Java, Scala, SQL, and cloud-based data platforms such as Redshift and Snowflake. You will collaborate with product managers and cross-functional teams to deliver data-driven experiences, conduct code reviews, and ensure performance-optimized, maintainable solutions. Staying current with technology trends and contributing to the broader engineering community is also part of the role.","Candidates must have a Bachelor's degree and at least 2 years of experience in application development (excluding internships) and 1 year working with big data technologies. Preferred qualifications include 3+ years of experience with Python, SQL, Scala, or Java; familiarity with public cloud platforms like AWS or Azure; and hands-on experience with distributed data tools like Spark, Hadoop, Kafka, or Hive. Knowledge of NoSQL databases, real-time streaming, data warehousing (Redshift/Snowflake), UNIX/Linux, and Agile practices is also highly valued. Capital One does not sponsor new employment authorization for this role.","{' Python': 'MISC', ' SQL': 'MISC', ' Scala': 'MISC', ' Java': 'MISC', ' Spark': 'MISC', ' Hadoop': 'MISC', ' UNIX/Linux': 'MISC', ' Agile': 'MISC'}"
46,SynergisticIT,Data Scientist,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don‚Äôt focus on getting you a tech Job we make careers.In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careershttps://www.synergisticit.com/candidate-outcomes/https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalogWe regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023All Positions are open for all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000‚Äôs of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry. We assist in filing for STEM extension and also for H1b and Green card filing to Candidateshttps://www.youtube.com/watch?v=OFoqPTNORewhttps://www.youtube.com/watch?v=-HkNN1ag6Zkhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://youtu.be/bJJl27D8bh0We are looking for the right matching candidates for our clientsREQUIRED SKILLS For Java /Full stack/Software ProgrammerBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learning PositionsREQUIRED SKILLSBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, TensorflowIf you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates","SynergisticIT is seeking entry-level professionals passionate about technology and looking to build careers in the tech industry. Positions include Software Programmers, Full Stack Java Developers, Python/Java Developers, Data Analysts, Data Scientists, and Machine Learning Engineers. Candidates will work on real-time client projects and gain hands-on experience in modern tools and technologies such as Spring Boot, Microservices, REST APIs, Python, Java, and various data science frameworks. The company provides training and placement support, helping candidates bridge the skills gap and successfully secure positions at top tech companies like Google, Apple, PayPal, and Visa.","Applicants should hold a Bachelor's or Master’s degree in Computer Science, Engineering, Mathematics, Statistics, Information Systems, or related fields. Ideal candidates are self-motivated, eager to learn, and have foundational knowledge or project experience in programming languages like Java, Python, or C++. For data science and machine learning roles, familiarity with statistics, data visualization, computer vision, and tools like SAS, Tableau, PowerBI, and TensorFlow is preferred. Excellent communication skills are essential. SynergisticIT is open to all visa types, supports STEM extensions, and assists with H1B and Green Card filings for eligible candidates.","{' Java': 'MISC', ' Python': 'MISC', ' C++': 'MISC'}"
47,FedEx Logistics,Data Analyst,"About FedEx Supply Chain

FedEx Supply Chain, a subsidiary of FedEx Corp. (NYSE: FDX), is a leader in the third-party logistics industry offering a diverse service portfolio that enables commerce for businesses. With a proven track record of innovation and operational excellence, FedEx Supply Chain takes a consultative approach to optimize logistics processes, implement innovative technology and drive continuous improvement. By leveraging best practices and the world-renowned FedEx network, FedEx Supply Chain delivers leading solutions that provide flexibility, enable scalability and improve cost-effectiveness for customers. Through more than 11,000 employees, 130 operations and 35 million square feet of warehouse space, FedEx Supply Chain manages nearly 150 million packages and processes 358 million returns each year. For more information, go to supplychain.fedex.com.

We Have‚Ä¶.

A strong FedEx brand consistently ranked among the world‚Äôs most admired and trusted employers.A top notch leadership team with the experience needed to grow and develop your career.An open mind for new ideas and creative methods.A strong compensation and benefits package, including health, vision, dental, 401k with a strong match and much more!

General Summary‚Ä¶.

The Analyst, Data II is part of a team that shares the responsibility for success and profitability by providing services to our customers which may include: data warehousing, post audits, reporting, carrier bids management, dashboard creation, project management, transportation analysis, application mastery, consulting support, and data analysis. The Data Analyst works with customers, carriers, and internal employees to analyze and identify cost saving opportunities for customers.

This position will be responsible for‚Ä¶..

Manage data gathering for customers‚Äô benchmark key performance metrics.Create a strategic approach to carrier bids through lane, mode, and service balancing (Bid team) by performing the following tasks: Scorecard and performance tracking, transportation dashboard, on-going analysis of data. Determine the best mode, carrier, and service for the customer, resulting in customer savings by providing the analysis and metrics for transportation bids.Use professional judgment to assess the impact of decisions/actions on the customer and the Company which would be approved by both the customer and the person‚Äôs leader.Act as an internal technical resource for role specific applications.Analyze large amounts of data and then recommend broad based innovative improvement initiatives for customer(s).Reporting and analyzing on an ad hoc basis for the customer. Develop customer presentations showing data trends and possible solutions to the customer. Collaborate with the objective of agreeing to the most effective and profitable solution for the customer, carrier, and the Company.Developing standard operating procedures based on the direction from manager.

You might be a great fit if‚Ä¶.

Education/Experience

Bachelor‚Äôs Degree in Statistics, Engineering, Accounting/Finance or related field preferred and 5+ years of relevant experience.In lieu of degree, high school diploma or GED and 4-6 years of relevant experience.Proficient with technology, specifically Microsoft applications such as Access and Excel.Experience with SQL is preferred.Ability to work in a fast paced environment with multiple deadlines.Strong organizational skills and the ability to handle multiple tasks simultaneously.Strong interpersonal skills with the ability to work with internal and external customers.Experience or knowledge in transportation, logistics, parcel shipping or freight pay is preferred.Excellent written and verbal communication skills.

Physical/Cognitive Requirements

With or without accommodation:

Ability to follow policies and procedures.Ability to read, write and interpret information.Ability to add, subtract, multiply and divide. Ability to use hands to finger, handle, or feel.Ability to sit/walk/stand for up to 8 hours per day. Must possess visual acuity, i.e., close, distance, and color vision, depth perception and the ability to adjust focus.

FedEx Supply Chain, Inc., as well as its subsidiary companies, is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.

The FedEx Logistics companies are committed to providing access, equal opportunity, and reasonable accommodation for qualified individuals with disabilities in its application procedures, hiring, and other terms and conditions of employment. To request a reasonable accommodation, please contact Fxl.talentacquisition@fedex.com.

Job ID: 52021

Schedule: Full-time","As a Data Analyst II at FedEx Supply Chain, you’ll support customer operations through advanced data analysis and reporting, contributing to cost-saving strategies and logistics optimization. You will manage data collection, benchmark key performance indicators, and create transportation dashboards to track carrier performance. Responsibilities also include supporting carrier bids, determining the best shipping methods, creating customer presentations with insights and trends, and developing standard operating procedures. You’ll work closely with internal teams, customers, and carriers to provide innovative solutions that align with business goals and drive continuous improvement.","The role requires a Bachelor’s degree in Statistics, Engineering, Finance, or a related field, along with at least 5 years of relevant experience (or 4–6 years with a high school diploma or GED). Proficiency in Microsoft Excel and Access is essential, and experience with SQL is preferred. The ideal candidate will have strong organizational and multitasking abilities, excellent communication skills, and familiarity with transportation, logistics, or parcel shipping. The position also demands strong analytical thinking and a collaborative mindset, with the ability to interpret large datasets and provide strategic insights.","{' GED': 'MISC', ' Microsoft Excel': 'MISC', ' Access': 'MISC', ' SQL': 'MISC'}"
48,Capital One,Data Engineer,"Locations: VA - McLean, United States of America, McLean, VirginiaData Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you‚Äôll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You‚Äôll Do

 Support the design and development of scalable data architectures and systems that extract, store, and process large amounts of data  Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity  Collaborate with Data Scientists, Machine Learning Engineers, Business Analysts and/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling  Implement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs  Use cutting edge technologies to develop modern data pipelines supporting Machine Learning and Artificial Intelligence 

Basic Qualifications:

 Bachelor‚Äôs Degree  At least 2 years of experience in application development (Internship experience does not apply)  At least 1 year of experience in big data technologies 

Preferred Qualifications:

 3+ years of experience in application development including Python, Scala, or Java  1+ years of experience using Spark  1+ years of experience working on data stream systems (Kafka or Kinesis)  1+ years of data warehousing experience (Redshift or Snowflake)  1+ years of experience with Agile engineering practices  1+ years of experience working with a public cloud (AWS, Microsoft Azure, Google Cloud) 

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City‚Äôs Fair Chance Act; Philadelphia‚Äôs Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).","As a Data Engineer at Capital One, you’ll play a key role in designing and developing scalable data architectures and modern data pipelines to support analytics, machine learning, and artificial intelligence initiatives. Your work will involve building robust data ingestion and transformation workflows, optimizing pipeline performance, and ensuring data integrity. You’ll collaborate with cross-functional teams—including Data Scientists, ML Engineers, and Product Owners—to deliver high-quality data solutions. Additionally, you’ll implement validation, testing, and observability tools to maintain reliable pipelines that meet strict service level agreements (SLAs).","The role requires a Bachelor's degree and at least 2 years of professional experience in application development, including 1 year working with big data technologies. Preferred candidates will have 3+ years of experience using Python, Scala, or Java, and hands-on knowledge of tools like Spark, Kafka/Kinesis, Redshift or Snowflake. Experience working in Agile environments and using cloud platforms such as AWS, Azure, or Google Cloud is also valued. Please note that Capital One does not provide employment sponsorship for this role.","{' Python': 'MISC', ' Scala': 'MISC', ' Java': 'MISC', ' Kafka/Kinesis': 'MISC'}"
49,Capital One,Data Engineer,"Plano 1 (31061), United States of America, Plano, TexasData Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you‚Äôll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You‚Äôll Do:

 Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies  Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems  Utilize programming languages like Java, Scala, Python and Open Source RDBMS and NoSQL databases and Cloud based data warehousing services such as Redshift and Snowflake  Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community  Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment  Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance 

Basic Qualifications:

 Bachelor‚Äôs Degree  At least 2 years of experience in application development (Internship experience does not apply)  At least 1 year of experience in big data technologies 

Preferred Qualifications: 

 3+ years of experience in application development including Python, SQL, Scala, or Java  1+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)  2+ years experience with Distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL)  1+ years experience working on real-time data and streaming applications  1+ years of experience with NoSQL implementation (Mongo, Cassandra)  1+ years of data warehousing experience (Redshift or Snowflake)  2+ years of experience with UNIX/Linux including basic commands and shell scripting  1+ years of experience with Agile engineering practices 

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.

New York City (Hybrid On-Site): $138,500 - $158,100 for Data Engineer

Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate‚Äôs offer letter.

This role is also eligible to earn performance based incentive compensation, which may include cash bonus(es) and/or long term incentives (LTI). Incentives could be discretionary or non discretionary depending on the plan.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City‚Äôs Fair Chance Act; Philadelphia‚Äôs Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).","As a Data Engineer at Capital One, you will work in Agile teams to design, develop, test, and support scalable data solutions using full-stack development tools. You'll collaborate with developers experienced in machine learning, microservices, and cloud systems to create innovative, performance-optimized pipelines. Your responsibilities include using technologies like Java, Scala, Python, Redshift, and Snowflake, as well as open-source RDBMS and NoSQL databases. You'll also partner with digital product managers to deliver impactful, cloud-based applications and services, staying current with emerging technologies while contributing to the engineering community.","The position requires a Bachelor's degree and a minimum of 2 years of experience in application development (excluding internships) and at least 1 year with big data technologies. Preferred candidates will have 3+ years of experience in languages such as Python, SQL, Scala, or Java; 1+ years of experience with public cloud platforms like AWS, Azure, or GCP; and experience with distributed computing tools (e.g., Hadoop, Spark, Kafka), NoSQL databases (e.g., MongoDB, Cassandra), and data warehousing platforms like Redshift or Snowflake. Familiarity with UNIX/Linux systems and Agile practices is also preferred. Note: Capital One does not offer sponsorship for new applicants for this position.","{' Python': 'MISC', ' SQL': 'MISC', ' Scala': 'MISC', ' Java': 'MISC', ' GCP': 'ORG', ' Hadoop': 'MISC', ' Spark': 'MISC', ' UNIX/Linux': 'MISC', ' Agile': 'MISC'}"
50,Capital One,Data Engineer,"Locations: VA - McLean, United States of America, McLean, VirginiaData Engineer

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you‚Äôll have the opportunity to be on the forefront of driving a major transformation within Capital One.

What You‚Äôll Do

 Support the design and development of scalable data architectures and systems that extract, store, and process large amounts of data  Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources while ensuring data quality and integrity  Collaborate with Data Scientists, Machine Learning Engineers, Business Analysts and/or Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling  Implement testing, validation and pipeline observability to ensure data pipelines are meeting customer SLAs  Use cutting edge technologies to develop modern data pipelines supporting Machine Learning and Artificial Intelligence 

Basic Qualifications:

 Bachelor‚Äôs Degree  At least 2 years of experience in application development (Internship experience does not apply)  At least 1 year of experience in big data technologies 

Preferred Qualifications:

 3+ years of experience in application development including Python, Scala, or Java  1+ years of experience using Spark  1+ years of experience working on data stream systems (Kafka or Kinesis)  1+ years of data warehousing experience (Redshift or Snowflake)  1+ years of experience with Agile engineering practices  1+ years of experience working with a public cloud (AWS, Microsoft Azure, Google Cloud) 

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.

Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.

This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City‚Äôs Fair Chance Act; Philadelphia‚Äôs Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.

If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).","As a Data Engineer at Capital One, you will play a key role in developing and optimizing scalable data architectures and pipelines that support high-volume data ingestion, transformation, and storage. You'll collaborate with cross-functional teams—including Data Scientists, ML Engineers, Business Analysts, and Product Owners—to deliver efficient data solutions for analysis and modeling. Your work will contribute directly to building modern data pipelines that power machine learning and AI use cases. Ensuring data quality, implementing testing and observability, and staying at the forefront of emerging technologies are key aspects of this role.","Candidates should hold a Bachelor’s degree and have at least 2 years of professional experience in application development, along with 1 year of experience in big data technologies. Preferred qualifications include experience with Python, Java, or Scala; working knowledge of Spark, Kafka/Kinesis, and cloud services like AWS, Azure, or Google Cloud; and familiarity with data warehousing tools such as Redshift or Snowflake. Agile engineering practice experience is also a plus. Note that Capital One is not sponsoring new applicants for employment authorization for this role.","{' Python': 'MISC', ' Java': 'MISC', ' Scala': 'MISC', ' Spark': 'MISC'}"
51,SynergisticIT,Data Scientist,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don‚Äôt focus on getting you a tech Job we make careers.In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careershttps://www.synergisticit.com/candidate-outcomes/https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalogWe regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023All Positions are open for all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000‚Äôs of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry. We assist in filing for STEM extension and also for H1b and Green card filing to Candidateshttps://www.youtube.com/watch?v=OFoqPTNORewhttps://www.youtube.com/watch?v=-HkNN1ag6Zkhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://youtu.be/bJJl27D8bh0We are looking for the right matching candidates for our clientsREQUIRED SKILLS For Java /Full stack/Software ProgrammerBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learning PositionsREQUIRED SKILLSBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, TensorflowIf you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates","SynergisticIT is focused on preparing and placing candidates in full-time tech roles such as Software Programmers, Full Stack Java Developers, Python/Java Developers, Data Analysts, Data Scientists, and Machine Learning Engineers. These positions are with top-tier clients including Apple, Google, PayPal, Bank of America, and more. The organization provides hands-on project training, helping candidates bridge the gap between academic knowledge and industry skills. Responsibilities may include designing and developing software solutions, building machine learning models, analyzing datasets, and working with modern tech stacks like Spring Boot, Docker, REST APIs, Python, and data visualization tools. Candidates are supported with career development, placement services, and visa sponsorship assistance (H1B, STEM OPT, Green Card).","Ideal candidates are recent graduates or professionals with degrees in Computer Science, Engineering, Mathematics, Statistics, or related fields, including those looking to switch careers or re-enter the workforce. For software roles, knowledge of Java, JavaScript, Core Java, C++, and tools like Jenkins and Microservices is preferred. For data-focused roles, familiarity with Python, SAS, machine learning, statistics, computer vision, and tools like Tableau, Power BI, or TensorFlow is beneficial. Strong self-motivation, eagerness to learn, and excellent communication skills are essential. Candidates from all visa backgrounds and U.S. citizens are welcome to apply.","{' Java': 'MISC', ' JavaScript': 'MISC', ' Core Java': 'MISC', ' C++': 'MISC', ' Python': 'MISC', ' SAS': 'MISC'}"
52,SynergisticIT,Data Scientist,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don‚Äôt focus on getting you a tech Job we make careers.In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careershttps://www.synergisticit.com/candidate-outcomes/https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalogWe regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023All Positions are open for all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000‚Äôs of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry. We assist in filing for STEM extension and also for H1b and Green card filing to Candidateshttps://www.youtube.com/watch?v=OFoqPTNORewhttps://www.youtube.com/watch?v=-HkNN1ag6Zkhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://youtu.be/bJJl27D8bh0We are looking for the right matching candidates for our clientsREQUIRED SKILLS For Java /Full stack/Software ProgrammerBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learning PositionsREQUIRED SKILLSBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, TensorflowIf you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates","SynergisticIT specializes in helping job seekers launch successful tech careers by bridging the gap between academic knowledge and industry demands. They offer full-time job placement support in roles such as Software Programmers, Full Stack Java Developers, Python/Java Developers, Data Analysts, Data Scientists, and Machine Learning Engineers. Candidates are trained through real-world projects and technologies including Spring Boot, Microservices, REST APIs, Python, Java, Docker, and data visualization tools. By working with top-tier tech clients like Google, Apple, PayPal, Visa, and Bank of America, SynergisticIT helps candidates secure roles that offer competitive salaries and long-term career growth.","Ideal candidates include recent graduates in Computer Science, Engineering, Mathematics, Statistics, or related fields, as well as individuals looking to re-enter the workforce or switch careers. Applicants should have a strong foundation in programming (Java, Python, C++), knowledge of software development life cycles, and relevant project experience. For data science roles, understanding of statistics, machine learning, and tools like SAS, Tableau, Power BI, and TensorFlow is valuable. Candidates should be self-motivated, eager to learn, and possess excellent communication skills. All positions are open to U.S. citizens and candidates from all visa backgrounds, with support for STEM OPT, H1B, and green card filings.","{'Java': 'MISC', ' Python': 'MISC', ' C++': 'MISC'}"
53,Old Second National Bank,Data Analyst,"Who We Are

At Old Second, you're first! For more than 150 years, Old Second has consistently put businesses and individuals throughout the Chicago area first, and we're only getting started.

With great employees we've grown from a single location in the back of a general store to 50 locations and over $6 billion dollars in assets. At Old Second we embrace values that foster an environment of community and growth. Recently, we've been voted a Forbes Best-In-State Bank for Illinois by our customers. Be a part of something big as we continue our growth story together!

Position Overview

Thie Retail Data Analyst is responsible for extracting and reviewing data to identify key insights into Retail customer and employee activities and ways the data can be used to improve Retail sales activities. Other responsibilities include producing and executing data, determining trends in the Retail market both internally and externally, tracking and enhancing sales efforts through providing data for incentive and list creation, and supporting Retail sales incentives, contests and employee engagement.

Essential Job Functions

Extracts Retail data on a daily, weekly, quarterly and annual basis to support Retail Data Manager initiatives.Preforms data validation and cleansing along with other data partners to ensure systems present information correctly.Serves as data support person for Retail sales efforts. Collects Retail sales lead information as appropriate.Provides actionable Retail sales support through analysis of trending data in conjunction with Retail Data Manager.Collaborates with other departments to connect data within all company software.Produces periodic analysis of competitive market peers.Develops ad hoc reports for sales prospecting.Extracts data in connection with Retail employee engagement efforts, including sales campaigns.Maintains knowledge of bank products and services.Performs additional duties as assigned by Retail Data Manager.


Minimum Requirements

Associate‚Äôs degree and three or more years of data analytics, or related; or equivalent combination of education and experience.


Competencies

Strong technical skills, including but not limited to: SQL, Microsoft Excel & Access, General Database Administration, General Programing knowledge.Database management.Proficiency with both technical and non-technical communication.Excellent organizational skills, with a focus on accuracy and comprehension.


Preferred, But Not Required

Undergraduate degree in related area of study.


Thanks for considering Old Second!","The Retail Data Analyst at Old Second Bank will support retail initiatives by extracting, analyzing, and validating data to uncover key insights related to customer behavior and employee performance. The role involves regular data reporting, identifying internal and market trends, and creating actionable insights to enhance sales efforts, campaign targeting, and employee engagement. The analyst will work closely with the Retail Data Manager and cross-functional teams to support data-driven decision-making, develop custom reports, and contribute to incentive programs, contests, and sales prospecting efforts.","Candidates should have an associate’s degree and at least three years of experience in data analytics or a related field, or equivalent education and experience. Strong technical skills in SQL, Microsoft Excel and Access, general programming, and database management are essential. The position requires excellent organizational and communication skills, with the ability to interpret and explain data clearly to both technical and non-technical stakeholders. While not required, a bachelor's degree in a related field is preferred.","{' SQL': 'MISC', ' Microsoft Excel': 'MISC', ' Access': 'MISC'}"
54,SynergisticIT,Data Scientist,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don‚Äôt focus on getting you a tech Job we make careers.In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careershttps://www.synergisticit.com/candidate-outcomes/https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalogWe regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023All Positions are open for all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000‚Äôs of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry. We assist in filing for STEM extension and also for H1b and Green card filing to Candidateshttps://www.youtube.com/watch?v=OFoqPTNORewhttps://www.youtube.com/watch?v=-HkNN1ag6Zkhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://youtu.be/bJJl27D8bh0We are looking for the right matching candidates for our clientsREQUIRED SKILLS For Java /Full stack/Software ProgrammerBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learning PositionsREQUIRED SKILLSBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, TensorflowIf you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates","Since 2010, SynergisticIT has been dedicated to helping job seekers succeed in the tech industry by equipping them with in-demand skills and real-world experience. The organization partners with leading tech companies—including Apple, Google, PayPal, Visa, and Bank of America—to place qualified candidates in full-time roles such as Software Programmers, Java Full Stack Developers, Python/Java Developers, Data Analysts, Data Scientists, and Machine Learning Engineers. With a proven track record of success, SynergisticIT also provides training aligned with client expectations, helping candidates secure high-paying job offers and long-term careers. Visa sponsorship for OPT, STEM extensions, H1B, and Green Cards is available.","Applicants should hold a Bachelor’s or Master’s degree in Computer Science, Engineering, IT, or related fields. Ideal candidates are self-motivated, technically curious, and have project experience or foundational knowledge in areas such as Java, Python, C++, Spring Boot, Microservices, REST APIs, and software development life cycles. For data science roles, familiarity with statistics, machine learning, SAS, Python, computer vision, and visualization tools like Tableau and Power BI is important. Strong communication skills are essential. These roles are suited for recent graduates, career switchers, or those returning to the workforce.","{' Java': 'MISC', ' Python': 'MISC', ' C++': 'MISC', ' Spring Boot': 'MISC', ' Microservices': 'MISC', ' SAS': 'MISC', ' Power BI': 'MISC'}"
55,SynergisticIT,Data Scientist,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don‚Äôt focus on getting you a tech Job we make careers.In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careershttps://www.synergisticit.com/candidate-outcomes/https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalogWe regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023All Positions are open for all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000‚Äôs of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry. We assist in filing for STEM extension and also for H1b and Green card filing to Candidateshttps://www.youtube.com/watch?v=OFoqPTNORewhttps://www.youtube.com/watch?v=-HkNN1ag6Zkhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://youtu.be/bJJl27D8bh0We are looking for the right matching candidates for our clientsREQUIRED SKILLS For Java /Full stack/Software ProgrammerBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learning PositionsREQUIRED SKILLSBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, TensorflowIf you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates","SynergisticIT has been helping job seekers successfully launch careers in tech since 2010 by offering comprehensive training and job placement services. The organization works closely with leading tech companies like Google, Apple, PayPal, Visa, and Bank of America, enabling candidates to secure high-paying roles, often with multiple offers exceeding $100K. By focusing on real-world skills aligned with client needs, SynergisticIT bridges the gap between academic learning and industry expectations. They participate in major tech events like Oracle CloudWorld and Gartner Data Analytics Summit, giving their candidates exposure and networking advantages. Full-time positions are available for software engineers, Java full stack developers, data scientists, machine learning engineers, and more—with support for all visa types, including STEM OPT, H1B, and green cards.","Applicants should have a Bachelor's or Master’s degree in Computer Science, Engineering, IT, or related fields. This program is ideal for recent graduates, career changers, or those returning to the workforce. For software and full-stack roles, candidates should have experience or academic projects in Java, Core Java, JavaScript, C++, Spring Boot, Docker, REST APIs, and Jenkins. For data science and machine learning positions, familiarity with Python, SAS, statistics, computer vision, and tools like Tableau, PowerBI, and TensorFlow is preferred. Strong communication skills, a self-driven attitude, and a passion for technology are key to success. Only serious candidates matching client needs will be contacted—no third-party or C2C applicants accepted.","{' Java': 'MISC', ' Core Java': 'MISC', ' JavaScript': 'MISC', ' C++': 'MISC', ' Spring Boot': 'MISC', ' Docker': 'MISC', ' REST APIs': 'MISC', ' Jenkins': 'MISC', ' Python': 'MISC', ' SAS': 'MISC', ' PowerBI': 'MISC', ' TensorFlow': 'MISC'}"
56,Bonterra,Data Engineer,"Bonterra exists to propel every doer of good to their peak impact. We measure that impact against our vision to increase the giving rate as a percentage of GDP from 2% to 3% by 2033. We know that this goal is lofty, but we are confident that the right technology and expertise will strengthen trust in the sector, allowing the social good industry to accelerate growth and reach peak impact. Bonterra's differentiated, end-to-end solutions collectively support a unique network of over 20,000 customers, including over 16,000 nonprofit organizations and over 50 percent of Fortune 100 companies. Learn more at bonterratech.com.

What You Will Do: 

As a Senior Analytics Engineer, you‚Äôll play a pivotal role in designing and developing Insights, the analytics product within our strategic philanthropy division. The ideal candidate will have extensive experience with Looker or similar tools, deep database knowledge, strong problem-solving abilities, leadership skills, and a passion for transforming raw data into actionable intelligence. Collaborate closely with cross-functional teams to ensure the seamless integration of analytics solutions, impacting business outcomes and fostering a

culture of innovation.

Lead the development and maintenance of Insights, using Looker, Python, DBT, and Snowflake Spearhead the design and implementation of scalable data models, ensuring accuracy and efficiency in reporting. Drive the identification and resolution of complex data-related challenges, demonstrating exceptional problem-solving skills. Collaborate with product management to understand business requirements and translate them into actionable analytics solutions. Mentor and guide team members, fostering a collaborative and knowledge-sharing environment. Continuously evaluate and enhance the analytics infrastructure to align with evolving business needs. Collaborate with cross-functional teams to integrate analytics solutions seamlessly into business processes. Stay abreast of industry trends and emerging technologies to proactively recommend improvements and innovations. 

Who You Are: 

You are a seasoned Analytics Engineer with a deep understanding of modern analytics technology stacks and a solid foundation in database fundamentals and mechanics. You have an unwavering attention to detail, a relentless commitment to quality, and a customer focused mindset. You love learning and solving challenging problems. You are not just seeking a job but an opportunity to contribute to a mission-driven company, where your expertise will play a pivotal role in driving impactful, data-driven decisions.

Demonstrated expertise in utilizing advanced analytics tools such as Looker, Tableau, or similar platforms to design and implement scalable analytics solutionsProven experience in designing and optimizing data models, ensuring efficient and effective storage, retrieval, and analysis of large datasetsStrong analytical and critical-thinking skills with a track record of successfully identifying and resolving complex data-related challengesAbility to understand and translate business requirements into actionable analytics solutions, aligning technical insights with strategic business goalsMeticulous attention to detail and a commitment to maintaining data accuracy and integrity throughout the analytics process, from data extraction to reportingA proactive approach to staying abreast of industry trends, emerging technologies, and best practices in analytics, driving continuous improvement and innovation within the teamStrong interpersonal and communication skills, with the ability to convey complex technical concepts to non-technical stakeholders, fostering collaboration and understanding across departments

Compensation

The range displayed on this job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and in addition to benefits this role may be eligible for discretionary bonuses/incentives, and equity.

US base salary range: $113,000 - $125,000

Please note that the compensation range specified in this job posting is applicable to candidates based in the United States. Applicants must be authorized to work for any employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa at this time. 

For international applicants, actual salary offers may vary based on the local market compensation standards and will be determined in accordance with regional considerations, including but not limited to applicable laws, cost of living, and industry norms.

Our Culture:

Our team is made up of industry experts and advocates who are 100% committed to supporting the doers of social good. We are currently undergoing an effort to create the vision and values that embody our collective organization and embrace the individuals who make up our community.

Our comprehensive and competitive benefits include:

Generous Flexible Time Off (FTO) PolicyEquity for ALL regular, full-time employees from individual contributors to management - share in our success!Up to 15 paid company holidays including some commemorating social justice events and self-carePaid volunteer timeResources for savings and investmentsPaid parental leavePaid sick leaveHealth, vision, dental, and life insurance with additional access to health and wellness programs. Opportunities to learn, develop, network, and connect

We are committed to being an equal opportunity employer and evaluate qualified applicants without regard to race, color, religion, sex, pregnancy (including childbirth, lactation and related medical conditions), national origin, age, physical and mental disability, marital status, sexual orientation, gender identity, gender expression, genetic information (including characteristics and testing), military and veteran status, diversity of thought and any other characteristic protected by applicable law.","As a Senior Analytics Engineer at Bonterra, you will lead the design and development of Insights, the company’s analytics product within the strategic philanthropy division. You’ll work with technologies like Looker, Python, DBT, and Snowflake to build scalable data models, integrate analytics into business workflows, and drive data-informed decisions. This role involves solving complex data challenges, mentoring junior team members, collaborating cross-functionally, and staying ahead of industry trends to continuously improve Bonterra's analytics infrastructure. Your work will directly influence product outcomes and strategic direction by transforming raw data into meaningful insights.","The ideal candidate has deep expertise in modern analytics tools (especially Looker, Tableau, or similar), strong database knowledge, and experience designing and optimizing data models for performance and accuracy. You should be skilled at translating business requirements into technical solutions, maintaining data quality throughout the analytics lifecycle, and clearly communicating insights to both technical and non-technical stakeholders. A passion for problem-solving, attention to detail, and a collaborative, mission-driven mindset are key. Applicants must be authorized to work in the U.S., as Bonterra is not able to sponsor visas at this time. Compensation ranges from $113,000 to $125,000 depending on experience and location, and includes a generous benefits package.",{' Looker': 'MISC'}
57,SynergisticIT,Data Scientist,"Since 2010 Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don‚Äôt focus on getting you a tech Job we make careers.In this market also we have been able to help our candidates get multiple job offers and $100k + salaries.please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careershttps://www.synergisticit.com/candidate-outcomes/https://reg.rf.oracle.com/flow/oracle/cwoh23/OCWExhibitorCatalog/page/OCWexhibitorcatalogWe regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023All Positions are open for all visas and US citizensWe at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000‚Äôs of candidates get jobs at technology clients like apple, google, Paypal, western union, bank of america, visa, walmart labs etc to name a few.We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in the Tech Industry. We assist in filing for STEM extension and also for H1b and Green card filing to Candidateshttps://www.youtube.com/watch?v=OFoqPTNORewhttps://www.youtube.com/watch?v=-HkNN1ag6Zkhttps://www.youtube.com/watch?v=OAFOhcGy9Z8https://youtu.be/bJJl27D8bh0We are looking for the right matching candidates for our clientsREQUIRED SKILLS For Java /Full stack/Software ProgrammerBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleProject work on the skillsKnowledge of Core Java , javascript , C++ or software programmingSpring boot, Microservices, Docker, Jenkins and REST API's experienceExcellent written and verbal communication skillsFor data Science/Machine learning PositionsREQUIRED SKILLSBachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITProject work on the technologies neededHighly motivated, self-learner, and technically inquisitiveExperience in programming language Java and understanding of the software development life cycleKnowledge of Statistics, SAS, Python, Computer Vision, data visualization toolsExcellent written and verbal communication skillsPreferred skills: NLP, Text mining, Tableau, PowerBI, SAS, TensorflowIf you get emails from our Job Placement team and are not interested please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.
No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates","Since 2010, SynergisticIT has helped thousands of job seekers successfully transition into tech careers by providing the skills, training, and support needed to meet real-world client expectations. With strong industry connections—including companies like Apple, Google, PayPal, Visa, and Bank of America—SynergisticIT has enabled candidates to secure high-paying roles, often exceeding $100K salaries. They offer full-time job placements for Software Programmers, Full Stack Java Developers, Python Developers, Data Analysts, Data Scientists, and Machine Learning Engineers. The organization actively supports all visa types and assists with OPT/STEM extensions, H1B, and Green Card filings.","This opportunity is ideal for recent graduates in Computer Science, Engineering, Mathematics, Statistics, or IT, as well as individuals re-entering the workforce or changing careers. For software roles, candidates should have hands-on or project experience in Java, Core Java, JavaScript, C++, Spring Boot, REST APIs, Docker, and Jenkins. For data-related roles, strong skills in Python, statistics, machine learning, SAS, data visualization tools (e.g., Tableau, Power BI), and frameworks like TensorFlow are highly valued. Candidates must be self-driven, eager to learn, and possess excellent communication skills. Only those matching client needs will be contacted—third-party or C2C candidates will not be considered.","{' Java': 'MISC', ' Core Java': 'MISC', ' JavaScript': 'MISC', ' C++': 'MISC', ' Spring Boot': 'MISC', ' REST APIs': 'MISC', ' Docker': 'MISC', ' Jenkins': 'MISC', ' Python': 'MISC', ' SAS': 'MISC', ' Power BI': 'MISC', ' TensorFlow': 'MISC'}"
58,Zefr,Data Analyst,"What We Do

Zefr is the global leader in brand suitability targeting and measurement across the world‚Äôs largest platforms. Zefr‚Äôs technology is helping to power the age of responsible marketing by putting advertisers in control of their content adjacencies based on their own unique brand safety and suitability preferences, mapped to the Global Alliance of Responsible Media‚Äôs (GARM) industry standards. As an official YouTube Measurement Program Partner, Meta for Business Partner, and TikTok for Business Partner, the company leverages patented machine learning and AI technology (Cognition AI) to offer brands and agencies more precise and transparent brand safety and suitability activation and measurement solutions on scaled platforms. The company is headquartered in Los Angeles, California, with additional locations across the globe.

What You‚Äôll Do

We are hiring a Multilingual Data Annotation Specialist responsible for annotating videos, images, and metadata for YouTube, TikTok, Facebook, and other social media content. High-quality human annotation data is an integral part of training Zefr‚Äôs sophisticated compound AI systems.

Previous data annotation experience is not required. We are excited to welcome someone passionate and curious about machine learning and computer vision. We seek a self-motivated candidate who values high-quality work, adeptly follows instructions and manages tasks to completion, embraces a proactive approach, is unhesitant to seek clarification or offer constructive feedback to enhance processes, possesses strong analytical skills, and enjoys continuous learning and problem-solving.

Here‚Äôs What You‚Äôll Get To Do

Use in-house tools to label social media content based on Zefr‚Äôs various contextual category guidelinesMake judgment calls on nuanced content to provide cognitive and cultural understanding Apply and refine labeling framework and guidelinesProvide valuable insights on content trends and contribute to the enhancement of an efficient labeling interfaceBe willing to work with sensitive content including varying religious and political views, violence, and adult contentYou will gain basic machine learning and computer vision knowledge and how annotation data powers Zefr‚Äôs machine learning and AI technology 


Here‚Äôs What We‚Äôre Looking For

Fluency in Spanish, Portuguese, German, Arabic, Turkish, Japanese, Mandarin, or ThaiFamiliarity using social media platforms, including TikTok, YouTube, Facebook, and Instagram Strong attention to detail with the ability to perform repetitive tasks with high quality and consistencyExceptional critical thinking, problem-solving, and communication skillsAbility to work in a fast-paced environment, adept at rapid learning, and skilled in effectively prioritizing tasksCapable in both collaborative teamwork and independent workProficiency in Google Workspace applicationsSQL familiarity is a plusPreference for a candidate that is located in (or willing to relocate to) the great Los Angeles area


Zefr is an equal opportunity employer that embraces diversity and inclusion in the workplace. We are committed to building a team that represents a variety of backgrounds, skills, and perspectives because we know this only makes us better. We strongly encourage women, persons of color, LGBTQIA+ individuals, persons with disabilities, members of ethnic minorities, foreign-born residents, and veterans to apply even if you do not meet 100% of the qualifications.

Benefits (for US Based Employees)

Flexible PTOMedical, dental, and vision insurance with FSA optionsCompany-paid life insurancePaid parental leave401(k) with company matchProfessional development opportunities10+ paid holidays offFlexible hybrid work schedules‚ÄúSummer Fridays‚Äù (shorter work days on select Fridays during the summertime)In-office lunches and lots of free foodOptional in-person and virtual events (we like to celebrate!)


Compensation (for US Based Employees)

The anticipated salary for this position is between $60,000 to $65,000. Within the range, individual pay is determined by factors such as job-related skills, experience, and relevant education or training. If your compensation expectations fall outside of this range, it may still be worth having a conversation.","As a Multilingual Data Annotation Specialist at Zefr, you will play a key role in training AI and machine learning systems by labeling video, image, and metadata content across platforms like YouTube, TikTok, and Facebook. Using internal tools and detailed guidelines, you’ll apply cultural and contextual judgment to annotate social media content for brand safety and suitability. You’ll help refine annotation frameworks, provide insights on content trends, and contribute to improving Zefr’s AI tools. The role may involve reviewing sensitive content, and you'll gain hands-on exposure to machine learning and computer vision fundamentals as part of your work.","Zefr is looking for candidates fluent in one or more of the following languages: Spanish, Portuguese, German, Arabic, Turkish, Japanese, Mandarin, or Thai. You should be highly detail-oriented, analytical, and capable of performing repetitive tasks with accuracy. Familiarity with platforms like YouTube, TikTok, and Instagram is essential, along with strong communication and problem-solving skills. Experience with Google Workspace and basic SQL is a plus. While the role is open to remote workers, preference is given to candidates based in or willing to relocate to the Los Angeles area. The salary range for this role is $60,000–$65,000, along with a competitive benefits package.","{' Spanish': 'MISC', ' Portuguese': 'MISC', ' German': 'MISC', ' Arabic': 'MISC', ' Turkish': 'MISC', ' Japanese': 'MISC', ' Mandarin': 'MISC', ' Thai': 'MISC', ' SQL': 'MISC'}"
59,NFP,Data Analyst,"PROCE011249_1

Who We Are

NFP is a seven-time Best Places to Work award winner in Business Insurance who has also earned the 5-Star Diversity, Equity and Inclusion (DEI) award from Insurance Business magazine and the WORK180 employer endorsement. We‚Äôre a recognized Elite Agency award winner and a leading property and casualty broker, benefits consultant, wealth manager, and retirement plan advisor. NFP provides solutions enabling client success through the expertise of over 7,000 global employees, investments in innovative technologies, and enduring relationships with highly rated insurers, vendors and financial institutions. To learn more, please visit: https://www.NFP.com.

Summary Of Role

Provide support to the department using clerical and analytical skills to assist Marketing Specialist & Account Managers in the daily management of Property & Casualty policies. Must be able to efficiently and accurately execute agency processes that provide account leaders quality management data per policy. Strong computer skills along with effective verbal, written and electronic communications are required. Must be able to perform within a team environment building long lasting relationships with agency partners, company leadership and staff.

Essential Duties And Responsibilities

Pull policy correspondence reports from carrier websites and manage carrier e-mail delivery of similar reportsUtilize agency management system to provide quality control check in of new business / renewal policies, endorsements, audits, etc‚Ä¶against account management activityExecute policy correspondence delivery to the client per agency guidelines and proceduresInput and communicate appropriately notice of cancellations, non-renewals etc‚Ä¶Operate a variety of standard office machines, including personal computer with a variety of software, phone, fax, calculator, and shredding, photocopy, and mail machinesEstablish and maintain effective working relationships with co-workers, supervisors and the general publicAssist with special projects as assigned by management


Knowledge, Skills, And/or Abilities

Good written and verbal communication skillsAbility to successfully interact with a variety of peopleWorking knowledge of the insurance industry is desiredKnowledge using Applied/EPIC, Microsoft Outlook, Excel and WordAttention to detailsWillingness and flexibility to adjust to varying schedulesAble to coordinate resources and responsibilitiesMay be required to work overtime as necessary


Education And/or Experience

High School graduate or general education degree (GED), college preferred


Certificates, Licenses, Registration

None


Preferred Qualifications

P&C License


What We Offer

We're proud to offer a competitive salary, PTO & paid holidays, 401(k) with match, exclusive discount programs, health & wellness programs, and more. Our PeopleFirst culture focuses on building and nurturing lifelong relationships with our employees because, at the end of the day, we exist to be there for others.

NFP and You... Better together!

NFP is an inclusive Equal Employment Opportunity employer.","This role supports the Property & Casualty team by handling administrative and analytical tasks to assist Marketing Specialists and Account Managers. Responsibilities include managing policy documents from carrier websites and emails, performing quality control checks on policy documents (new business, renewals, endorsements, etc.), and ensuring timely client communication in line with agency guidelines. Additional duties involve maintaining accurate records using the agency’s management system (Applied/EPIC), processing policy notices (cancellations, non-renewals), and operating standard office equipment. The role also requires collaboration with internal teams and participation in special projects assigned by management.","Candidates should have a high school diploma or GED (college preferred), with good verbal and written communication skills and attention to detail. Experience in the insurance industry and familiarity with Applied/EPIC and Microsoft Office (Outlook, Excel, Word) are beneficial. The role demands flexibility, the ability to work both independently and within a team, and may occasionally require overtime. A Property & Casualty (P&C) license is preferred but not required. NFP offers a supportive PeopleFirst culture, competitive salary, benefits, and a focus on diversity, inclusion, and employee development.","{' Microsoft Office': 'MISC', 'Outlook': 'MISC', ' Excel': 'MISC', ' Word': 'MISC'}"
60,Nasdaq,Data Analyst,"Analyzes, tracks and maintains Index Licensing user requirements. Coordinates with customers to ensure that business needs are met. Manages account relationships with Index Licensing customer and internal support groups.

Performs basic, routine financial, analytical and database work relating to the company‚Äôs market data and/or index licensing systems.Assists with client onboarding process which includes providing product information, product ordering, reporting support and billing procedures.Serve as a liaison between the customer and the invoice collections team to assist in collecting payments if needed.Customer outreach for reporting.Provides responses to client inquiries relating to their accounts and escalates as needed.Supports internal customers with routine and/ or ad hoc reports as needed.Works with accounting and financial reporting teams as necessary.Maintain database integrity and accuracy.Collect, calculate and reconcile customer fees.Participates in and may coordinate aspects of systems to enhancement processes by collaborating with support teams.Interacts with customers to provide and process information in response to inquiries about their contractEducation Required: Bachelor Degree in Business or related disciplineExperience Required: At least 1 yearAbility to be organized and decisiveCritical thinking and analytical problem-solving skillsStrong customer service skillsExperience with MS OfficeExperience with SalesforceExperience with Power BI/ TableauExperience with SQLExperience with Alteryx

Come as You Are

Nasdaq is an equal opportunity employer. We positively encourage applications from suitably qualified and eligible candidates regardless of age, color, disability, national origin, ancestry, race, religion, gender, sexual orientation, gender identity and/or expression, veteran status, genetic information, or any other status protected by applicable law.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request an accommodation.

What We Offer

We‚Äôre proud to offer a competitive rewards package that is meaningful, recognizes the unique needs of our employees and their families and incentivizes employees for their contribution to Nasdaq‚Äôs overall success.

The base pay range for this role is $45,900 - $76,500. In addition to base salary, Nasdaq provides a generous annual bonus/commission (short-term incentive), and equity (long-term incentive), comprehensive benefits, and opportunity for growth. Exact compensation may vary based on several job-related factors that are unique to each candidate, including but not limited to: skill set, experience, education/training, business needs and market demands.

Nasdaq‚Äôs programs and rewards are intended to allow our employees to:

Secure Wealth: 401(k) program with 6% employer match, Employee Stock Purchase Program with 15% discount, Student loan repayment program up to $10k, Company paid life and disability plans, Generous paid time offPrioritize Health: Comprehensive medical, dental and vision coverage, Health spending account with employer contribution, Paid flex days to support mental wellbeing, Gym membership discountsCare for Family: Hybrid home/office schedule (for most positions), Paid parental leave, Fertility benefits, Paid bereavement leaveConnect with Community: Company gift matching program, Employee resource groups, Paid volunteer daysGrow Career: Education Assistance Program, Robust job skills training and Professional development opportunities

For more information, visit Nasdaq Benefits & Rewards Career page.","The Index Licensing Analyst will be responsible for managing user requirements, supporting client onboarding, and maintaining account relationships with both external customers and internal stakeholders. Key duties include financial and analytical tasks such as calculating and reconciling customer fees, maintaining database integrity, and generating reports. The role involves frequent customer outreach for reporting and inquiries, as well as coordinating with the billing and collections teams when necessary. Analysts will also support ad hoc internal requests, contribute to system improvement initiatives, and serve as a key liaison between clients and internal support teams.","Candidates should hold a bachelor’s degree in Business or a related field and have at least one year of relevant experience. Essential skills include strong organization, critical thinking, and customer service abilities. Proficiency in Microsoft Office is required, along with experience using Salesforce, Power BI or Tableau, SQL, and Alteryx. The role values individuals who are analytical, proactive, and able to manage multiple tasks effectively. Nasdaq offers a comprehensive benefits package, including competitive salary, bonuses, equity, and programs to support health, family, and professional development.","{' Microsoft Office': 'MISC', ' Power BI': 'MISC', ' SQL': 'MISC', ' Alteryx': 'MISC', ' Nasdaq': 'MISC'}"
61,TEKsystems,Data Analyst,"Description 

 Data Programmer Analyst 

We are seeking a skilled Data Programmer Analyst to join our team. The ideal candidate will have experience in SQL development, query building, data extraction, and other technical skills. As a Data Programmer Analyst, you will be responsible for analyzing and interpreting complex data sets, designing and implementing data solutions, and collaborating with cross-functional teams to drive data-driven decision-making.

 Responsibilities 

 Develop and optimize SQL queries for data extraction, transformation, and loading (ETL) processes. Collaborate with business stakeholders to understand data requirements and translate them into technical specifications. Design, develop, and maintain data pipelines and workflows. Perform data analysis to identify trends, patterns, and insights. Create and maintain documentation related to data processes and workflows. Troubleshoot and resolve data-related issues. Collaborate with data engineers, data scientists, and other team members to ensure data quality and accuracy. Stay up-to-date with industry trends and best practices in data management and analytics.


 Top Skills 

SQL Development Query development and extractionData Science Analysis and Reporting


 Additional Details 

3 month extendable contractHybrid in San Bernardino


 About TEKsystems 

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.","As a Data Programmer Analyst, you will play a critical role in designing, developing, and optimizing SQL queries and ETL processes to support data extraction, transformation, and loading needs. Your work will involve collaborating with business stakeholders to gather and understand data requirements, maintaining data pipelines and workflows, and performing data analysis to uncover insights and trends. You will also be responsible for creating and updating technical documentation, troubleshooting data-related issues, and ensuring data accuracy and quality in collaboration with data engineers and data scientists.","The ideal candidate will have strong experience in SQL development, data extraction, and query building, as well as a solid foundation in data science, analysis, and reporting. Attention to detail, problem-solving ability, and clear communication skills are essential. This is a 3-month extendable hybrid contract role based in San Bernardino. Staying current with industry trends in data management and analytics is encouraged. TEKsystems is an equal opportunity employer and values diversity and inclusion across its workforce.",{' SQL': 'MISC'}
62,TEKsystems,Data Scientist,"Top Skills' Details 

Passion for Machine Learning and Data Science and their fundamentals

Research and quantitative analysis of AI risk management

Development of data science algorithms using Python

Documentation

Would prefer someone who has a strong understanding or at least a passion for AI Risk Management.

 Description 

This is a Data Scientist role in Chat and Voice Technology team. The team builds next generation AI and Search platforms for the bank, enabling smart virtual assistants across multiple channels and platforms. This position requires candidate to be well versed with various machine learning algorithms and NLP techniques, including LLM and Generative AI techniques. Role offers an opportunity to work with seasoned architects, PhDs in Machine Learning and NLP, Software Engineers, and Risk Management partners. Candidate should be able to work independently and collaboratively to take ownership of prepare models for validation and monitoring. Candidate must possess passion for machine learning and data analysis, creatively solving how to assess risk, conduct and summarize research, and prepare technical white papers to support Machine Learning and Software Engineers through the model development lifecycle. This role is unique, in that candidate must be 100% AI Risk Management (50% Research and Quantitative Analysis, 25% Development, and 25% White Paper Documentation).

 Required Skills 

 Bachelor Degree in Computer Science, Data Science, Mathematics, or related field Knowledge of machine learning and related techniques Knowledge of recent developments in AI space including but not limited to transformers, LLMs, Generative AI Good understanding of a version control system like git to be able to efficiently collaborate with colleagues. Strong Python development skills and knowledge of Java/C++ Adept at leveraging ML/AI techniques to solve critical business problems with good understanding of Supervised, Unsupervised and Reinforcement Learning. Excellent interpersonal communication skills for tech, business, and risk conversations Good analytical skills to break down requirements, solve complex problems, and challenge the approach, build, and test of AI models and model components


 Skills 

Python, Data science, Data, java, Algorithm, risk management, artificial intelligence, Machine learning, Predictive modelling, Data analysis, Predictive analytics

 Top Skills Details 

Python, Data science, Data, java Algorithm, risk management, artificial intelligence

 Additional Skills & Qualifications 

There will be a heavy research and analysis component to this job, especially around risk management related to artificial intelligence and GenAI. They will be diving into an understanding of the biases of AI and the algorithms created by other data scientists on the team, how the data flows through the algorithm, and the risks associated to the outcomes. They'll be developing their own algos a smaller percentage of their time, but need to have a strong background in Python to be able to read the code of the 18 existing AI models and their architecture. They'll be spending a lot of time trying to break what exists and raising questions around why certain things were done that way. From a documentation perspective, they'll need to be able to create graphical representations of their findings so a lay person could understand them.

 About TEKsystems 

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.","This Data Scientist role supports the Chat and Voice Technology team focused on building AI and search platforms for smart virtual assistants. The position is unique in its focus on AI Risk Management, with about 50% of the role centered on research and quantitative analysis of AI/ML risks, 25% on algorithm development in Python, and 25% on preparing white papers and technical documentation. You'll analyze and assess the risk profiles of AI models—including LLMs and Generative AI—by deeply evaluating model behavior, algorithmic bias, and data flow through existing systems. This includes reviewing and challenging existing AI models, collaborating with engineering and risk teams, and translating findings into clear, visual, and layperson-friendly documentation.","A Bachelor’s degree in Computer Science, Data Science, Mathematics, or a related field is required. Ideal candidates will have strong skills in Python, Java or C++, and experience with machine learning techniques including supervised, unsupervised, and reinforcement learning. Familiarity with modern AI developments like transformers and generative models is essential. Applicants should demonstrate strong research capabilities, a passion for AI risk management, excellent problem-solving skills, and the ability to clearly communicate technical insights to both technical and non-technical stakeholders. Experience with Git, predictive modeling, and AI fairness/bias evaluation is a plus.","{' Python': 'MISC', ' Java': 'MISC', ' C++': 'MISC', ' Git': 'MISC'}"
63,Philips,Data Scientist,"Job Title
Clinical Adoption Data Scientist

Job Description

Clinical Adoption Data Scientist 
You will be responsible for working with clinical and technical experts to develop advanced reports on patient monitoring system usage, adoption and clinical impact for customers. These reports will contribute to the performance dashboard helping customers and Philips understand usage, adoption and achievement of desired outcomes in areas never measured previously. You will work with technical and clinical experts in order to understand and identify data signatures and sources needed for algorithm development and performance reporting. You will participate in various activities around clinical decision support, operational workflow improvement, and other healthcare-related applications, focusing on research, development, and evaluation of first-of-kind and prototypes for clinicians and other relevant partners, which will help make better and informed decisions, improving patient care, optimizing clinical and operational outcomes in clinical workflows.

Your role:
Measures how customers are using Philips technology through advanced data analytics on usage, adoption of workflows and achievement of outcomes by:
Defining data flows and schemaDefining clinical and technical analyticsWriting scripts and queriesCreating compelling, dynamic data visualizations
Collaborates with customers and Philips experts on advancing our digital understanding of customer usage and adoption of patient monitoring solutions.Reports on internal performance measures, including asset utilization, service and equipment costs, as well as volume and revenue to plan that are critical to profitability:
Identify data sources, interfaces and analyticsDefine inventory tracking methodology & market inventory management analytics
Identify data sources, interfaces and analytics
Publish customer scorecard internally
Develops new concepts, build proof-of-concept demonstrators and validate results with customer and field teams.Interacts with business partners and customers to understand their problems, share insights and validated practices.Identify gaps and data needs that limit successful measurements of the designed experienceCollaborate with other solution and functional teams (e.g., commercial operations, professional services, clinical education, financial administration) to find practical and ambitious solutions to these gaps and aspirations.Identify critical success metrics with which to gauge the relative performance and progress of our managed service customers over time.

You're the right fit if: 
You‚Äôve acquired 7+ programming, data visualization, and healthcare informatics experience as well as knowledge of physiologic monitoring systems.Your skills include database design, modeling and dynamic visualization, Proficiency with R and/or Python libraries commonly used in data science, Python programming experience, hospital data flows such as CPOE, EMR, RIS, LIS and PACS. Experience in related data format standards such as HL7, DICOM, FHIR and IHE, healthcare terms and classifications (SNOMED CT, ICD10); high affinity with applying new IT platforms/dash boarding software tools for reporting and experience.You have a Master‚Äôs Degree in Computer Sciences, Biomedical Engineering, Bioinformatics, or a related field OR 10 years of work experience, preferred.You must be able to successfully perform the following minimum Physical, Cognitive and Environmental job requirements with or without accommodation for this position.You also need to have the ability to work with cross-functional teams, be self-motivated, committing to results and be flexible and quick-learning. You also should have excellent verbal and written communication skills, ability to manage complex projects along with demonstrated operational analytics and financial analysis capabilities.

About Philips

We are a health technology company. We built our entire company around the belief that every human matters, and we won't stop until everybody everywhere has access to the quality healthcare that we all deserve. Do the work of your life to help improve the lives of others.

Learn more about our business.Discover our rich and exciting history.Learn more about our purpose.Read more about our employee benefits.

If you‚Äôre interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our commitment to diversity and inclusion here.

Additional Information

US work authorization is a precondition of employment. The company will not consider candidates who require sponsorship for a work-authorized visa, now or in the future.

Company relocation benefits will not be provided for this position. For this position, you must reside in or within commuting distance to the locations listed.

This requisition is expected to stay active for 45 days but may close earlier if a successful candidate is selected or business necessity dictates. Interested candidates are encouraged to apply as soon as possible to ensure consideration.

Philips is an Equal Employment and Opportunity Employer/Disabled/Veteran and maintains a drug-free workplace.","As a Clinical Adoption Data Scientist at Philips, you will analyze how healthcare providers use Philips patient monitoring systems to evaluate clinical adoption, workflow effectiveness, and outcome achievement. Your work will include developing advanced analytics, defining data schemas and flows, and creating dynamic data visualizations to support internal dashboards and customer-facing reports. You will collaborate with cross-functional teams and customers to identify relevant data sources, build and validate algorithms, and measure key performance indicators such as asset utilization, workflow adoption, and clinical impact. This role also involves developing proof-of-concept solutions and contributing to broader digital transformation efforts within healthcare environments.","The ideal candidate has at least 7 years of experience in programming, healthcare data analytics, and clinical informatics. A strong foundation in Python or R, data visualization, database modeling, and familiarity with healthcare data standards (e.g., HL7, DICOM, FHIR, SNOMED CT) is essential. You should have knowledge of hospital data systems like EMRs, PACS, and LIS, along with excellent communication skills and the ability to work on complex, cross-functional projects. A Master’s degree in Biomedical Engineering, Computer Science, or a related field is preferred, though 10 years of relevant experience may be considered in place of a degree. Candidates must be authorized to work in the U.S. without sponsorship.","{' Python': 'MISC', ' R': 'MISC'}"
64,ServiceNow,Data Engineer,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can‚Äôt wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.

With more than 7,700+ customers, we serve approximately 85% of the Fortune 500¬Æ, and we're proud to be one of FORTUNE 100 Best Companies to Work For¬Æ and World's Most Admired Companies‚Ñ¢.

Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.

Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

You will be part of the ServiceNow Cloud Services Big Data Team. The Big Data team is building the next-generation platform that collects, stores and provides real-time access to large amounts of data.

You will also build real-time analytic tools and reporting capabilities for various purposes including:

Monitoring, alerting and troubleshootingAnomaly detectionCapacity planningData analyticsETL Pipelines

What you get to do in this role:‚ÄØ‚ÄØ

Build the next-generation Observability platform in a big-scaleBuild high-quality, clean, scalable and reusable code by enforcing best practices around software engineering architecture and processes (Code Reviews, Unit testing, etc.)Design software that is simple and modular to use to allow other engineers to extend and customize the functionality to meet their specific needsDevelop data engineering components and applications and entities to empower self-serve for big data productsBe a mentor for colleagues and help promote knowledge-sharingTeam player with a proactive mindset 

Qualifications

To be successful in this role you have:

Bachelor‚Äôs degree or equivalent experience in Computer Science or related field 6+ years of experience with Java or a similar OO language6+ Experience with data structures, algorithms, object-oriented design, design patterns, SQL, and performance-scale considerations4+ years in building and maintaining ETL pipelines using Bigdata technologies like Spark Streaming, Spark SQL, MapReduce, Kafka and Hive/Impala and HadoopAbility to design complex systems with material & technical risk at a team levelEnjoy working in an agile, rapid development, and prototyping environment Driven towards writing, debugging, and improving existing code Ability to make decisions independently Exceptional debugging, testing, and problem-solving skills.Exceptional written and verbal communication skills with proven ability to effectively communicate complex technical issues to both technical and non-technical teams.

Preferred Qualifications:

Master's degree in Computer Science or related technical fields.Able to handle multiple competing priorities in a fast-paced environmentExperience with Kubernetes and dockerExperience in working with 3 pillars of Observability(metrics, logs and traces) in an enterprise, big-scale settingsProficiency in code and system health, diagnosis and resolution, and software test engineering.Experience in setting and configurating performance testing tools like Jmeter

GCS-23

For positions in California (outside of the Bay Area), we offer a base pay of $142,700 - $249,800, plus equity (when applicable), variable/incentive compensation and benefits. Sales positions generally offer a competitive On Target Earnings (OTE) incentive compensation structure. Please note that the base pay shown is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies and work location. We also offer health plans, including flexible spending accounts, a 401(k) Plan with company match, ESPP, matching donations, a flexible time away plan and family leave programs (subject to eligibility requirements). Compensation is based on the geographic location in which the role is located, and is subject to change based on work location. For individuals who will be working in the Bay Area, there is a pay enhancement for positions located in that geographical area; please contact your recruiter for additional information.

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.

At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.

If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.

For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.

Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.

From Fortune. ¬© 2022 Fortune Media IP Limited All rights reserved. Used under license.

Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","As a Big Data Engineer at ServiceNow, you will help build the next-generation observability platform to support real-time data analytics at scale. Your work will involve developing clean, scalable, and reusable code to power monitoring, alerting, anomaly detection, capacity planning, and ETL pipelines. You’ll collaborate cross-functionally to develop data engineering components and support self-service for big data products. The role emphasizes high-performance software development, data platform scalability, and mentorship, while encouraging proactive innovation in an agile, fast-paced environment.","Candidates should have a Bachelor’s degree in Computer Science or a related field (Master’s preferred) and 6+ years of experience in Java or similar object-oriented programming languages. A strong understanding of data structures, algorithms, SQL, and performance considerations is essential. Experience with big data technologies such as Spark, Kafka, Hive/Impala, and Hadoop is required, along with ETL pipeline development and observability tools (metrics, logs, traces). Knowledge of Kubernetes, Docker, and performance testing tools like JMeter is a plus. Strong communication skills and the ability to work independently or collaboratively in a high-speed development setting are key.","{' Java': 'MISC', ' SQL': 'MISC', ' Hadoop': 'MISC'}"
67,Creative Financial Staffing (CFS),Data Engineer,"Position: Database Administrator

Location: East Lansing, MI (Onsite)

A Privately Held Organization In The Financial Industry Located Near The East Lansing, MI Area Is Seeking a Full-time, Permanent Database Administrator To Be An Integral Part On Their Mortgage Technology Team! Here Are a Few Reasons Why You Should Apply

Outstanding culture with family-oriented feel, and technology department is valued.Competitive compensation and benefits package with $0 cost healthcare options.Located in a modern, high tech office building, along with fun areas and sweet treats.

Responsibilities Of The Database Administrator

Prioritize site reliability, security, and transparency.Methodically work to improve automation and tooling for all aspects of the SDLC including business analysis, prioritization, development, testing, deployment, change management, and provisioning of needed resources to support business departments, users, and customers.Participate in resolving production incidents when necessary.Work to identify and effectively communicate ideas for improvement.Troubleshoot user or system issues as assigned.

Preferred Experience Of The Database Administrator

Strong understanding of Microsoft SQL Server, including installation, configuration, and best practices.Ability to automate common Microsoft SQL Server administration tasks, including backups, integrity checks, statistic updates, index maintenance, and monitoring.Ability to make software design recommendations for application code that interacts with our database systems, especially when it comes to identifying and communicating advantages and tradeoffs associated with different design choices.Familiarity with the security model in Microsoft SQL Server, and a sense of ownership over the confidentiality, integrity, and availability of our data.

Benefits

Competitive Medical/Dental/Vision Insurance with $0 cost optionsRetirement Plan w/ match3.5 Weeks PTO, etc.

#INAPR2024","As a Database Administrator, you will play a key role in supporting the Mortgage Technology Team by ensuring the reliability, performance, and security of Microsoft SQL Server environments. Your tasks will include automating administrative processes such as backups, index maintenance, and integrity checks, as well as improving tooling and automation across the software development lifecycle (SDLC). You’ll also contribute to system issue resolution, production incident response, and proactively suggest improvements in database performance and development practices.","The ideal candidate has a strong understanding of Microsoft SQL Server installation, configuration, and best practices. Experience automating routine administrative tasks, working with SQL Server's security model, and offering guidance on application design related to database interactions is highly valued. A proactive mindset, strong troubleshooting skills, and a commitment to data integrity and availability are essential. This is a full-time, on-site role in a modern, high-tech office setting with a supportive and family-oriented culture. The organization offers competitive compensation, $0 cost healthcare options, generous PTO, and retirement plan matching.","{' Microsoft SQL Server': 'MISC', ' SQL Server': 'MISC'}"
68,Google,Data Scientist,"The application window will be open until at least April 12, 2024. This opportunity will remain online based on business needs which may be before or after the specified date.

Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Boulder, CO, USA; Atlanta, GA, USA.Minimum qualifications:

Bachelor's degree or equivalent practical experience.5 years of experience in operations management, strategy, planning, program management, and vendor management.5 years of experience in driving organizational change across various workflows, services, and teams.5 years of experience using analytics or applying project management tools to address business issues.

Preferred qualifications:

5 years of experience working in extended workforce management or related fields involving program and/or engagement management.2 years of experience in GenAI, Large Language Models (LLM‚Äôs), and Supervised Machine Learning.Experience with human in the loop data services for machine learning models.Ability to be proactive and think multiple steps ahead to anticipate what‚Äôs needed.Ability to influence executive-level cross-functional stakeholders and seamlessly resolving conflicts.Excellent communication skills.

About The Job

At gTech‚Äôs Users and Products team (gUP), our mission is to help users get the most out of Google. We represent Google's users and many of our partners globally, sharing insights with the larger Google organization to enable exceptional customer and product experiences.

gUP builds innovative solutions that take user experience and engagement with Google to the next level, supporting users across products, countries, cultures, incomes, and identities. We advocate for users through partnerships with product areas at Google (and some Alphabet businesses), supporting Google‚Äôs consumer products ecosystem and enabling numerous launches for Google‚Äôs consumer products each year.

The Machine Learning Data Operations (MLDO) team within gUP Operations is a newly created team that is responsible for delivering supervised machine learning and GenAI model tuning data operations for Google‚Äôs products. Working with an ecosystem of global vendors, the MLDO team delivers high quality data services that power Google‚Äôs products.

In this role, you will manage multiple vendors across the globe that support Google‚Äôs AI/ML initiatives. You will use your vendor management innovative thought process to recommend solutions that will help improve evolving workflows and prepare them for scaling. You'll also manage a portfolio of vendors that contribute to the long-term operational strategy and support model, seeking decisions, and operational excellence of business processes through continuous improvements. You will also help drive consistent and standard operating practices across all workflows to allow for scaling and repeatability.

Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life. Our teams of trusted advisors support customers globally. Our solutions are rooted in our technical skill, product expertise, and a thorough understanding of our customers‚Äô complex needs. Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.

To learn more about gTech, check out our video .

The US base salary range for this full-time position is $99,000-$145,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.

Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .

Responsibilities

Track vendor performance against key metrics (KPIs) and SLAs, such as on-time delivery, quality, and cost. Address performance issues promptly and collaborate with vendors to implement corrective actions.Lead and deliver regular business reviews and execute a robust vendor governance plan in the form of weekly, monthly, and quarterly reviews. Establish and nurture collaborative relationships with vendors to ensure open communication and proactive problem resolution.Partner with cross-functional teams to drive continuous vertical and horizontal process improvements at scale. Identify and program manage strategic projects to solve for challenging business issues by working with stakeholders, managing communications, and overseeing milestones and timelines.Provide efficient and effective escalation management in line with the established policies and procedures.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .","As a Vendor Program Manager on Google’s Machine Learning Data Operations (MLDO) team, you’ll oversee a portfolio of global vendors delivering supervised ML and GenAI data operations. You’ll track vendor performance across KPIs and SLAs such as delivery speed, quality, and cost, and lead regular business reviews and governance meetings to ensure alignment. The role also involves driving strategic process improvements, developing scalable workflows, and providing robust escalation management. By collaborating with cross-functional teams, you’ll support continuous improvement in AI/ML data services that power Google products and user experiences globally.","Candidates should have at least 5 years of experience in operations or vendor management, program strategy, and analytics, with proven experience driving organizational change across workflows. Preferred qualifications include experience in extended workforce management, knowledge of GenAI and Large Language Models (LLMs), and familiarity with human-in-the-loop data services. Strong analytical and project management skills, along with the ability to influence executive stakeholders and communicate effectively, are essential. A bachelor’s degree or equivalent practical experience is required. The role is based in Boulder, CO or Atlanta, GA, with a base salary range of $99,000–$145,000 plus bonus, equity, and benefits.","{' GenAI': 'MISC', 'LLMs': 'MISC'}"
69,Spectrum,Data Scientist,"Job Code: BDA303

Does using data science to solve business problems sound intriguing? Enjoy working collaboratively with diverse teams? Analytical, strategic and tech savvy? Then working within our Credit Services Team at Spectrum may be a great fit for you.

At Spectrum, we keep more than 32 million customers connected across our 41-state footprint. Our Credit Services Team uses advanced analytics and data science to develop credit solutions for our mobile and cable customers. Our customer-centric approach to finding solutions helps deliver the exceptional services and experiences Spectrum is known for.

BE PART OF THE CONNECTION

As a Data Scientist in the Credit Services department, you‚Äôll work in a fast-paced, collaborative environment to develop data-driven solutions to Charter‚Äôs business problems. You‚Äôll be empowered to think of new approaches, use analytical, statistical and programming skills to analyze and interpret data sets, and learn new skills while growing your career with Spectrum.

What Our Data Scientists Enjoy Most

Leveraging knowledge in analytical and statistical algorithms to assist stakeholders in improving their businessPartnering on the design and implementation of statistical data quality procedures for existing and new data sourcesCommunicating complex data science solutions, concepts, and analyses to team members and business leadersPresenting data insights & recommendations to key stakeholdersEstablishing links across existing data sources and finding new, interesting data correlationsEnsuring testing and validation are components of all analytics solutions

You‚Äôll work in a dynamic office environment. You‚Äôll excel in this role if you are a self-starter who can work independently as well as in a team. If you‚Äôre comfortable presenting data and findings in front of team members & stakeholders and have excellent problem-solving skills, this could be the role for you.

Required Qualifications

WHAT YOU‚ÄôLL BRING TO SPECTRUM

Experience: Data analytics experience: 3 years, programming experience: 2 yearsEducation: Bachelor‚Äôs degree in computer science, statistics, or operations research, or equivalent combination of education and experienceTechnical skills: Python, R, comprehensive SQL skill, Spark, HiveSkills: Experience with analytics and modeling on large datasets encompassing millions of records; Experience with the full model development and implementation cycle from ideation; Research, train and test models to model implementationAbilities: Perform in-depth & independent research and analysis; Experience using a data science toolkit such as Python or R, command of statistical techniques and machine learning algorithms; Ability to work with minimum supervision; Effective communication, verbal and written, relationship management, and customer service skills with a focus on working effectively in a team environmentTravel: As required (10%)

Preferred Qualifications

Education: Graduate degree in statistics, mathematics, analytics or operations researchExperience: Experience in working with large consumer data to discern consumer behaviors and risk profiles, ideally in telecommunication or banking industries.

SPECTRUM CONNECTS YOU TO MORE

Dynamic Growth: The growth of our industry and evolving technology powers our employees‚Äô careers as they move up or around the companyLearning Culture: We invest in your learning, and provide paid training and coaching to help you succeedSupportive Teams: Be part of a strong community that gives you opportunities to network and grow, and wants to see you succeed Total Rewards: See all the ways we invest in you‚Äîat work and in life

Apply now, connect a friend to this opportunity or sign up for job alerts!

BDA303 2023-25170 2023

Here, employees don‚Äôt just have jobs, they build careers. That‚Äôs why we believe in offering a comprehensive pay and benefits package that rewards employees for their contributions to our success, supports all aspects of their well-being, and delivers real value at every stage of life.

A qualified applicant‚Äôs criminal history, if any, will be considered in a manner consistent with applicable laws, including local ordinances.

Get to Know Us Charter Communications is known in the United States by our Spectrum brands, including: Spectrum Internet¬Æ, TV, Mobile and Voice, Spectrum Networks, Spectrum Enterprise and Spectrum Reach. When you join us, you‚Äôre joining a strong community of more than 101,000 individuals working together to serve more than 32 million customers in 41 states and keep them connected to what matters most. Watch this video to learn more.

Who You Are Matters Here We‚Äôre committed to growing a workforce that reflects our communities, and providing equal opportunities for employment and advancement. EOE, including disability/vets. Learn about our inclusive culture.","As a Data Scientist on Spectrum’s Credit Services team, you will develop and implement data-driven solutions to support credit decisioning for cable and mobile customers. You’ll use your skills in Python, R, SQL, Spark, and Hive to perform advanced analytics and statistical modeling on large datasets. Key duties include designing model testing and validation procedures, building and refining machine learning models, identifying key data correlations, and communicating insights and recommendations to business stakeholders. You will also play a crucial role in improving data quality and developing scalable solutions that directly impact customer experiences and business outcomes.","Candidates should have at least 3 years of data analytics experience and 2 years of programming experience, along with a bachelor’s degree in computer science, statistics, or a related field (a graduate degree is preferred). Technical proficiency in Python, R, SQL, and big data tools like Spark and Hive is essential. The ideal candidate will also have experience working with large-scale consumer data, preferably in telecom or finance, and be skilled in model development, implementation, and communication of insights. This role requires strong problem-solving abilities, the ability to work independently, and excellent collaboration and presentation skills. Occasional travel (up to 10%) may be required.","{' Python': 'MISC', ' R': 'MISC', ' SQL': 'MISC', ' Spark': 'MISC', ' Hive': 'MISC'}"
70,Pinecone,Data Scientist,"About Pinecone

Pinecone is on a mission to build the search and database technology to power AI applications for the next decade and beyond. Our fully managed vector database makes it easy to add vector search to AI applications. Since creating the ‚Äúvector database‚Äù category, demand has grown incredibly fast and it shows in our user base. We are a distributed team with clusters in New York, San Francisco, Tel-Aviv, and Manchester.

About The Role

Pinecone is seeking a skilled and highly motivated data science intern to join our Data Engineering team in 2024. As part of the Data Engineering organization you will collaborate with cross-functional teams to develop and deliver conversion funnel metrics, cohort and segment analysis, and user and workload classifications to help understand our user base and how they use Pinecone to inform and evaluate Product development and launches.

In This Role, You Will

Partner with product, engineering and design to drive insights, identify opportunities, and understand user behavior and trendsThoroughly analyze and interpret data to identify patterns and generate insights.Define and monitor key metrics through tracking KPIs and dashboardsSupervise model performance and find opportunities for improvement.Collaborate with multi-functional teams to translate insights into actionable solutions.Write clear and concise documentation of your work.

Required Qualifications & Skills

Working towards a Bachelors, Masters, or PhD degree in a technical field of study in Data Science, Engineering, Computer Science, Computer Engineering, Management Information Systems, or ITEnrolled in an accredited college/university with an anticipated graduation date in Winter 2024 or Spring 2025Strong data manipulation skills required including cleaning and handling dataProgramming proficiency in Python and SQLExperience with distributed computing frameworkExcellent communication and storytelling skills. You like to share and communicate your findings through writing or visualizations.","As a Data Science Intern on Pinecone’s Data Engineering team, you will collaborate with product, engineering, and design teams to analyze user behavior and drive product insights. You’ll develop key performance indicators (KPIs), monitor conversion funnels, perform cohort and segment analysis, and classify user workloads to help inform product strategy. Your work will include interpreting complex datasets, visualizing trends, tracking model performance, and providing actionable insights. Additionally, you’ll document your findings and contribute to data-driven product development efforts.","This internship is ideal for students pursuing a Bachelor's, Master's, or PhD in Data Science, Computer Science, Engineering, MIS, or related fields, with a graduation date in Winter 2024 or Spring 2025. Strong data manipulation and analysis skills are essential, along with proficiency in Python and SQL. Experience with distributed computing frameworks and a passion for storytelling through data visualizations and written reports are highly valued. Excellent communication skills and the ability to turn data into actionable insights are key to success in this role.","{' Python': 'MISC', ' SQL': 'MISC'}"
72,Piper Companies,Data Engineer,"Piper Companies is currently searching for an Azure Cloud Database Developer to work 100% remotely for a leader in providing premier support to defense and civilian government agencies across the United States. The Azure Cloud Database Developer will support various database administration tasks, including SQL databases, Databricks, Data Lakes, and advanced data scripting.

Responsibilities for the Azure Cloud Database Developer include:

 Collaborate with a team to strategize and implement new data storage solutions Conduct regular backups and restores Manage database security protocols and procedures Implement security measures, roles, users, and privileges following industry best practices Design scalable and efficient database schemas/models, and enhance existing data models as per application needs Develop databases (scaling/indexing management), schemas, tables, complex views, stored procedures, data sharing, and ETL processes Thoroughly document existing and new database designs

Required Qualifications for the Azure Cloud Database Developer include:

 Bachelor's degree in Computer Science, Information Systems, Engineering, Business, or related field 8-12+ years of relevant database administration experience Proficiency in Microsoft Azure SQL, complex query skills, and SQL Server Management Studio (SSMS) Experience in managing Cloud Database solutions and data Strong familiarity with Object-relational mapping and T-SQL Some exposure to Python preferred; willingness to learn new technologies/languages for data processing/storage is essential

Compensation for the Azure Cloud Database Developer include:

 $90,000 - $105,000 Base Salary *depending on experience* Full Medical, Dental, Vision, PTO, Paid Holidays, Sick time, 401K and much more

SECURITY CLEARANCE REQUIREMENTS: May be required to obtain a Public Trust clearance upon hire.","As an Analytics Intern, you will contribute to real-world business decisions by analyzing complex datasets, building data visualizations, and uncovering key insights. Your role will involve preparing messy datasets for analysis, creating interactive dashboards, and performing exploratory data analysis to identify trends and anomalies. You’ll work closely with team members to QA analytics work, document data concepts, and present your findings to stakeholders in a clear and compelling way. This internship is a hands-on opportunity to learn how data drives strategy across a fast-paced, dynamic organization.","Ideal candidates will have a strong foundation in mathematics, statistics, or computer science, and must be comfortable working with SQL and understanding basic data structures. Familiarity with Python is a plus. You should thrive in an entrepreneurial environment, be adaptable to changing priorities, and capable of making assumptions and drawing conclusions from incomplete information. Strong communication skills and the ability to present analytical findings to non-technical stakeholders are essential for success in this role.","{' SQL': 'MISC', ' Python': 'MISC'}"
73,UPMC,Data Analyst,"The Youth and Family Research Program (Youth and Family Research Program | University of Pittsburgh) seeks to be an inclusive, affirming, and safe space for all staff and participants. We value diversity and are committed to rectifying longstanding inequities with research and academia. We conduct high quality research with the goal of reducing health inequities in substance use problems. Within this context, we examine systemic racism and discrimination experiences in conjunction with individual factors that may contribute to substance use risk. The Research Specialist will be involved in novel research through interacting with participants during semi-structured diagnostic interviews, lab-based tasks and questionnaires, and during a smartphone-based portion of the study. This individual will be part of a collaborative research team and will attend lab meetings, collaborate with multiple faculty members, and have opportunities to grow research skills and interests.

This position is grant funded.

Responsibilities:

Conducts neurocognitive evaluations and collects other information from participants as required. Retrieves current and retrospective data on an ongoing basis, for assigned studies. Assists research personnel in collecting and verifying information related to protocol management. Responsible for maintaining research records. Enters data into the database as designated per research study. Performs in accordance with system-wide competencies/behaviors. Performs other duties as assigned. High school diploma or equivalent required. Education in health care or related field 

OR 

two years of experience in health care or related field. Microsoft Office skills and knowledge of medical terminology preferred. 

Licensure, Certifications, and Clearances:

Act 31 Child Abuse Reporting with renewalAct 33 with renewalAct 34 with renewalAct 73 FBI Clearance with renewal

UPMC is an Equal Opportunity Employer/Disability/Veteran

Annual","As a Research Specialist, you will support a grant-funded project focused on reducing health inequities related to substance use by conducting neurocognitive assessments, administering diagnostic interviews, lab tasks, questionnaires, and assisting with smartphone-based study components. You’ll collaborate closely with a multidisciplinary team, contribute to data collection and management, enter data into research databases, maintain accurate records, and attend lab meetings. The role offers hands-on experience in behavioral health research and opportunities for skill development in a collaborative, inclusive research environment.","Applicants must have a high school diploma or equivalent, with either additional education in a healthcare or related field or at least two years of relevant experience. Familiarity with Microsoft Office and medical terminology is preferred. Candidates must obtain and maintain several clearances including Act 31 (Child Abuse Reporting), Act 33, Act 34, and Act 73 (FBI). The ideal candidate is organized, detail-oriented, and comfortable interacting with study participants from diverse backgrounds in both clinical and research settings.","{' Microsoft Office': 'MISC', ' Act 31': 'MISC', 'Child Abuse Reporting': 'MISC', ' Act 73': 'MISC'}"
74,Valor Equity Partners,Data Scientist,"Job Title: Data Scientist/Machine Learning Engineer (Associate)Department: Valor LabsWork Location: ChicagoReports To: Head of Labs
Who We Are:Valor Equity Partners is a different kind of private investment firm. We invest in technology and technology-enabled companies that innovate and disrupt existing industries ‚Äî from biosciences to transportation to food to health and wellness.Our mission is to invest in and work side by side with companies that make the world a better place. These companies include SpaceX, Anduril, GoPuff, HackerOne, Cloud9, and others. We‚Äôve had the honor of serving some of the world‚Äôs greatest entrepreneurs and companies.Our values are core to all we do. These values are excellence, humility, integrity, and responsibility.
Valor means that we:Strive for excellence in everything we do;Maintain our humility and mutual respect no matter what circumstances we encounter;Insist upon the highest level of integrity in our interactions and in the logic of our investment process; andDemonstrate responsibility and dedication to all of our constituents.
About the Team:Labs is an internal team at Valor that builds software to support the Firm‚Äôs investment process. It comprises software, data, and machine learning engineers as well as data scientists with diverse backgrounds and levels of experience. The team‚Äôs mission is to build cutting edge software applications and data models that generate proprietary investment insights and provide the investment team with tools that augment the investment decision making process.
About the Role:Develop features and machine learning models that augment the Firm‚Äôs investment decision making processWork collaboratively with machine learning engineers and software engineers to build, deploy, monitor, and maintain machine learning modelsWork collaboratively with team members to promote technical rigor and adopt best practicesCollaborate with data scientists, engineers, and other stakeholders in translating project requirements into technical specificationsYou will help shape the future of software engineering at Valor by bringing your ideas on improving and automating what we do and how we do it
We‚Äôre excited about candidates that have:B.S. and/or M.S. in Computer Science, Applied Mathematics, Statistics, or related field, especially with coursework in machine learning2+ years of machine learning, data science, and/or statistical modeling experience, with significant contributions that you can talk toExceptional coding skills in Python and SQL, to include common Python libraries like Pandas, Scikit-Learn, PyTorch, and/or TensorFlowExperience with any of the following:Time-series modelingGraph-based modelingSupervised learning, especially boosted tree algorithms such as XGBoost and LightGBMNatural Language Processing (incl. LLMs)
Additionally, experience with any of the following is a bonus:Experience with deploying and monitoring machine learning modelsExperience with Docker and GPU-based infrastructureExperience with modern cloud platforms (AWS, Azure, or GCP)Modern data pipeline experienceBig Data processing (Spark, PySpark, Scala, Dask)Passion for machine learning while being mission-driven, hard-working, humble, intellectually curious, and most importantly, great team playersBias for execution and delivery. You know that what matters is delivering software that works every timeAbility to assist in system design and the generation of key technical assumptions while encouraging solutions that respect existing infrastructureWillingness to be resourceful, flexible, and adaptable; no task is too big or too small
Our Tech Stack:Frontend: React with Hooks, Material UIBackend: Python, Fast APITooling: Google Cloud PlatformData: PostgreSQL, Firestore, BigQuery, Elastic Search, Prefect, Kafka, Scala, Spark, dbt","As a Data Scientist/Machine Learning Engineer at Valor Labs, you will develop machine learning models and features that directly support and enhance the firm's investment decision-making process. You'll collaborate with a multidisciplinary team of data scientists, software engineers, and ML engineers to build, deploy, and maintain scalable models and analytical tools. Your work will involve translating business and technical requirements into well-documented, production-ready solutions. You'll also play a role in shaping Valor’s software and ML infrastructure by promoting best practices, technical rigor, and automation in workflows.","Candidates should have a Bachelor’s or Master’s degree in Computer Science, Statistics, Applied Mathematics, or a related field, along with 2+ years of hands-on experience in machine learning, data science, or statistical modeling. Strong coding skills in Python and SQL are essential, along with experience in libraries like Pandas, Scikit-Learn, PyTorch, or TensorFlow. Familiarity with time-series modeling, graph-based modeling, NLP, and algorithms like XGBoost/LightGBM is highly desirable. Experience with deploying ML models, cloud platforms (GCP/AWS/Azure), containerization (Docker), and big data tools (Spark, PySpark, dbt) is a plus. The ideal candidate is intellectually curious, mission-driven, and thrives in a collaborative, fast-paced environment.","{' Python': 'MISC', ' SQL': 'MISC', ' Pandas': 'MISC', ' Scikit-Learn': 'MISC', ' PyTorch': 'MISC', ' TensorFlow': 'MISC', ' XGBoost/LightGBM': 'MISC', 'Spark': 'MISC', ' PySpark': 'MISC', ' dbt': 'MISC'}"
75,St. Peter's Health Partners,Data Analyst,"Employment Type

Full time

Shift

Day Shift

Description

Quality Data Payer Specialist - Rensselaer - FT/DAY

Under the direction of the Director of Quality, coordinates and implements performance analysis and reporting for Senior Leadership, Clinicians and Administrators in support of Quality Improvement Initiatives. Specific focus on optimizing performance contract with multiple payers.

Implements data collection and reporting strategies for evaluation of key quality performance initiatives, quality metrics, outcomes evaluation, etc. for quality improvement.Interfaces data from external facilities/organization for reporting purposes; develops and analyzes systems and support tools needed to obtain information or statistics vital to quality improvement efforts.Investigates data quality problems and reporting issues with recommended solutionsDelivers reports and owns various Quality metrics dashboards/scoreboards.Manually and electronically provide EMR data in support of contractual and incentive programs.Collaborates with clinical and IT staff to support defined business requirements.Works with external Business Partners (i.e. Payers, ACO, CMS) to facilitate receipt and delivery of quality data.Analyzes data and prepares data trend reports.Identifies gap areas and coordinates follow-up activity.Maintains consistency and integrity of data collection and storage.Educate/Train Physician and staff on Quality Measure definition and workflow.Bachelor's Degree in Basic Sciences or related field or equivalent work experience.Minimum of five (5) years progressively responsible related work experience, including knowledge of payer operations and quality programs, research methods, basic statistics, business intelligence applications, and data analysis. Payer Experience and Ambulatory Quality Experience preferredExcellent analytical abilities and good problem-solving skills, required.Exceptional computer skills required, specifically reporting metricsProficiency with Microsoft Office suite, including strong Excel skills.Strong verbal and written communication skills, requiredClinical/Healthcare experience, preferred.EMR and Billing/Claims familiarity, preferred, EPIC familiarity a plusDetail oriented, excellent follow-upAbility to multi-task in a fast paced environmentMust be service oriented, quick learner, team player

Pay Range:$22.40 - $35.84

Pay is based on experience, skills, and education. Exempt positions under the Fair Labor Standards Act (FLSA) will be paid within the base salary e

Our Commitment to Diversity and Inclusion

Trinity Health is one of the largest not-for-profit, Catholic healthcare systems in the nation. Built on the foundation of our Mission and Core Values, we integrate diversity, equity, and inclusion in all that we do. Our colleagues have different lived experiences, customs, abilities, and talents. Together, we become our best selves. A diverse and inclusive workforce provides the most accessible and equitable care for those we serve. Trinity Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other status protected by law.

00504404","The Quality Data Payer Specialist is responsible for coordinating and implementing data analysis and reporting to support quality improvement initiatives, particularly in relation to payer performance contracts. Key tasks include collecting, analyzing, and reporting quality metrics; managing dashboards and scoreboards; resolving data issues; and working closely with clinical teams, IT staff, and external partners such as payers, ACOs, and CMS. The role also involves identifying performance gaps, supporting EMR data submissions for incentive programs, and training staff on quality measure workflows.","Candidates should have a Bachelor’s degree in a science or related field or equivalent work experience, along with a minimum of 5 years in a relevant role involving data analysis and payer operations. Strong analytical skills, proficiency in Microsoft Excel, and familiarity with EMR systems (especially EPIC) are essential. Experience with billing/claims, quality reporting programs, and healthcare settings is preferred. Excellent communication, attention to detail, multitasking ability, and a collaborative, service-oriented mindset are also key for success in this role. The pay range is $22.40–$35.84/hour, depending on experience and education.","{' Microsoft Excel': 'MISC', ' EMR': 'MISC', ' EPIC': 'MISC'}"
76,Trinity Health,Data Analyst,"Employment Type

Full time

Shift

Day Shift

Description

Quality Data Payer Specialist - Rensselaer - FT/DAY

Under the direction of the Director of Quality, coordinates and implements performance analysis and reporting for Senior Leadership, Clinicians and Administrators in support of Quality Improvement Initiatives. Specific focus on optimizing performance contract with multiple payers.

Implements data collection and reporting strategies for evaluation of key quality performance initiatives, quality metrics, outcomes evaluation, etc. for quality improvement.Interfaces data from external facilities/organization for reporting purposes; develops and analyzes systems and support tools needed to obtain information or statistics vital to quality improvement efforts.Investigates data quality problems and reporting issues with recommended solutionsDelivers reports and owns various Quality metrics dashboards/scoreboards.Manually and electronically provide EMR data in support of contractual and incentive programs.Collaborates with clinical and IT staff to support defined business requirements.Works with external Business Partners (i.e. Payers, ACO, CMS) to facilitate receipt and delivery of quality data.Analyzes data and prepares data trend reports.Identifies gap areas and coordinates follow-up activity.Maintains consistency and integrity of data collection and storage.Educate/Train Physician and staff on Quality Measure definition and workflow.Bachelor's Degree in Basic Sciences or related field or equivalent work experience.Minimum of five (5) years progressively responsible related work experience, including knowledge of payer operations and quality programs, research methods, basic statistics, business intelligence applications, and data analysis. Payer Experience and Ambulatory Quality Experience preferredExcellent analytical abilities and good problem-solving skills, required.Exceptional computer skills required, specifically reporting metricsProficiency with Microsoft Office suite, including strong Excel skills.Strong verbal and written communication skills, requiredClinical/Healthcare experience, preferred.EMR and Billing/Claims familiarity, preferred, EPIC familiarity a plusDetail oriented, excellent follow-upAbility to multi-task in a fast paced environmentMust be service oriented, quick learner, team player

Pay Range:$22.40 - $35.84

Pay is based on experience, skills, and education. Exempt positions under the Fair Labor Standards Act (FLSA) will be paid within the base salary e

Our Commitment to Diversity and Inclusion

Trinity Health is one of the largest not-for-profit, Catholic healthcare systems in the nation. Built on the foundation of our Mission and Core Values, we integrate diversity, equity, and inclusion in all that we do. Our colleagues have different lived experiences, customs, abilities, and talents. Together, we become our best selves. A diverse and inclusive workforce provides the most accessible and equitable care for those we serve. Trinity Health is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other status protected by law.

00504404","The Quality Data Payer Specialist plays a critical role in supporting Quality Improvement Initiatives by analyzing and reporting on performance metrics related to payer contracts. Working under the Director of Quality, the specialist is responsible for data collection, dashboard reporting, EMR data management, and identifying performance gaps. They collaborate with clinical teams, IT, and external partners such as payers, ACOs, and CMS to ensure accurate and timely delivery of quality data. Additional tasks include trend analysis, system integration, documentation, and staff training on quality measure workflows and data standards.","Candidates should have a bachelor’s degree in a related field (or equivalent experience) and at least five years of relevant experience, particularly involving payer operations, data analytics, and quality programs. Strong skills in Microsoft Excel, statistical analysis, and business intelligence applications are essential. Preferred qualifications include healthcare or clinical background, experience with EMR and billing systems (especially EPIC), and the ability to multitask in a fast-paced environment. The role requires excellent problem-solving, follow-up, and communication skills. The pay range is $22.40–$35.84 per hour, based on experience and qualifications.","{' Microsoft Excel': 'MISC', ' EPIC': 'MISC'}"
78,myGwork - LGBTQ+ Business Community,Data Scientist,"This inclusive employer is a member of myGwork ‚Äì the largest global platform for the LGBTQ+ business community.  

Join the team that conducts impactful economic research utilizing big data for the public good.

As a Data Science Research Associate within the JPMorgan Chase Institute you will conduct economic research under the guidance of a Research Lead using proprietary big data from within JPMorgan Chase.

Job Responsibilities

Work alongside other researchers, PhD fellows, academic advisors, and internal thought-leaders to create cutting-edge analyses, using large data sets of de-identified banking records alone or in combination with existing publicly available data that add to both the public and academic discourse. Work with large data sets using big data programming languages on a public cloud platform and produce statistical and visual analytics.Gain and apply topic-specific knowledge in areas such as consumer finance, small businesses, middle market businesses, housing finance, and financial markets.Communicate analytical insights and be directly involved in the research process.Perform literature reviews, edit and draft reports and other research materials.

Required Qualifications, Capabilities, And Skills

Bachelor‚Äôs degree required in statistics, economics, public policy, data science, or other related fields.Experience working with big data sets and strong programming experience with Python, Scala, and/or SQL and experience in statistical languages (R, SAS, Stata).Ability to translate economic research into implications for policy makers and other decision makers. Strong sense of intellectual curiosity and desire to be directly involved in the public-oriented mission of the Institute.Capacity to work in a high-performance professional environment, with quick turn-around and changing priorities.Commitment to intellectual rigor and observance of compliance and data privacy controls.

Preferred Qualifications, Capabilities, And Skills

Experience with big data computing on a public cloud platform (e.g. Spark, AWS) is a plus. Experience working with technical collaboration tools (Git, Jira) is a plus.Prior experience working with financial services or other administrative data sets is a plus.","As a Data Science Research Associate, you will conduct impactful economic research using JPMorgan Chase’s proprietary, de-identified big data to contribute to public and academic discourse. You’ll collaborate with a multidisciplinary team—including PhD fellows and academic advisors—to perform statistical and visual analyses, combining internal data with public sources. Your responsibilities will include managing large datasets on public cloud platforms, conducting literature reviews, contributing to report writing, and helping translate complex economic findings into actionable insights for policymakers and thought leaders.","Candidates should have a Bachelor’s degree in economics, statistics, public policy, data science, or a related field, with strong programming skills in Python, SQL, or Scala, and experience with statistical tools like R, SAS, or Stata. A demonstrated ability to work with big data and communicate analytical insights in a policy-relevant context is essential. Experience with public cloud platforms (e.g., AWS, Spark), version control (e.g., Git), and financial or administrative datasets is preferred. Candidates must be intellectually curious, adaptable to fast-paced environments, and committed to data privacy and compliance standards.","{' Python': 'MISC', ' SQL': 'MISC', ' Scala': 'MISC', ' R': 'MISC', ' AWS': 'ORG', ' Spark': 'ORG'}"
80,Infocepts Inc,Data Analyst,"Job Description: Data Analyst (OPT/CPT Candidates with Visa Sponsorship)Experience: Minimum 2-3 years of relevant experienceEmployment Type: W2/1099 position with visa sponsorship provided for successful candidates
Responsibilities:Collect, clean, and analyze large datasets to extract meaningful insightsCollaborate with various teams to understand data requirements and objectivesDevelop and maintain data models, dashboards, and reports to support business decision-makingIdentify trends, patterns, and anomalies in data to inform strategic initiativesUtilize statistical techniques and predictive modeling to drive data-driven solutionsCommunicate findings and recommendations to stakeholders through visualizations and presentationsAssist in the design and implementation of data collection processes and toolsConduct quality assurance checks to ensure data accuracy and integrityStay up-to-date with industry trends and best practices in data analysis and visualization
Qualifications:Bachelor's or Master's degree in Data Science, Statistics, Mathematics, Computer Science, or related fieldProficiency in SQL, Python, R, or other programming languages used for data analysisExperience with data visualization tools such as Tableau, Power BI, or matplotlibStrong analytical and problem-solving skills with a keen attention to detailExcellent communication and collaboration abilities to work effectively with cross-functional teamsFamiliarity with machine learning algorithms and techniques is a plusAbility to work independently and manage multiple priorities in a fast-paced environmentUnderstanding of data governance and privacy regulations","As a Data Analyst, you will be responsible for collecting, cleaning, and analyzing large datasets to derive actionable insights that support strategic business decisions. You’ll collaborate with cross-functional teams to understand data needs, build and maintain reports, dashboards, and data models, and communicate findings clearly through visualizations and presentations. Additional responsibilities include identifying data trends, performing quality checks for accuracy, and applying statistical techniques or predictive models to develop data-driven solutions. You'll also assist in designing data collection tools and stay updated with industry best practices in analytics.","Candidates should have a Bachelor’s or Master’s degree in Data Science, Statistics, Computer Science, or a related field, with 2–3 years of relevant experience. Proficiency in SQL, Python, R, and data visualization tools such as Tableau or Power BI is essential. Strong analytical, problem-solving, and communication skills are required, along with the ability to work independently in a fast-paced environment. Familiarity with machine learning techniques and an understanding of data governance or privacy standards are advantageous. This is a W2/1099 opportunity offering visa sponsorship for OPT/CPT candidates.","{' SQL': 'MISC', ' Python': 'MISC', ' R': 'MISC', ' Power BI': 'MISC', ' W2/1099': 'MISC', ' OPT': 'MISC'}"
81,StepStone Group,Data Scientist,"StepStone is a rapidly growing Global Private Markets firm who provides customized investment and advisory solutions to some of the most sophisticated investors in the world. With $640 billion of total capital allocations, including $143 billion in AUM, we are highly diversified in the private markets across the globe and provide creative solutions to solve for the objectives of any investment program. With a culture built on entrepreneurialism, partnership and being a team within teams, our firm offers joiners the opportunity to think out loud, collaboratively.

Position Overview

The Data Science Intern will work as part of the Private Wealth team and is expected to perform the fundamental core responsibilities described below. The Data Science intern will work within the Global CRM team and closely with members of the Business Development team, other Private Wealth members, and all relevant departments to support data initiatives.

Responsibilities

Handle reporting requirements for the Business Development Team, including gathering requirements, creating report templates, and routinely updating reportsApply analytical skills and knowledge to solve real-world problems, extract meaningful insights from complex data sets, and contribute to the development of data-driven outcomesMaintain data hygiene by creating, updating and deleting records in applicable systemsAnalyze reports to draw meaningful conclusions, highlight trends, extract insights to support decision-makingAssist in process standardization and automationDevelop and implement statistical models and machine learning algorithmsPrepare and present reports and visualizations to communicate findings and recommendations to both technical and non-technical stakeholdersIdentify and investigate issues or inconsistencies with dataStay abreast of industry trends and advancements in data science and analytics


Qualifications

Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, ITStrong foundation in statistical analysis, machine learning, and data modelingProficiency in programming languages such as Python and experience with Python LibrariesExperience in Python programming and understanding of the software development life cycleAdvanced proficiency in Microsoft Excel for data analysis and reporting


Core Competencies

Strong analytical and problem-solving skills, with clear attention to detailStrong communication and collaboration skillsDetail-oriented with a commitment to data accuracy and integrityAbility to work independently with minimal supervisionAbility to prioritize and work under tight deadlinesFast learner, able to master new concepts, theories, ideas, and processes with easeHighly motivated, self-learner, and technically inquisitiveAdjusts plans, expectations, and/or processes to meet changing needs of key stakeholders Highly motivated individual with demonstrated initiative, independence, professionalism and adaptabilityWell organized, good time management skills, and prioritizes appropriatelyEffectively work in teams; teams orientedMaintains a positive attitude, strong work ethic, and treats others with respectStrong ability to multi‚Äêtask and manage time in a detail‚Äêoriented environment


About Us

Click here to learn more about the intern experience.

Working out of 26 offices in 15 countries, StepStone has a truly global viewpoint. As people are our biggest asset, we offer resources to help our employees reach their full potential. Our principles are based on integrity, transparency, respect and creativity, which together define how we do business.

Join us

When you choose to work at StepStone, you'll find a group of professionals who are passionate about anticipating changes, solving problems and working together to make it all happen. Our integrated global team shares insights into how managers think and operate, as well as how they might perform.

StepStone offers a competitive compensation package including salary and incentive compensation for all full time hires, as well as a comprehensive benefits package.

Benefits

We offer a range of benefits which include comprehensive healthcare, strong retirement plan, a mental health well-being program, paid time off, student loan repayment program for our US office locations, and several wellness initiatives.

Disclaimer / Policy Statements

At StepStone, diversity, equity and inclusion are an integral part of our culture. We are an Equal Opportunity Employer that strives to create an inclusive environment that empowers our employees and allows them to be heard, regardless of title or tenure. Our organizational community features multiple Employment Resource Groups representing our dedication to Diversity, Equity & Inclusion. 

As an Equal Opportunity Employer, StepStone does not discriminate on the basis of race, creed, color, religion, sex, national origin, citizenship status, age, disability, marital status, sexual orientation, gender identity, gender expression, genetic information or any other characteristic protected by law.

Developing People at StepStone","The Data Science Intern will support StepStone’s Private Wealth and Global CRM teams by providing key analytical and reporting functions. Core responsibilities include gathering business requirements, developing and maintaining reports, analyzing data to identify trends, and helping standardize and automate internal processes. The intern will apply statistical models and machine learning algorithms to real-world datasets, maintain data quality and hygiene, and present insights in clear, visual formats to both technical and non-technical stakeholders. This position also requires collaboration across various departments to support broader data-driven initiatives.","Applicants should be pursuing or have completed a bachelor’s or master’s degree in Computer Science, Engineering, Information Systems, or a related field. A strong foundation in statistical analysis, data modeling, and machine learning is required, as well as proficiency in Python and experience with Python libraries. Advanced Excel skills are also essential. Ideal candidates are analytical, detail-oriented, strong communicators, and capable of working independently in a deadline-driven environment. A curiosity for data science, problem-solving mindset, and the ability to quickly learn new tools or concepts will ensure success in this internship.","{' Python': 'MISC', ' Excel': 'MISC'}"
82,EXL,Data Engineer,"Hi,
We have urgent requirements for our direct client, please go through the below Job Description. If you are interested please send me your updated word format resume to sudi.reddy@exlservice.com and reach me @ 520-231-4672.
 Title: GCP Data EngineerLocation: Hartford, CTDuration: Full Time
6-8 Years of experience in data extraction and creating data pipeline workflows on Bigdata (Hive, HQL/PySpark) with knowledge of Data Engineering concepts.Experience in analyzing large data sets from multiple data sources, perform validation of data.Knowledge of Hadoop eco-system components like HDFS, Spark, Hive, Sqoop.Experience writing codes in Python.Knowledge of SQL/HQL to write optimized queries.Hands on with GCP Cloud Services such as Big Query, Airflow DAG, Dataflow, Beam etc.","The GCP Data Engineer will be responsible for designing, building, and maintaining scalable data pipelines to support data extraction, transformation, and loading (ETL) across large datasets. This includes analyzing complex data from various sources, validating data integrity, and optimizing performance using tools and languages such as Hive, HQL, and PySpark. The role also involves creating workflows and developing solutions using GCP cloud services such as BigQuery, Dataflow, and Airflow, while leveraging frameworks like Apache Beam for stream and batch data processing.","The ideal candidate should have 6–8 years of experience in big data engineering with a solid understanding of Hadoop ecosystem components (HDFS, Hive, Spark, Sqoop), strong Python programming skills, and advanced SQL/HQL abilities for querying and data manipulation. Practical experience with Google Cloud Platform (GCP) services including BigQuery, Airflow DAGs, and Dataflow is required. A background in building efficient data workflows and a keen eye for data validation and performance tuning are key to succeeding in this role.","{' Hadoop': 'MISC', ' Python': 'MISC', ' SQL': 'MISC', ' Google Cloud Platform': 'MISC', 'GCP': 'MISC', ' BigQuery': 'MISC'}"
83,Ulta Beauty,Data Engineer,"Overview

Live the experience. From professional empowerment to continual learning opportunities. From ongoing investment in new and emerging technologies to a career of self-determination. At Ulta Beauty, our tech team is critical to our scalability‚Äîand is recognized that way. We‚Äôve been defined as a ‚Äúmature start-up.‚Äù A place where interdepartmental exposure, open doors, and genuine collaboration is ubiquitous. Where challenges come fast and furious, requiring agility, mental dexterity, and creativity. Where our passion for better solutions drives us and is core to who we are.

We‚Äôre engineering for the future of retail, and it‚Äôs no-holds-barred. But for those motivated by continual change and ambiguity, by superior leadership, by whip smart colleagues who will press you daily for your very best, you‚Äôll find that virtually nothing‚Äôs impossible at Ulta Beauty.

THE IMPACT YOU CAN HAVE: 

Data Protection IT Manager is responsible for building the data protection strategy and managing the data protection program. Develop and maintain data protection policies and procedures; undertake routine data protection control monitoring and awareness. Provide demonstrable assurance that data protection controls are operating effectively. Lead and assist as needed on regulatory projects to ensure compliance with regulations.

Advice IT project teams to ensure data protection controls are being implemented and followed. Identify enterprise solutions tools and processes for data protection initiatives. Educate end users on best practices for data protection.

YOU'LL ACCOMPLISH THESE GOALS BY: 

Information Management: Drafts and maintains the policy, standards, and procedures for compliance with relevant legislation. Assesses the implications of information, both internal and external, that can be mined from business systems and elsewhere and makes business decisions based on that information, including the need to make changes to systems. Reviews proposals for new initiatives and provides specialist advice on information management,Information security: Directs the development, implementation, delivery, and support of an enterprise information security strategy aligned to the strategic requirements of the business. Ensures compliance between business strategies and information security and leads the provision of information security resources expertise, guidance, and systems necessary to execute strategic and operational plans across all of the organization's information systems.Relationship management: Develops long-term, strategic relationships with senior stakeholders. Facilitates open communication and discussion between stakeholders, acting as a single point of contact by developing, maintaining, and working to stakeholder engagement data protection strategies and plans. Negotiates with stakeholders at senior levels and ensures that organizational data protection policy and strategies are adhered to.Innovation: Manages, monitors, and seeks, opportunities, new methods, trends, capabilities, and products to the advancement of the organization. Clearly articulates, and formally reports potential benefits from both structural and incremental change. Business process improvement: Advises on significant enterprise level improvements and measurable business benefits by identifying, proposing, initiating, and leading significant programs of improvement. Champions a culture of continuous improvement.

ESSENTIALS FOR SUCCESS: 

Data Protection:

Build and execute on the data protection strategy (e.g., risk-based application inventory, data classification, access, encryption controls, data loss monitoring etc.).Develop and improve the data protection policies and standards to manage data risks.Establish program for documenting and monitoring data security controls to ensure safeguards are appropriate.Enhance and maintain data classification standards, data mappings on how data 

Is processed, stored, shared, and accessed across the organization.

Educate and raise awareness to end users on best practices for data protection.Partner with key business units in proactively identifying security risks and building solutions, controls, and processes for data protection program.Perform privacy and security impact assessments for business and IT Projects.Establish and report relevant metrics and KPIs to communicate status, demonstrate progress of the data protection strategy.Assist legal and procurement in reviewing and advising on the contract language pertaining to data protection controls as needed.

Security Advising:

Interface with IT and business units to implement data protection safeguards.Work with enterprise architecture team in identifying enterprise solutions, tools for data protection initiatives.

Special Position Requirements

8+ years of experience in implementing and advising projects on data protection controls across the enterprise.Proficient knowledge of data protection laws and awareness of relevant guidelinesExperience in developing data protection policies and standardsDeveloped business process flows to identify confidential data.Has experience in socializing data protection awareness across the organization.Assisted in identifying solutions and tools for data protection initiatives.Demonstrate a working knowledge of NIST, ISO 27001 or ISO 27018, SOC security and privacy principles and provide practical examples of their application across the technical domain.Knowledge of IT security and privacy risks and best practice controls across multiple technologies and processesExperience performing IT security and privacy risk assessments / audits, using defined risk management approaches and processes.Excellent communication skills; feels comfortable working with non-technical business partners.Highly motivate, proactive and ability to work independently.Excellent interpersonal skills and the ability to interact well with both internal and external stakeholders.Able to prioritize and execute tasks in a high-pressure environment.

Preferred Qualifications:

Bachelor‚Äôs degree in computer science, a related field, or applicable work experienceCISSP, CISM, CIPT, CIPP or other officially recognized certification would be desirable.

About

At Ulta Beauty (NASDAQ: ULTA), the possibilities are beautiful. Ulta Beauty is the largest North American beauty retailer and the premier beauty destination for cosmetics, fragrance, skin care products, hair care products and salon services. We bring possibilities to life through the power of beauty each and every day in our stores and online with more than 25,000 products from approximately 500 well-established and emerging beauty brands across all categories and price points, including Ulta Beauty‚Äôs own private label. Ulta Beauty also offers a full-service salon in every store featuring‚Äîhair, skin, brow, and make-up services.

We will consider for employment all qualified applicants, including those with arrest records, conviction records, or other criminal histories, in a manner consistent with the requirements of any applicable state and local laws, including the City of Los Angeles‚Äô Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, and the New York City Fair Chance Act.","The Data Protection IT Manager at Ulta Beauty will lead the development and execution of a company-wide data protection strategy. This includes creating and maintaining data protection policies, overseeing data classification and loss prevention measures, and performing security impact assessments. The role involves collaborating with IT, legal, procurement, and business units to implement safeguards, maintain compliance with privacy regulations, and ensure data security controls are in place. The manager will also drive end-user education, establish KPIs, and support innovation and continuous improvement in data protection practices.","The ideal candidate will have 8+ years of experience in enterprise-level data protection, including expertise in risk management, policy development, and awareness of frameworks such as NIST, ISO 27001/27018, and SOC. Strong communication, stakeholder engagement, and cross-functional collaboration skills are essential. A Bachelor's degree in computer science or related field is preferred, along with certifications such as CISSP, CISM, CIPT, or CIPP. Experience advising on IT security risks, developing business process flows, and identifying enterprise data protection tools is highly desirable.","{' NIST': 'MISC', ' ISO 27001/27018': 'MISC', ' SOC': 'MISC', ' CISSP': 'MISC', ' CISM': 'MISC', ' CIPT': 'MISC', ' CIPP': 'MISC'}"
85,ATC,Data Analyst,"Job Title: Entry Level Business Analyst / Product Owner U.S. Citizens and those authorized to work in the U.S. are encouraged to apply. We are able to sponsor at this time.We are a US equal employment opportunity employer. Job Description:Entry Level expertise in gathering, analyzing, and documenting business requirements. If you do not have experience as a Business Analyst or Product Owner, you will be put through a training & Internship program.Experience in Requirement Gathering, Agile methodology, writing user stories, and building and planning roadmaps.Experience in preparing functional and detailed system design documentsDemonstrate expertise with SDLC methodologyAbility to communicate effectively across multiple levels of the organization, including with leadership.Demonstrated leadership, initiative, analytical skills, and sound business acumen, including the ability to understand and analyze recommendationsExperience with all phases of testing (i.e., system, integration, user acceptance), including creating use cases, test conditions, and review of output.Must be able to adjust and work effectively in a dynamic, changing environmentOther:Master‚Äôs Degree.We sponsor H1B or related work visas for eligible candidates on F1/OPT/CPT.We offer health insurance 100% paid.We follow equal employment opportunity.","The Entry Level Business Analyst / Product Owner will be responsible for collecting, analyzing, and documenting business requirements to support various technology projects. The role involves working within an Agile framework to write user stories, plan product roadmaps, and support functional system design. The candidate will collaborate across departments to ensure smooth communication, support the Software Development Life Cycle (SDLC), and contribute to testing processes including system, integration, and user acceptance testing. Candidates without direct experience will undergo a training and internship program to build practical skills and real-world exposure.","Ideal candidates should possess strong analytical and communication skills, a Master’s degree, and a proactive mindset. Familiarity with Agile methodologies, SDLC, and experience in writing use cases and test conditions is beneficial. The company welcomes U.S. citizens and those authorized to work in the U.S., offering sponsorship for eligible F1/OPT/CPT visa holders. Health insurance is fully covered, and the organization is committed to equal employment opportunities for all applicants.",{' Agile': 'MISC'}
91,Minnesota Department of Revenue,Data Analyst,"The successful candidate will support senior analyst in the ongoing monitoring support of quality controls designed to ensure the integrity of all data exchanges between internal and external partners. The controls framework will be updated based on consultation with other members of leadership, subject matter experts, personal knowledge base and industry best practices. The candidate should have a variety of competencies including knowledge of strong problem-solving skills, Microsoft Suite of applications and the ability to work in a team environment. ResponsibilitiesAdhere to team objectives that align to Customer Operations Management AgendaCreate test data for testing future system enhancements to make the data management process more accurate and efficient.Analyze data to determine exceptions and correct data transactions that fail to load into the billing system or other applicationsFollow protocols for preventing and handling data exceptions and delays.Manage all inbound and outbound electronic data transactions that flow through the internal data management middleware platform.Analyze and correct data transactions that fail to load into the application suite.All other projects and duties as assigned.
QualificationsBachelor‚Äôs degree in Information Technology or Business Administration is preferred1 year of energy industry experience preferredAn effective communicator with excellent written, verbal and presentation skillsDemonstrates expertise in utilizing Microsoft PowerPoint, Visio, Word, Excel - MS Access and SQL preferredKnowledge of flat files and EDI standards is a plusFlexibility and adaptability to work in a team environmentAbility to effectively multi-task and work in a pressure paced environment","The successful candidate will assist senior analysts in maintaining and improving the quality control framework that ensures accurate data exchanges between internal systems and external partners. Core duties include analyzing and correcting failed data transactions, creating test data for system enhancements, and adhering to data protocols to prevent delays and exceptions. The role also involves managing electronic data transfers via a middleware platform and participating in team objectives that align with customer operations strategies. Additional responsibilities may be assigned based on project needs.","A Bachelor’s degree in Information Technology or Business Administration is preferred, along with at least one year of experience in the energy industry. Strong communication skills—both verbal and written—are essential. Candidates should be proficient in Microsoft Office tools, particularly PowerPoint, Visio, Word, and Excel, with a preference for those experienced in MS Access and SQL. Familiarity with flat files and EDI standards is a plus, and the ideal candidate will demonstrate adaptability, teamwork, and the ability to multitask effectively in a high-paced environment.","{' Microsoft Office': 'MISC', ' PowerPoint': 'MISC', ' Visio': 'MISC', ' Word': 'MISC', ' Excel': 'MISC', ' MS Access': 'MISC', ' SQL': 'MISC', ' EDI': 'MISC'}"
92,Minnesota Department of Revenue,Data Analyst,"Job ID: 75056Who May Apply: This vacancy is open for bids and for all qualified job seekers simultaneously. Bidders will be considered through 04/04/2024.Date Posted: 03/29/2024Closing Date: 04/11/2024Hiring Agency/Seniority Unit: Revenue Dept / Revenue (inc Assessors)-MAPEDivision/Unit: Income Tax & Withholding / ITW-Systems Support/DiscoveryWork Shift/Work Hours: Day ShiftDays of Work: Monday - FridayTravel Required: NoSalary Range: $26.64 - $39.06 / hourly; $55,624 - $81,557 / annuallyClassified Status: ClassifiedBargaining Unit/Union: 214 - MN Assoc of Professional Empl/MAPEFLSA Status: NonexemptTelework Eligible: YesDesignated in Connect 700 Program for Applicants with Disabilities: Yes
Make a difference in the lives of Minnesotans.The work you‚Äôll do is more than just a job. Join the talented, engaged and inclusive workforce dedicated to creating a better Minnesota.
Job SummaryThis posting may be used to fill multiple vacancies.
The candidate(s) hired and new to this job classification may be eligible to receive a $5,000 hiring bonus! This bonus will be paid in two increments, with the first payment made after successfully passing the probationary period.
A $1,000 Referral Bonus may be offered to Revenue staff that recruit new talent hired at Revenue, in this position. 
To submit your referral, email: shelley.marty@state.mn.us using subject line ‚ÄòEmployee Referral‚Äô and include candidate‚Äôs name and this job posting ID, prior to candidate being selected.
A Revenue Tax Specialist Intermediate in the Systems, Support and Discovery Unit will work with a small team of data analysis and tax administration experts to identify compliance work for the Income Tax and Withholding Division. This position's duties include the income tax automated non-filer program. A person in this position must possesses strong data analysis abilities and be able to learn and apply new skills. They will work with data analysis tools like Microsoft Excel, Structured Query Language, and the Minnesota Department of Revenue's integrated tax system to identify potential tax non-compliance and income tax non-filers and make work available to Income Tax and Withholding Division staff.
Working at the Department of Revenue offers numerous advantages, including opportunities for personal and professional growth, impactful work, competitive compensation, work-life balance, and continuous learning. We strive to provide a supportive and inclusive work environment that enables our employees to thrive and make a meaningful impact. Join us and be a part of a team that is making a difference!Teleworking employees are required to live in Minnesota or in a state bordering Minnesota.
Minimum QualificationsTwo (2) years* of full-time professional experience in accounting or auditingORCertification (satisfactory completion of probation) as a Revenue Tax SpecialistApplicants who meet the above requirements will be further evaluated based on the following during the interview process:Knowledge of accounting and auditing principles and practicesTechnical tax knowledge, including court rulings, regulations and administrative policies and procedures.Customer service and interpersonal skillsAbility to plan, direct and review the work of others.Knowledge of personal computer operation and software programs used by the department in its internal and external operations.Communication and presentation skillsKnowledge of audit report processing proceduresKnowledge of electronic filing/processing systemsSkill in reading comprehensionSkill in problem-solving
*An associate degree may substitute for six (6) months of experience. Bachelor's degree may substitute one (1) year of experience; master‚Äôs degree may substitute for eighteen (18) months of experience; PhD may substitute for twenty-four (24) months of experience. Majors in Accounting, Finance, Economics, Business Administration, Legal, Business Management, Marketing, or other closely related fields are acceptable.
Preferred QualificationsThe ability to gain knowledge and apply it to tax and accounting work.Experience with data analysis tools such as Microsoft Excel and Structured Query Language (SQL).Knowledge of federal (Internal Revenue Code) and state statutes, regulations, rulings, and administrative policies related to individual income tax, withholding tax, and property tax refund.Knowledge of withholding tax and income tax nonfiler and audit processes, policies, and procedures.Knowledge of accounting and auditing principles and practices.Extensive knowledge of the operation of a personal computer, including the use of Microsoft Office software such as Excel, Word, Access, PowerPoint.
Physical RequirementsRequires occasional moving of articles such as boxes, accounting records, laptop computer, and portable printer.
Additional RequirementsPrior to an offer of employment, a background check will be conducted. This will include, but is not limited to checking degrees and licensures, criminal history, and tax filing and payment history. All individual income tax filing and payment obligations must be current prior to interviewing for this position.Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).
About Revenue Dept The Minnesota Department of Revenue works to fund the future for all of Minnesotans. We manage over 30 different taxes and collect $26.7 billion annually in state taxes, which funds state programs such as healthcare, transportation, public safety, and early childhood, K-12, and higher education.
Revenue is dedicated to an inclusive work environment that celebrates and values the diversity of each employee and reflects the communities we serve. We're committed to a culture of inclusion where everyone can bring their authentic selves to work and thrive.
We value a work life balance for our employees, and many of our employees telework in a full or hybrid capacity. For those that come to the office, regularly or occasionally, we invested in a state-of-the-art hybrid workspace located at the Stassen building in St. Paul.
Find out more about us on our website.
Why Work for Us Diverse Workforce We are committed to continually developing a workforce that reflects the diversity of our state and the populations we serve. The varied experiences and perspectives of employees strengthen the work we do together and our ability to best serve the people of Minnesota.
A recent engagement survey of State of Minnesota employees found: 95% of employees understand how their work helps achieve their agency‚Äôs mission91% of employees feel trusted to do their jobs88% of employees feel equipped to look at situations from other cultural perspectives when doing their job87% of employees report flexibility in their work schedule
Comprehensive Benefits Our benefits aim to balance four key elements that make life and work meaningful: health and wellness, financial well-being, professional development, and work/life harmony. As an employee, your benefits may include:Public pension planTraining and professional developmentPaid vacation and sick leave11 paid holidays each yearPaid parental leaveLow-cost medical and dental coveragePrescription drug coverageVision coverageWellness programs and resourcesEmployer paid life insuranceShort-term and long-term disabilityHealth care spending and savings accountsDependent care spending accountTax-deferred compensationEmployee Assistance Program (EAP)Tuition reimbursementFederal Public Service Student Loan Forgiveness Program
Programs, resources and benefits eligibility varies based on type of employment, agency, funding availability, union/collective bargaining agreement, location, and length of service with the State of Minnesota.
AN EQUAL OPPORTUNITY EMPLOYER Minnesota state agencies are equal opportunity, affirmative action, and veteran-friendly employers. The State of Minnesota recognizes that a diverse workforce is essential and strongly encourages qualified women, minorities, individuals with disabilities, and veterans to apply.We will make reasonable accommodations to all qualified applicants with disabilities. If you are an individual with a disability who needs assistance or cannot access the online job application system, please contact the job information line at 651-259-3637 or email careers@state.mn.us and indicate what assistance is needed.","As a Revenue Tax Specialist Intermediate within the Systems, Support, and Discovery Unit, you will support data analysis efforts to identify tax non-compliance and non-filers for the Income Tax and Withholding Division. Core duties include maintaining the income tax automated non-filer program, utilizing tools such as Microsoft Excel and SQL, and collaborating with a small team to analyze data from the department’s integrated tax system. You’ll contribute to making compliance work accessible to division staff, ensuring accuracy and efficiency in identifying non-compliant filings. This role also offers the opportunity to work on impactful public service initiatives, participate in continuous learning, and support efforts that fund essential state services.","The position requires at least two years of professional experience in accounting or auditing, or certification as a Revenue Tax Specialist. A degree in accounting, business, or related fields may substitute for a portion of experience. Ideal candidates will possess strong data analysis skills, knowledge of auditing principles, tax regulations, and experience using software like Excel, SQL, and department-specific systems. Excellent communication, problem-solving abilities, and the capability to work in a team-focused environment are essential. A background check and current tax compliance are required for employment consideration.","{' Excel': 'MISC', ' SQL': 'MISC'}"
95,ServiceNow,Data Engineer,"Company Description

At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can‚Äôt wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.

With more than 7,700+ customers, we serve approximately 85% of the Fortune 500¬Æ, and we're proud to be one of FORTUNE 100 Best Companies to Work For¬Æ and World's Most Admired Companies‚Ñ¢.

Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.

Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.

Job Description

We‚Äôre not yesterday‚Äôs IT department, we're Digital Technology. The world around us keeps changing and so do we. We‚Äôre redefining what it means to be IT with a mindset centered on transformation, experience, AI-driven automation, innovation, and growth. We‚Äôre all about delivering delightful, secure customer and employee experiences that accelerate ServiceNow‚Äôs journey to become the defining enterprise software company of the 21st century. And we love co-creating, using, and highlighting our own products to do it. Ultimately, we strive to make the world work better for our employees and customers‚Äîwhen you work in ServiceNow Digital Technology, you work for them.

What you get to do in this role:

The Principal Data Architect is accountable for executing the vision and strategy for the organizations use of data.Accountable for defining and maintaining the data architecture roadmap , offering advice and guidance to business stakeholders.Ensure that data architect solutions align with business requirements and data policies and regulations.Accountable for the choice of the toolsets required to design, build, manage and maintain the data storage facility within an agreed budget. You'll work closely with our business, DT partners and other data teams to deliver a simplified data solution ensuring that data is secure, available, and accurate to business stakeholders.

Qualifications

To be successful in this role you have:

15 years minimum experience required.Minimum of 3 years experience with data systems AI and MLlead cross-functional teams and executing the data strategies from your vast experience.Translate business requirements into data models that are easy to understand and used by different subject areas. Design, implement and build data models and pipelines that deliver data with measurable quality.Be responsible for defining data architectural solutions leveraging the cloud tech stack available that are in line with the long-term business strategy.Be accountable for the creation of data flows (operational / analytical) that show key data entities and any data required to implement solutions.Work closely with business stakeholders to educate and engage in architectural and requirements analysis discussions.Be accountable for the simplification the data estate by reducing the number of tools/data duplication utilized to gather data, this will include the design and management of data feeds, introduction of best practice including documentation and version control.Be responsible for working closely with project team and raising risks. You will manage risks to mitigation, resolution, or acceptance.Engage with senior management and playback options and opportunities considering time cost and quality.Be accountable to ensure that any design, build and decommissioning and archive of.Partner with product teams, data analysts and engineering teams to build foundational data sets that are trusted, well understood, and aligned with business strategy. Will improve existing systems, including what areas have gaps that need to be filled, and have started working with the team and stakeholders to scope and prioritize solutions.Work proactively with stakeholders and establish strong working relationships and a mutual trust.Will be accountable for the management and resolution of escalations from both external and internal stakeholders.

#DTjobs 

Additional Information

ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.

At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.

If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.

For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.

Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.

From Fortune. ¬© 2022 Fortune Media IP Limited All rights reserved. Used under license.

Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.","As a Principal Data Architect in ServiceNow’s Digital Technology team, you will be accountable for shaping and executing the data architecture roadmap, ensuring data solutions align with business goals, security, and compliance standards. You will lead cross-functional efforts to design scalable data models, pipelines, and operational/analytical data flows while driving simplification and standardization across the enterprise data estate. This includes toolset selection, data strategy execution, decommissioning outdated systems, and ensuring trusted, well-documented data delivery to business stakeholders.","The ideal candidate brings a minimum of 15 years of experience, including at least 3 years with AI/ML data systems. They must possess a deep understanding of cloud-based data architecture, strong leadership in translating business needs into scalable technical solutions, and proven ability to manage risks, engage senior stakeholders, and foster trust across teams. Proficiency in developing foundational, high-quality data sets and driving data governance best practices is essential for this role.",{' AI/ML': 'MISC'}
96,ADP,Data Analyst,"ADP is seeking an experienced professional to join the Integration Management Team as a Data Integration Specialist. This will be a substantial customer-facing role within the Operations organization that requires a unique mix of technical and business expertise. The ability to perform a consultative role to our internal partners within Operations and Service as well as our customers and their technology partners is critical to delivering on the key responsibilities of the position. A successful candidate will possess the ability to utilize pre-defined file and non-file based (API) data intake methods to recommend and complete integrations for the purpose of acquiring customer data in support of ADP Tax Credits product administration. Additionally, this role will support implementation teams as an SME while new integration capability (i.e. APIs, File based capability) is implemented. The candidate will pilot the new capability, define onboarding processes for emerging capability and train the broader teams on how to onboard clients utilizing the new capability.

The primary responsibilities of this role include, but are not limited to:

Supporting the installation of ADP Tax Credits customers by implementing data integrations using already established, methodologies (API).Working closely with our customers and/or the Third-Party partners as well as internal business partners to define, recommend and implement effective solutions.Coordinating activities of internal / external technical teams completing data integrations, leading working sessions to troubleshoot issues and providing technical guidance.Defining onboarding processes for emerging capabilities and training the broader teams on how to onboard clients utilizing the new capabilities.Defining data requirements specific to the customers‚Äô plan design, review data requirements with the customer and offer alternatives for data concerns.Completing iterative data auditing / testing for completeness and adherence to plan details.Providing feedback for data corrections to meet predefined tolerances for data accuracy.Coordinating activities to complete data loads into the appropriate administration system and promoting the data integrations to production status.Solving complex problems by taking a broad perspective to identify solutions.Working independently and leading others through complex situations.Leading process improvement initiatives that focus on bringing efficiencies to customer onboarding activities.Excellent communication skills, including direct interaction with customers and the ability to tailor messages based on the customer needsStrong analytical and problem-solving skills, preferably working on data integration projectsExperience writing/reading SQL Queries and Stored Procedures and familiarity with architecture and data structureExperience with reporting technologies such as Crystal Reporting, Microsoft SQL Server Reporting Services, Microsoft Power BI or Tableau, JavaExcellent interpersonal skills with the ability to build and cultivate partnerships with ADP customers, their technology partners, and internal business partnersDemonstrated project management skills with the ability to drive others in various project stagesDemonstrated experience serving as a subject matter expert to internal and external teams focused on data integrationsAbility to build new and mature business processes to be used by othersProven track record of delivering results, with the ability to meet deadlines in a fast-paced environmentAbility to work independently, prioritize deliverables and drive to solutionsWorking knowledge of APIs highly desiredKnowledge of integration to Workday tenants and an understanding of it Oracle and SAP systems a plusAbility to effectively work through ambiguous situations and bring clarity to othersTechnical background with Excel, text file manipulation and SQLExperience with CSV / fixed width file formats requiredKnowledge of ADP products and services a plusBachelor‚Äôs degree or equivalent work experience

Diversity, Equity, Inclusion & Equal Employment Opportunity at ADP: ADP is committed to an inclusive, diverse and equitable workplace, and is further committed to providing equal employment opportunities regardless of any protected characteristic including: race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, protected veteran status or disability. Hiring decisions are based upon ADP‚Äôs operating needs, and applicant merit including, but not limited to, qualifications, experience, ability, availability, cooperation, and job performance.

Ethics at ADP: ADP has a long, proud history of conducting business with the highest ethical standards and full compliance with all applicable laws. We also expect our people to uphold our values with the highest level of integrity and behave in a manner that fosters an honest and respectful workplace. Click https://jobs.adp.com/life-at-adp/ to learn more about ADP‚Äôs culture and our full set of values.","As a Data Integration Specialist on ADP’s Integration Management Team, you’ll serve in a highly consultative, customer-facing capacity, supporting the seamless onboarding and integration of client data for ADP's Tax Credits product. Your core responsibilities include implementing data integrations using predefined file-based and API methodologies, collaborating with internal teams and external partners to define and execute integration plans, and troubleshooting technical issues. You’ll also act as a subject matter expert during the rollout of new integration capabilities, piloting and documenting processes, conducting data audits, and ensuring the accuracy and completeness of data prior to production deployment. This role requires direct customer engagement and proactive project management to drive efficient and effective implementations.","The ideal candidate will bring a mix of technical proficiency and business acumen, including experience with SQL, APIs, and reporting tools like Power BI or Tableau. A solid understanding of data structures, file formats (CSV, fixed width), and systems such as Workday, Oracle, or SAP is essential. Strong interpersonal and analytical skills, coupled with the ability to manage multiple priorities in a fast-paced environment, are critical. Candidates should have a bachelor’s degree or equivalent experience, a proven track record of leading integration initiatives, and the ability to train others on new technologies. Familiarity with ADP products and services is a plus, and a commitment to diversity, equity, inclusion, and ethical business practices is expected.","{' SQL': 'MISC', ' APIs': 'MISC', ' Power BI': 'MISC', ' Tableau': 'MISC'}"
97,Olsson,Data Engineer,"Company Description

We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.

Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us ‚Äî and will continue to allow us ‚Äî to grow. The result? Inspired people, amazing designs, and projects with purpose.

Job Description

Olsson provides mechanical and electrical services for data centers, large commercial developments, hospitals, laboratories, school/university buildings, and military facilities. As an Electrical Engineer on the Mechanical/Electrical team, you will complete a variety of tasks, which may include the preparation of design documents, calculations and specifications for various projects. Projects would be completed under direct supervision of experienced electrical engineers that will provide mentorship, training and project quality review.

Qualifications

You are passionate about:

Working collaboratively with othersHaving ownership in the work you doUsing your talents to positively affect communities

You bring to the team:

Strong communication skillsAbility to contribute and work well on a teamBachelor‚Äôs degree in electrical engineeringObtained or working to obtain Fundamentals of Engineering.2-5 years of experienceAutoCAD and/or Revit experience is a plusStrong attention to detailDesire to provide innovative solutions

Additional Information

Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we‚Äôre here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.

As an Olsson employee, you‚Äôll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you‚Äôll:

Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)Engage in work that has a positive impact in communitiesReceive an excellent 401(k) matchParticipate in a wellness program promoting balanced lifestylesBenefit from a bonus system that rewards performanceHave the possibility for flexible work arrangements

Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.","As an Electrical Engineer on Olsson’s Mechanical/Electrical team, you’ll support a variety of projects involving the design and development of electrical systems for data centers, commercial buildings, healthcare facilities, schools, and more. Your responsibilities will include preparing design documents, performing electrical calculations, and drafting project specifications—all under the guidance of experienced engineers who provide mentorship and quality assurance. This position emphasizes collaboration and offers an opportunity to contribute to meaningful infrastructure that positively impacts communities.","The ideal candidate will hold a bachelor’s degree in electrical engineering and be working toward or have already obtained their Fundamentals of Engineering (FE) certification. Candidates should have 2–5 years of experience and a keen attention to detail. Proficiency in AutoCAD and/or Revit is a plus. Strong communication skills, teamwork, and a proactive mindset are key to thriving in this role. Olsson offers a supportive, growth-focused environment with benefits including an ESOP, 401(k) match, wellness programs, flexible work options, and performance-based bonuses.",{' AutoCAD': 'MISC'}
99,FastTek Global,Data Scientist,"Manage a portion of a major engineering program or a small technical program to assure that cost, schedules and performance goals are met.Assist in managing the reporting/dashboards developments used by the programs.

Essential Duties And Responsibilities

Interact and coordinate with Business Program management and Contracts Administration on issues pertaining to requirements, changes, interpretations, and financial conditions of the contract.Accountable for all schedules, control accounts, financial reporting, quality, and customer satisfaction on project(s).Develop and maintain tools, reporting/dashboards to provide portfolio visibility to key stakeholders and drive accountable business results.Automate portfolio data collection and presentation where possible.Develop and implement corrective action plans when deviations from budgets and/or schedules are evident.Assign and manage internal, external, multi-divisional, direct and matrixed resources to ensure all project objectives and goals are met.Develop, prepare and present briefings to both executive management and the customer related to program status, direction and performance.Formally identify, assess, monitor and mitigate risk throughout project life cycle.Provide leadership to cross functional team. Assure communication and cooperation among team members and resolve areas of conflict.Assure communication and cooperation among program and project team members and resolve areas of conflict.Other duties as assigned.

Basic Qualifications

Bachelor‚Äôs degree or equivalent experience in engineering, business, finance, operations management, data science or other related field6 plus years of relevant experiencePMP certification

Preferred Qualifications

Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Knowledge of and experience with data visualization and reporting packages (Power BI, etc.), database (SQL, etc.), and programming (Python, JavaScript, ETL tools, etc.).Knowledge of and experience with advanced Microsoft Excel tools including macros, VBA, and Power Query.Proficient skills in Microsoft Office Suite: Word, Excel (Intermediate to Advanced), PowerPoint, SharePoint, etc.Skilled with MS Excel ‚Äì pivot tables, graphs, macros, VBASkilled in Microsoft Power BI, data analytics, BI (Business Intelligence) reportingEngineering project management and contract managementExperience with project portfolio management.Working knowledge of Primavera P6 or Microsoft Project or equivalent with at least 6 years of experienceAbility to develop training material and experience training othersIndependent judgment and decision-making abilityStrong verbal presentation and written communication skillsExcellent time management and organizational skillsAbility to influence othersCMMI or TS16949 Certification experience, Systems EngineeringBasic knowledge of defense government contracts to include CLIN, FAR, DFAR etcBasic knowledge of Defense Acquisitions process, decision milestones and funding procedures

Required

As this is a program manager position, we are looking for someone who has a strong background in project management with a PMP as a foundation to communicate with our integrated product development teams (Business Program Management, Systems Engineering, Test and Development, Operations, contract management).We manage a lot of data so this person will be required to have intermediate to advanced skills in Excel and other Microsoft applications.We need someone who has made the transition to using tools like Power BI for big data reporting and analytics.

Preferred

If they have strong project management skills not in engineering, but another discipline that is okay.We have resources that have a variety of backgrounds (finance, operations, construction, engineering, IT, business, etc) that have done well in this position as long as they have good project management skills in managing costs, schedule, labor.If they have the PMP they should be qualified to cover the project management requirements.

Additional Info

At FastTek Global, Our Purpose is Our People and  Our Planet . We come to work each day and are reminded we are helping people find their success stories . Also, Doing the right thing is our mantra . We act responsibly, give back to the communities we serve and have a little fun along the way.

We have been doing this with pride, dedication and plain, old-fashioned hard work for 24 years !

FastTek Global is financially strong, privately held company that is 100% consultant and client focused .

We've differentiated ourselves by being fast, flexible, creative and  honest . Throw out everything you've heard, seen, or felt about every other IT Consulting company. We do unique things and we do them for Fortune 10, Fortune 500, and technology start-up companies.

Benefits

Our benefits are second to none and thanks to our flexible benefit options you can choose the benefits you need or want, options include:

Medical and Dental (FastTek pays majority of the medical program)VisionPersonal Time Off (PTO) ProgramLong Term Disability (100% paid)Life Insurance (100% paid)401(k) with immediate vesting and 3% (of salary) dollar-for-dollar match

Plus, we have a lucrative employee referral program and an employee recognition culture.

FastTek Global was named one of the Top Work Places in Michigan by the Detroit Free Press in 2013, 2014, 2015, 2016, 2017, 2018, 2019,  2020, 2021, 2022, and 2023!

To view all of our open positions go to: https://www.fasttek.com/fastswitch/findwork

Follow us on Twitter: https://twitter.com/fasttekglobal

Follow us on Instagram: https://www.instagram.com/fasttekglobal

Find us on LinkedIn: https://www.linkedin.com/company/fasttek

You can become a fan of FastTek on Facebook: https://www.facebook.com/fasttekglobal/","This position involves managing a portion of a large-scale engineering program or leading a smaller technical program, ensuring that cost, schedule, and performance goals are achieved. The Program Manager will interact with multiple departments including Business Program Management and Contracts Administration, while developing dashboards and automating data reporting for greater visibility and decision-making efficiency. Responsibilities include developing corrective action plans, managing cross-functional and matrixed teams, ensuring risk mitigation, and driving customer satisfaction through regular reporting and performance reviews. The role also entails presenting to leadership, supporting continuous improvement efforts, and ensuring compliance with quality standards.","Candidates should have at least a bachelor’s degree in a relevant field and six or more years of experience, preferably with a PMP certification. The ideal candidate will be proficient in Microsoft Office, Excel (macros, VBA), and Power BI, with working knowledge of SQL, project management tools like MS Project or Primavera, and familiarity with defense contract management and acquisition processes. Strong communication, time management, data visualization, and organizational skills are critical. While engineering experience is preferred, a strong background in project management from fields like finance, IT, or operations is also highly valued.","{' Microsoft Office': 'MISC', ' Excel': 'MISC', ' VBA': 'MISC', ' Power BI': 'MISC', ' SQL': 'MISC', ' MS Project': 'MISC'}"
103,NBC Sports Next,Data Engineer,"Company Description

NBC Sports Next is where sports and technology intersect. We‚Äôre a subdivision of NBC Sports and home to all NBCUniversal digital applications in sports and technology within our two groups: Youth & Recreational Sports; and Golf.

At NBC Sports Next, we make playing sports better through innovative technology and immersive experiences for athletes, coaches, players and fans. We equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; GolfNow, the leading online tee time marketplace and provider of golf course operations technology; GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, and coaching, tips; TeamUnify, swim team management services; and GoMotion, sports and fitness business software solutions.

At NBC Sports Next we‚Äôre fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology that provides the ultimate in immersive experiences.

Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.

Come join us as we work together as one team to innovate and deliver what‚Äôs Next. 

Job Description

GolfNow has an exciting opportunity for an experienced Data Engineer II. In this role as part of the Data Engineering Team, you work to manage the full lifecycle of our data warehousing needs. You will read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions) and create and maintain ETL pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including MS SQL Server, SSIS, PowerShell, and other AWS cloud technologies. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.

Responsibilities Include But Are Not Limited To

Work within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse.Build, analyze and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance.Build data pipelines and ETLs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.

Qualifications

All candidates must meet the qualifications below:

A minimum of 3 years of data engineering experience is required.Bachelor‚Äôs Degree in Computer Science or related field/relevant industry experience in data engineering.Strong experience with SQL Server database and related technologies such as SSIS, SSRS and SSMSAdvanced knowledge of TSQL tuningExperience in the Azure Cloud Environment including ETL processingExperience in the AWS Cloud Environment including ETL processingAdvanced experience and knowledge of T-SQL Microsoft SQL Server Database Platforms.Working experience developing and refactoring SQL Stored Procedures.Experience using source control with Git or Team Foundation Server.Experience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools: Tableau, Power BI

Desired Qualifications Are As Follows

Experience with AWS resources including Glue, S3, Lambda functions and Step Functions are a plusExperience with Datadog is a plusExperience with Apache Airflow is a plusExperience with PowerShell scripting is a plusExperience working in Agile environmentExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.

Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee‚Äôs residence.

Additional Information

NBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.

If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations in the US by calling 1-818-777-4107 and in the UK by calling +44 2036185726.","As a Data Engineer II at GolfNow (NBC Sports Next), you will play a key role in managing the lifecycle of data warehousing operations. Your responsibilities will include building and maintaining complex ETL pipelines, developing SQL queries, managing data models for business reporting, and collaborating with engineers and stakeholders to support data-driven decisions. You’ll also help troubleshoot and enhance existing reports, develop scalable data solutions, and ensure performance optimization across systems using both Microsoft and AWS cloud technologies.","The ideal candidate has at least 3 years of data engineering experience, a bachelor’s degree in computer science or a related field, and advanced knowledge of T-SQL, SQL Server, SSIS, and cloud platforms like Azure or AWS. Experience with tools such as Power BI, Tableau, Git, and Agile methodologies is preferred, along with familiarity with AWS services like Glue, Lambda, and S3. Strong problem-solving skills, eagerness to learn, and the ability to work remotely with a collaborative mindset are essential for success in this fully remote role.","{' T-SQL': 'MISC', ' SQL Server': 'MISC', ' SSIS': 'MISC', ' Power BI': 'MISC', ' Tableau': 'MISC', ' Git': 'MISC', ' Agile': 'MISC'}"
104,For Pete's Sake ¬Æ Cancer Respite Foundation,Data Engineer,"For Pete‚Äôs Sake Cancer Respite Foundation enables cancer patients and their loved ones to strengthen, deepen and unify their relationships by creating unforgettable and lasting respite experiences. Working with oncology professionals at over 100 hospitals and cancer centers, FPS provides transformative respite experiences to cancer patients (ages 21-55), their caregivers and their children and offers our families emotional support that assists them as their journey with cancer continues. Our respite program helps families recognize it is love, not cancer, that defines them. Patients must be nominated by a healthcare professional who is a member of the patient‚Äôs oncology team to be eligible for the program. Currently, FPS is exclusively working with our travel partner, Woodloch Resort, and nominated families are invited to spend five nights/six days at this safe, top-rated family destination. A typical respite is six days and includes a generous cash stipend, travel costs, accommodations, a For Pete‚Äôs Sake welcome bag with travel items and other materials that assist in the respite experience, including writing journals, materials to encourage family communication, inspirational and spiritual books on coping and hope, therapeutic art activities, and other carefully selected items to help make the respite meaningful emotionally and spiritually.  FPS is in a growth stage as it plans to expand from its five-state region to fifteen states, opening satellite offices in seven additional locations over the next four years. Further, the organization plans to construct the nation‚Äôs first Respite Center dedicated exclusively to families. 
Who You Are:The Development Data Manager is charged with effectively and correctly overseeing and actively participating in all technology systems and database management for the organization. This extends to all programmatic and development efforts and includes systems including Raiser‚Äôs Edge, NXT, Omatic, Classy, Salesforce, Box, Outlook and Ring Central. This position will work with Development Staff, Program Staff, Office administration, the CFO and the CEO in an administrative role for all tasks related to the organization‚Äôs development and programmatic efforts, including data integrity, data relationship, event data, data integration and overall system integration. 
What You'll Do:
Database Management:Lead all technology and data practices for FPS, ensuring the organization has the necessary resources for respite delivery.Maintain and update internal guidelines for data entry, ensuring accuracy and integrity.Implement best practices for data management and security.Provide training to staff on internal guidelines and technological advancements.Manage Data Entry Specialist and additional department staff to uphold data entry standards and accuracy.
Oversight of Raiser‚Äôs Edge Data and Reporting:Ensure accurate entry of constituent and gift data into Raiser‚Äôs Edge following internal guidelines.Process offline gifts and manage recurring donations effectively.Coordinate with Event Coordinator for successful technology integration in FPS events.Prepare reports and reconcile donations, ensuring data accuracy and consistency.Assist in clean-up efforts and suggest improvements for data tracking methods.
Oversight of Salesforce Data and Reporting:Collaborate with Program leadership to optimize Salesforce platform for mission delivery.Oversee data entry for program execution and provide reporting expertise for dashboards.
What You Bring:
Knowledge, Skills, Abilities:Ability to work independently, take initiative, and problem solve.Excellent organizational and multitasking skills.Strong computer proficiency and familiarity with Microsoft Office suite.Exceptional people skills for engaging with FPS constituents,
Training and Experience:Minimum of two (2) years in technology development and integration support.Minimum of four (4) years of professional office experience with Raiser‚Äôs Edge, NXT, and Salesforce.Proficiency in written and oral communication.Knowledge of Raiser‚Äôs Edge and Salesforce required; familiarity with Omatic and Classy preferred.
 For Pete‚Äôs Sake Cancer Respite Foundation is an equal opportunity employer and is committed to fostering a diverse and inclusive workplace. We do not discriminate on the basis of race, color, religion, national origin, gender, gender identity, sexual orientation, age, marital status, veteran status, disability status, or any other characteristic protected by applicable laws.","The Development Data Manager at For Pete’s Sake Cancer Respite Foundation plays a central role in supporting the organization’s mission by overseeing all technology systems and data operations. This individual ensures the integrity, accuracy, and efficiency of data across platforms such as Raiser’s Edge, Salesforce, Omatic, Classy, and others, which support both development and program activities. Responsibilities include managing data entry standards, optimizing system integrations, training staff, supporting fundraising and event technology, and producing key performance reports to guide strategic initiatives. Collaboration across departments, particularly with Development, Program, and Executive leadership, is crucial to success in this role.","Ideal candidates will have a minimum of four years of experience working with Raiser’s Edge and Salesforce in a professional office setting and at least two years of experience supporting technology development or system integration. They should demonstrate strong organizational and analytical skills, the ability to work independently, and excellent interpersonal communication. Proficiency in Microsoft Office and familiarity with platforms like Omatic and Classy is preferred. This role is ideal for someone passionate about using data and technology to improve nonprofit operations and enhance the lives of families impacted by cancer.",{' Microsoft Office': 'MISC'}
105,N.C. Department of Information Technology,Data Engineer,"Description Of Work

Looking to take the next step in your IT career?

We currently have an opening for a Database Administrator I

The position is designated Statutory Exempt and is exempt from the State Human Resources Act.

This is a time-limited position. It is full-time with State Benefits for a limited time. Although the length of time this position will be active cannot be determined, we anticipate that this position will be in place through December 31, 2026. If you have questions concerning the time-limited status of this position, you may inquire at the interview.

The Database Administrator I is responsible for the design, implementation, backup, and management of geospatial databases, and the data contained in them that becomes part of the NC Division of Broadband and Digital Equity (DBDE) work. The position is statewide in scope. The NC DBDE has a formal agreement with the Center for Geographic Information & Analysis (CGIA) to manage PostgreSQL enterprise databases related to broadband availability for over four million locations in the state, as well as tracking broadband grant locations throughout all 100 counties.

Management and administration of the Geographic Information Systems (GIS) data and databases includes the following tasks:

Seeking and receiving regular updates to GIS data layers Performing quality control checks (e.g. projection, metadata, completeness) on the data before making it available to CGIA and DBDE customers Provides technical advice and direction to CGIA and the Division of Broadband and Digital Equity Responsible for data modeling, database optimization, implementation of schemas, and interpreting and writing complex Structured Query Language (SQL) queriesResolving any technical issues that may surface with any GIS data Developing and implementing GIS data archival, recovery, and access strategies Maintaining a GIS data inventory and clearinghouse through NC OneMap to facilitate discovery and access of GIS data resources Assessing technical requirements and implement technology enhancements and solutions based on customer feedback, technology trends, etc. (e.g. implementation and automation of relational database management system (PostgreSQL with the PostGIS extension) running in the Amazon Web Services (AWS) cloud) Resolving technical issues related to data delivery and availability and install and maintain patches for database and geospatial software Providing leadership in the long-term planning of the broadband location database Providing consultation to staff that are performing data creation and implementation activities related to database and enterprise activities 


Availability of the DBDE databases and the geospatial data in them is critical to understanding the broadband landscape in North Carolina. The Database Administrator will need to:

Administer a database to support the tracking of currently funded locations and identifying locations that are eligible for future funding programs Oversee data and database functions for tracking the progress of these programs and the overall progress of connecting all citizens in the state to this critical infrastructure Maintain a reliable database with reliable geospatial information that is continuously available to support essential stakeholder workflows and the transparency and success of the funding programs implemented by the DBDE Serve as a key technical resource in solving highly complex problems related to relational database management systems and Geographic Information Systems Track changes within Federal Communications Commission (FCC) datasets related to location-level availability of broadband Investigate, research, and implement new technical approaches and technologies associated with relational database management systems and Geographic Information Systems 


About the Organization

The N.C. Department of Information Technology (NCDIT) serves as the Technology Center for the State of NC. Services that NCDIT provides reach a client base of state and local government agencies, as well as schools, colleges and universities. NCDIT‚Äôs mission is to enable trusted business-driven solutions that meet the needs of North Carolinians. NCDIT provides technology services to state agencies and is charged with closing the digital divide by expanding availability of broadband services and promoting the adoption of affordable, high-speed internet.

As NCDIT‚Äôs services reach North Carolina residents from all backgrounds, we believe that a diverse workforce is our most valuable asset to recognize, understand and meet the IT needs of our constituents across the state. Our agency culture intentionally values diversity, equity and inclusion through the implementation of thoughtful, practical, innovative and data-driven strategies. We are an Employment First state, ensuring that people with disabilities have equal opportunities to succeed in the state government workplace ( Executive Order 92 ). NCDIT supports recent executive orders to address pay equity for women ( Executive Order 93 ), establish paid parental leave for birth, adoption, and foster care ( Executive Order 95 ), and implement fair chance policies ( Executive Order 158 ). Join a team that welcomes, values, respects and supports all members of our work community.

If you have student loans, becoming a state employee includes eligibility for the Public Service Loan Forgiveness Program. Visit www.studentaid.gov to learn more.

Knowledge, Skills And Abilities / Competencies

Resumes/CVs are intended to be used as a complement to an application. Generally resumes/CVs are lacking the detail and breadth of an applicant‚Äôs full education and work history so applicants should complete the application with more detail than what their resume contains to show that they meet both the Education Requirements and ALL Knowledge, Skills and Abilities (KSAs) listed below in order to qualify. Click these links for additional information:  Introduction to the Job Application  and  Addressing Knowledge, Skills and Abilities .

To qualify for this position, applicants must document on the application that they possess ALL of the following:

Demonstrated experience with administration and/or structuring of an integrated database systemDemonstrated experience with applications analysis and/or programming techniquesExperience with the development of data automation routines and/or administration for large datasetsExperience working with underlying OS level technology that supports the database environmentExperience with implementing and administering data and/or database security techniques


Minimum Education And Experience Requirements

Bachelor's degree in Computer Science or an IT related field or a related curriculum from an appropriately accredited institution and one year of experience in programming and applications analysis including the design and maintenance of an integrated database system

OR

Associate degree in Computer Science or an IT related field or a related curriculum from an appropriately accredited institution and two years of experience in programming and applications analysis including the design and maintenance of an integrated database system

OR

High School or General Educational Development (GED) diploma and five years of experience in programming and applications analysis including the design and maintenance of an integrated database system; or an equivalent combination of education and experience.

Supplemental and Contact Information

The North Carolina Department of Information Technology (DIT) is an Equal Opportunity Employer who embraces an Employment First philosophy which consists of complying with all federal laws, state laws and Executive Orders.

NCDIT uses the Merit-Based Recruitment and Selection Plan to fill posted positions. Hiring salary will be based on relevant qualifications, internal equity, and budgetary considerations pertinent to the advertised position.

 The Department of Information Technology will not accept ""See Resume"" or inserted text resumes in lieu of all work experience and education completed on the application.  Employment at NCDIT is contingent upon a satisfactory background check.  Applicants seeking Veteran's Preference must attach a DD form 214, Certificate of Release or Discharge from Active Duty, along with your application.  Applicants seeking National Guard Preference must attach a NGB 23A (RPAS) if you are a current member of the NC National Guard in good standing. If you are a former member of the NC National Guard who served for at least 6 years and was discharged under honorable conditions, you must attach either a DD256 or NGB 22.  Applicants applying for positions that require specific coursework, must upload and attach a copy of the transcript with their application.  Applicants with relevant professional certifications to the posted job must attach proof of active certification along with the information in the ‚ÄúCertificates and Licenses‚Äù section.  If applicants earned college credit hours but did not complete a degree program, they must attach an official transcript to each application to receive credit for this education .If applicants earned a foreign degree, foreign degrees require an official evaluation for U.S. equivalency, and must be submitted to Human Resources for verification. There are several organizations that perform this specialized service, feel free to use any service of your choosing. The National Association of Credential Evaluation Services (NACES) has several options on their website that can provide credential verification: https://www.naces.org/members 


 REMOTE WORK: 

We trust our employees to be self-motivated and successful in hybrid/remote roles, thus NCDIT offers robust work from home options and variable work schedule flexibility.

 COMPENSATION & BENEFITS: 

The state of North Carolina offers excellent comprehensive benefits. Employees can participate in health insurance options, standard and supplemental retirement plans, and the NCFlex program (numerous high-quality, low-cost benefits on a pre-tax basis). Employees also receive paid vacation, sick, and community service leave. In addition, paid parental leave is available to eligible employees.

Some highlights include:

 The best funded pension plan/retirement system in the nation according to Moody‚Äôs Investor‚Äôs Service  Twelve (12) holidays/year  Fourteen (14) vacation days/year which increase as length of service increases and accumulate year-to-year  Twelve (12) sick days/year which are cumulative indefinitely  Longevity pay lump sum payout yearly based on length of service  401K, 457, and 403(b) plans 


 Learn more about employee perks/benefits: 

 Why Work For NC?  NC OSHR: Benefits  NC OSHR: Total Compensation Calculator 


To apply for this position, please click the ""Apply"" link above (on the Government Jobs website) or visit https://www.governmentjobs.com/Applications/Index/northcarolina to complete an on-line application.

Due to the volume of applications received, we are unable to provide information regarding the status of your application over the phone. To check the status of your application, please log in to your account and click ""Application Status."" If you are selected for an interview, you will be contacted by management. If you are no longer under consideration, you will receive an email notification. If there are any questions about this posting other than your application status, please contact:

NCDIT Human Resources

Samika Lewis

samika.lewis@nc.gov

For technical issues with your application, please call the GovernmentJobs.com Applicant Support Help Line at 855-524-5627.","The Database Administrator I will manage geospatial databases critical to broadband availability and grant tracking efforts for the NC Division of Broadband and Digital Equity (DBDE). This includes administering a PostgreSQL/PostGIS enterprise database within AWS, ensuring data quality, modeling, and integration with systems such as NC OneMap. The role is key to supporting accurate and reliable broadband mapping for over four million locations across North Carolina, and it directly impacts the success of statewide digital equity initiatives. Duties also involve performing database optimization, automating data workflows, maintaining data inventories, and resolving technical issues related to data delivery and system reliability.","To qualify, candidates must demonstrate experience in integrated database systems, programming, data automation for large datasets, OS-level technologies supporting databases, and database security. Minimum qualifications include a bachelor's degree in Computer Science or related IT field and one year of experience, though equivalent combinations of education and experience are acceptable. Strong analytical skills, familiarity with GIS tools, SQL, and data integrity practices are essential for success in this role. This full-time, benefits-eligible, time-limited position is expected to remain active through December 2026 and supports remote work arrangements.",{' SQL': 'MISC'}
106,"Skadden, Arps, Slate, Meagher & Flom LLP and Affiliates",Data Analyst,"About Us Skadden, Arps, Slate, Meagher & Flom LLP (Skadden) has forged a reputation as one of the most prestigious law firms in the world. By relying on innovation, intellect, teamwork and tenacity, our lawyers deliver the highest quality advice and novel solutions to our clients' legal issues. We are recognized as a global powerhouse for complex transactions, litigation/controversy issues, and regulatory matters, as well as for the open, collaborative relationships we build with clients. Our attorneys, who reflect diverse backgrounds and perspectives, collaborate seamlessly across 50-plus practices and 21 offices in the world‚Äôs major financial centers.
The OpportunityWe are seeking a Legal Technology Data Specialist to join our Firm. Within this position, you will be responsible for performing data analysis and completes projects related to the Firm‚Äôs document management systems such as creating databases, loading, exporting, maintaining and manipulating data, converting and managing electronic files. This position will be based in our New York office and has a hybrid in-office/remote working schedule. Please note that the Firm will not sponsor applicants for work visas for this position.
As the Legal Technology Data Specialist you will:Create and maintain databases such as Relativity and Kira, administer database security and permissions, design views, and layouts.Ensure database indices are correctly set up and updated to optimize searching.Perform database searches to check data, prepare for analytics operations and to assist case teams as needed in locating documents.Perform file transfers to and from the Firm's systems and external sources using various file transfer protocols and methods.Analyze data collections to identify loadable data, duplicative files, etc.Load data to and export data from the Firm‚Äôs databases such as Relativity and Kira, validating deliverables and input to ensure the files conform with industry standards, project specifications, and are compatible with databases. Perform file conversions to meet loading and production specifications.Manipulate data to meet project specifications, e.g. conforming field values, merging data, extracting text strings.Perform tasks related to database maintenance such as record deletions, data back-up, updating existing records, and associated images/native files, field merges, and conforming field values.Prepare document productions, creating production sets, checking endorsements, and redaction settings and exporting files.Perform quality checks productions to ensure load files and final deliverables are valid and work product meets project-specific and industry standards.Perform structured analytics operations (textual near duplicate analysis, email threading, and name normalization), assessing data for suitability of operation, creating associated views and layouts to aid in the presentation and interpretation of the analytics results.Create conceptual analytics indices and works with senior team members in supporting case teams in technology assisted review (TAR) projects.Ensure the integrity of data and soundness of databases by performing periodic checks on database fields, indices, and structure.Troubleshoot and resolve database issues such as missing or corrupt data and images, incorrectly loaded data, database permission issues, and outdated indices.Trace document history by researching requests, email chains, checking load files used and original data sources.Create digital media archive files for preservation in the Firm's Records system.Maintain physical order of source media and other related materials.Assist in testing technical solutions to improve existing project workflows.Work with Legal Technology Project Managers to ensure efficient workflows are adapted and databases are properly maintained and optimally configured.Assess non-standard requests and works with team to develop a work plan.Demonstrates effective interpersonal, written and verbal communication skills to facilitate effective work relationships with others.Manages Firm resources responsibly.Complies with and understands Firm operation, policies and procedures.Performs other related duties as assigned.
QualificationsExperience in Relativity workspace set-up including but not limited to, importing data, preparing productions, analytics, user set-up and group permissions, coding layouts, running complex keyword and dtSearch queries, and workflow customization such as indexing, set-up of views, field/choices, persistent highlighting sets, etc.Knowledge of Relativity structured analyticsKnowledge of EDRM processes as they relate to the various phases of litigation, including demonstrated experience in the EDRM lifecycle such as document collection, processing, review and production. (Last used version of Relativity should not be earlier than 10.0)Familiarity with ESI protocolsKnowledge of various data load file and image formats commonly used in the industry (Concordance DAT, Opticon, IPRO), and ability to validate, create and convert such filesAbility to manipulate data through programmatic means or by using a text editor such as TextPad, ReadySuite, UltraEditFamiliarity with productivity tools used for file transfers and copies (FTP), file compression (RAR and ZIP) and encryption (TrueCrypt)Excellent communications skills needed ‚Äì ability to describe complex technical concepts and ideas in non-technical termsHands-on experience with both traditional SQL, keyword and concept-based search tools and technologies.Familiarity with ESI data processing platforms (e.g., Relativity, eCapture, Nuix, Clearwell, LAW, etc.Ability to perform troubleshooting and learn customized proprietary softwareKnowledge of relevant firm computer software programs (e.g., Outlook, Excel, PowerPoint), with the ability to learn new software and operating systems, as applicableDemonstrates effective interpersonal and communication skills, both verbally and in writingDemonstrates close attention to detailAbility to handle multiple projects and shifting prioritiesAbility to handle sensitive matters and maintain confidentialityAbility to organize and prioritize workAbility to work well in a demanding and fast-paced environmentStrong problem solving and troubleshooting skillsAbility to work well independently as well as effectively within a teamFlexibility to adjust hours and work the hours necessary to meet operating and business needs
Education/ExperienceBachelor's degreeMinimum of one year eDiscovery experience in law firm or litigation support industry, managing databases and assisting in eDiscovery projects
Culture & Life at SkaddenWhat makes Skadden special is our people and the culture, community and spirit of collaboration we have created. We believe in teamwork and inspiring each other to be our best in an atmosphere that promotes professionalism and excellence in all that we do. We know that inclusion, equity and drawing on the strength of a wide spectrum of diverse talent only make us better and is vital to the firm's success. Our goal is for everyone at the firm to enjoy a challenging career with opportunities for development and growth and to support the well-being of our attorneys and professional staff.
BenefitsThe overall well-being of our team is important to us. We offer generous benefits to help you achieve wellness in all areas of your life. Competitive salaries and year-end discretionary bonuses.Comprehensive health care (medical, dental, vision), savings plan/401(k) and voluntary benefits.Generous paid time off.Paid leave options, including parental.In-classroom, remote, and on-demand learning and professional development opportunities.Robust well-being classes and programs.Opportunities to give back and make an impact in local communities.
For further details, please visit: https://www.skadden.com/careers/staff/employee-benefits
The starting base salary for this position is expected to be within the range listed under Salary Details. Actual salary will be determined based on skills, experience (to the extent relevant) and other-job related factors, consistent with applicable law.
Salary Details$95,000 - $105,000
Skadden is an Equal Opportunity Employer (Disability/Vet/other protected categories). For more information, please visit Skadden.com/careers.","Key responsibilities include creating databases, handling data loads and exports, performing quality checks, managing file conversions, and executing structured analytics tasks like email threading and near duplicate analysis. The role involves close collaboration with project managers to ensure efficient workflows and support document productions, search operations, and reporting needs.","Candidates should have at least one year of eDiscovery experience in a law firm or litigation support environment and a bachelor’s degree. Hands-on experience with Relativity (version 10.0 or newer) is essential, including skills in workspace setup, structured analytics, and production preparation. Familiarity with EDRM lifecycle processes, ESI protocols, data formats (DAT, Opticon), and tools like ReadySuite, FTP, and SQL is required. Strong communication, multitasking, and troubleshooting abilities are critical, as is flexibility in adjusting work hours to meet business needs. The salary range for this role is $95,000–$105,000. Skadden offers comprehensive benefits and a collaborative, inclusive work culture.",{' SQL': 'MISC'}
107,Expert Technical Solutions,Data Scientist,"Junior Data Scientist ‚Äì ( Python / Modeling and Operat ions ) 

 Expert Technical Solutions has an immediate opening for a Junior Data Scientist with an industry leading client in Atlanta , GA. Our client is looking for a highly motivated and research oriented Data Scientist who will play a vital role in enhancing our cli ent ‚Äô s contact center solutions through the development of advanced NLP algorithms and models. You will work in a collaborative team environment to explore and create solutions to industry problems using machine learning and state-of-the-art large language models. You bring to this team environment a strong foundation in machine learning and deep learning, as well as the curiosity and grit to see a project to delivery. 

T his is a permanent , HYBRID (2 days onsite, Monday and Tuesday every week) opportunity offering st rong pay, ex cellent growth opportunities, and outstanding benefits.

Responsibilities

 Productizing AI predictive models  Producing data and model accuracy analyses  Developing & maintaining of scripts/tools to automate both new model production and updates to existing model packages  Working with developers to help design automation and tool improvements for model building  Maintaining documentation of processes and projects across all supported languages and environments  Developing knowledge of the internal data sources  Explore high-level, undefined ideas and business problems using structured and unstructured data  Develop product offerings through careful consideration of business value and data analysis  Build and fine-tune deep learning and machine learning models, with an emphasis on large language models  Communicate research findings, technical concepts, and model recommendations effectively to technical and non-technical stakeholders 


 R equired E xperience 

 BS or MS in Computer Science or related field required  Proficiency in Python.  2+ year s‚Äô experience with bash, python, or equivalent script development, deployment, and execution.  1 + year of Windows experience with remote access and dos shell.  Minimum of 1 year of experience implementing machine learning and NLP models using real-life (‚Äúindustry‚Äù) data  Experience working with deep learning models  Knowledge of statistical techniques and concepts (regression, statistical tests and proper usage, etc.)  Desire and ability to learn and continually expand knowledge in the data science, machine learning, and speech analytics. 


 Desired S kills 

 Proficiency with one more deep learning libraries (PyTorch, TensorFlow, JAX, etc.)  Experience deploying NLP models in production environments, ensuring scalability and performance  Experience with building and/or fine-tuning large language models  Experience as part of a software organization","The Junior Data Scientist will contribute to enhancing contact center solutions by developing advanced Natural Language Processing (NLP) algorithms and predictive models. Responsibilities include productizing AI models, analyzing data and model accuracy, automating model development workflows, maintaining documentation, and collaborating with developers to improve tools and processes. The role also involves working with structured and unstructured data, fine-tuning machine learning models—particularly large language models—and effectively communicating insights to technical and non-technical stakeholders.","To qualify, candidates should have a BS or MS in Computer Science or a related field, proficiency in Python, and at least one year of experience implementing machine learning/NLP models using industry data. Experience with scripting (bash or similar), remote Windows environments, deep learning, and statistical techniques is also required. Desired skills include familiarity with deep learning libraries (e.g., PyTorch, TensorFlow), NLP model deployment in production, and experience working in a software development setting. This is a hybrid, full-time opportunity based in Atlanta, GA, offering strong compensation, excellent benefits, and professional growth potential.","{' Python': 'MISC', ' PyTorch': 'MISC', ' TensorFlow': 'MISC'}"
108,Talentify.io,Data Analyst,"Employer Industry: Solar Energy

Why Consider This Job Opportunity

 Salary up to $100,000 Opportunity for career advancement and growth within the organization Work remotely from home Health, dental, vision, and life insurance benefits Paid time off, sick leave, and holidays Dynamic and fast-paced work environment

What To Expect (Job Responsibilities)

 Work with large amounts of data to draw meaningful conclusions Develop and implement data collection systems and strategies Provide regular reporting and analysis to the team Collaborate with cross-functional teams to identify areas for improvement Provide training and support to team members on data analysis techniques

What Is Required (Qualifications)

 Minimum two years of experience with DOMO MajorDOMO Certification Required 3+ years experience in data analysis, reporting, business intelligence or financial analysis Bachelor‚Äôs Degree in Business, Statistics, Mathematics, Analytics, Computer Sciences or related field Experience with SQL, and DOMO

How To Stand Out (Preferred Qualifications)

 2 years experience in providing people analytics reporting to organizations

#SolarEnergy #DataAnalysis #RemoteWork #CareerGrowth #CompetitivePay

At Talentify, we prioritize candidate privacy and champion equal-opportunity employment. Central to our mission is our partnership with companies that share this commitment. We aim to foster a fair, transparent, and secure hiring environment for all. If you encounter any employer not adhering to these principles, please bring it to our attention immediately.

Talentify is not the EOR (Employer of Record) for this position. Our role in this specific opportunity is to connect outstanding candidates with a top-tier employer.

Talentify helps candidates around the world to discover and stay focused on the jobs they want until they can complete a full application in the hiring company career page/ATS.","Analyze large data sets to uncover actionable insights and trends. Design, implement, and optimize data collection systems and strategies. Produce regular reports and dashboards to support various teams.
 Collaborate cross-functionally to identify business improvement opportunities. Provide training and support on data visualization tools and analytics practices.","Minimum 3 years of experience in data analysis, business intelligence, or financial reporting. Strong command of SQL and advanced data tools; expertise in DOMO is required. MajorDOMO Certification is a must. Bachelor’s degree in a related field (e.g., Business, Analytics, Statistics, Computer Science). At least 2 years of experience specifically using DOMO for analytics and reporting.","{' SQL': 'MISC', ' DOMO': 'MISC', ' MajorDOMO Certification': 'MISC'}"
109,AbbVie,Data Scientist,"Company Description

AbbVie's mission is to discover and deliver innovative medicines and solutions that solve serious health issues today and address the medical challenges of tomorrow. We strive to have a remarkable impact on people's lives across several key therapeutic areas ‚Äì immunology, oncology, neuroscience, and eye care ‚Äì and products and services in our Allergan Aesthetics portfolio. For more information about AbbVie, please visit us at www.abbvie.com. Follow @abbvie on Twitter, Facebook, Instagram, YouTube and LinkedIn.

Job Description

Purpose

AbbVie Data Science is the best-in-class team within its cross-industry peer group and is responsible for bringing people, process, and technology together to generate business value from clinical trials data. Our operational model is exemplified through execution and innovation. This role is key to ensuring successful delivery against the program- and study-level accountabilities assigned to Data and Statistical Sciences.

Responsibilities

Aligns DSS study teams with program- and study-level strategies. Assigned programs may include programs that are of low complexity and size. For assigned programs and studies, leads the DSS Study Team and represents DS as a member of the cross-functional study teamFor assigned programs and studies, acts as single point of contact and accountable operational lead from DSS. Coordinates associated DSS study teams to meet operational objectives. Engages and connects global functional and cross-functional teams at the study levelInteracts with and influences cross-functional team members to achieve program objectivesUtilizes operational analytics and project management tools to optimize execution of programs and studies, to manage internal and external resources, to track study progress, and to prepare study status reports. Anticipates and identifies issues that could affect timelines or quality and develops options and solutionsEnsures adherence to federal regulations and applicable local regulations, Good Clinical Practices (GCPs), ICH Guidelines, AbbVie Standard Operating Procedures (SOPs), and to functional quality standards. Stays abreast of new and/or evolving local regulations, guidelines and policies related to clinical development. If assigned, participates as the DS study owner in regulatory inspections and internal quality auditsParticipates in oversight of vendors and provides feedback related to clinical trial operations, issues, and trends in performanceResponsible for coaching and mentoring team membersLeads DSS innovation and process improvement initiatives and participates in cross-functional initiativesConducts study execution ‚Äúlessons learned‚Äù across functionsMay include indirect supervision of employee as well as supervision of work of contract resources

Continuous sitting for prolonged periods (more than 2 consecutive hours in an 8 hr day) is required

Qualifications

Bachelor‚Äôs degree in business, management information systems, computer science, life sciences or equivalent. Master‚Äôs preferred. PMP Certification or Lean Six Sigma Green Belt desired.Must have 6+ years of pharma / clinical research / data management / health care experience or 8+ years of project management experience (and / or applicable work experience).In-depth understanding of clinical trial processes and clinical technology. Management of a clinical trial from initiation through to completion in a lead role is preferredDemonstrated performance as a functional leaderDemonstrated ability to influence others without direct authorityDemonstrated ability to successfully coach / mentor in a matrix environmentDemonstrated effective communication skillsDemonstrated effective analytical skills

Additional Information

Applicable only to applicants applying to a position in any location with pay disclosure requirements under state or local law:

The compensation range described below is the range of possible base pay compensation that the Company believes in good faith it will pay for this role at the time of this posting based on the job grade for this position. Individual compensation paid within this range will depend on many factors including geographic location, and we may ultimately pay more or less than the posted range. This range may be modified in the future. We offer a comprehensive package of benefits including paid time off (vacation, holidays, sick), medical/dental/vision insurance and 401(k) to eligible employees. This job is eligible to participate in our short-term incentive programs. This job is eligible to participate in our long-term incentive programs

Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, incentive, benefits, or any other form of compensation and benefits that are allocable to a particular employee remains in the Company's sole and absolute discretion unless and until paid and may be modified at the Company‚Äôs sole and absolute discretion, consistent with applicable law.

AbbVie is committed to operating with integrity, driving innovation, transforming lives, serving our community and embracing diversity and inclusion. It is AbbVie‚Äôs policy to employ qualified persons of the greatest ability without discrimination against any employee or applicant for employment because of race, color, religion, national origin, age, sex (including pregnancy), physical or mental disability, medical condition, genetic information, gender identity or expression, sexual orientation, marital status, status as a protected veteran, or any other legally protected group status.","As a key player within AbbVie’s Data and Statistical Sciences (DSS) team, the Data Science Operational Lead coordinates and oversees program- and study-level clinical trial data operations. This includes leading DSS study teams, aligning project execution with strategic goals, tracking milestones, and ensuring compliance with regulatory and quality standards. The role requires strong cross-functional collaboration, issue resolution, vendor oversight, and active participation in innovation and continuous improvement initiatives. It may involve indirect supervision of staff and contract resources, and participation in inspections and audits.","a bachelor's degree (master’s preferred) in a relevant field and at least 6 years of experience in pharma, clinical research, or healthcare data management. Candidates should demonstrate clinical trial knowledge, leadership ability, strong analytical and communication skills, and experience mentoring others in a matrix environment. Certifications such as PMP or Lean Six Sigma Green Belt are desirable.","{' PMP': 'MISC', ' Lean Six Sigma Green Belt': 'MISC'}"
113,Salesforce,Data Analyst,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category

Sales

Job Details

About Salesforce

We‚Äôre Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too ‚Äî driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good ‚Äì you‚Äôve come to the right place.

About The Team

The Partner Program Strategy team is a high-performance team chartered with defining the future of Salesforce‚Äôs partner ecosystem. We work on the most pressing issues for the partner and sales organizations and have the regular senior executive visibility that goes with it. We succeed if we ensure that the partner program meets the accelerating and changing needs of our partners and customers. Our team is responsible for ensuring that the partner ecosystem continues to have the capacity and competency required to deliver on our ambitious growth targets. The background of the team is a mix of top-tier strategic consulting, investment banking, strong operational experience, and deep knowledge of the enterprise IT partner ecosystem (SIs, ISVs, MSP, Reseller, VARs, BPOs, etc.)

About The Role

The Partner Program Strategy Analyst will work alongside the Senior Manager of Partner Program Strategy to scope and deliver cross-functional transformation initiatives for the Salesforce Partner Program. Examples of projects you will work on range from the very strategic to the very operational: Program Scorecard design, business model definition, process improvement, data modeling, data insight analysis, visualization and data processing tool development, project management, and regular business performance reviews. You will interact with all areas of the Industries & Partners organization with regular exposure to senior executives, as well as working closely with business partners in the technology, strategy, operation, marketing and directly with the Salesforce partner ecosystem.

The successful candidate will possess superior analytical and strategic thinking capabilities, a strong work ethic, ability to learn fast and handle ambiguity, and be highly collaborative. Demonstrated experience in go-to-market strategy, partner management, program design, and tracking performance through concrete KPIs is a must. We consider candidates from other business or engineering backgrounds that can demonstrate solid analytical and business capabilities.

This is a team that provides excellent opportunities for advancement and learning for top performers.

Responsibilities

Data Management and Automation:

Perform data migration activities - data collection, data cleansing, data transformation for all master data & metadata and loading using data loader or other data management tools, by working with key usersWrangle and analyze large datasets using Salesforce, SQL/Snowflake, Tableau Prep etc, to identify and handle risks in various processesDevelop and maintain robust data validation processes to ensure data accuracy across different dashboardsDevelop automation and improve process to accelerate and simplify data analysis and data processing

Reporting And Data Insights

Provide recommendations for reporting improvements and develop proof-of-concept processes for effective Salesforce and data managementSupport ad-hoc dashboard and data requests, offering insights to various teams, including the partner program scorecard design, metrics update, A-B testing, and scenario analysis

Dashboard Design And Maintenance

Develop UI/UX prototypes or mockups for dashboards to improve user engagementDesign, build, and maintain interactive dashboards in Tableau and Tableau CRM, ensuring efficient performance and handling of row-level securityBuild dashboard tutorials, document process flows, and establish standards and requirements for various use cases, catering to both technical and non-technical audiencesConstruct and deliver comprehensive training on new and existing dashboards to diverse business units.

Program Management

Coordinate and lead cross-functional meetings, document decisions & follow-up on actionsManage projects including tracking tasks, issues, system requirements, and risksImprove enablement/change management processes

Required Skills / Experience

2+ years industry experience in business analysis, data processing, partner management, program management, or go-to-market strategyIntermediate level of experience with databases, data processing, data analysis tool, visualization tool (Tableau preferred), and writing SQL (Oracle, SQL Server, MySQL, etc.. ), knowledge if Python, R a plusPassion for visualization, reporting, and documentation with confirmed ability building visualization with the ability to quickly understand technical subjects and learn new emerging technologiesHigh level of confidence and comfort in working autonomously without constant supervision (self-starter, strong initiative, fast learner). Adaptable and resourceful team player, capable of growing in dynamic environments with changing priorities.Ability to manage multiple projects simultaneously with minimal supervisionExperience defining, documenting, managing, and improving processesCommitment to innovation and beginner‚Äôs mind approach to recognizing and solving challengesInitiative to see through transformative projects from the big picture to the operational detail of executionExcellent executive-level verbal and written communication skills

Preferred Skills / Experience

Familiarity with the Salesforce Partner Program ecosystemDemonstrated Salesforce proficiency via active certifications

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.

Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.

ÔªøSalesforce welcomes all.

Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.

For Washington-based roles, the base salary hiring range for this position is $79,900 to $109,900.

For California-based roles, the base salary hiring range for this position is $87,200 to $119,900.

Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.","Salesforce is seeking a Partner Program Strategy Analyst to support its Partner Program Strategy team. The role involves managing and automating large datasets, analyzing partner-related data, and designing and maintaining dashboards to support strategic initiatives across the Salesforce partner ecosystem. Responsibilities also include improving data validation processes, performing ad-hoc data requests and A/B testing, and collaborating with cross-functional teams to drive data-driven decisions and reporting improvements.","Requirements include 2+ years of experience in data analysis or program management, proficiency in SQL and data visualization tools (preferably Tableau), and experience managing projects independently in a fast-paced environment. Familiarity with Salesforce’s partner ecosystem and certifications are a plus. Strong communication, analytical thinking, and project management skills are essential.","{' SQL': 'MISC', ' Tableau': 'MISC', ' Salesforce': 'ORG'}"
114,Gartner,Data Analyst,"Data Analyst Lead, Business Analytics

The Global Product Management (GPM) organization is responsible for business performance of all research products. The Research Business Analytics (RBA) team is part of GPM and performs analysis related to all aspects of Gartner‚Äôs Research. This includes client value drivers: Research content, research interaction, and the research role in conferences and events. RBA also supports the Research & Advisory (R&A) organization by enabling and performing analysis running from client retention analytics, associate performance analytics, budget and financial analysis (in partnership with the finance organization), and client demand sensing. We power fact-based decision making by providing data, insights, and analytic tools to continuously improve our business ‚Äì operationally and strategically.

We are looking for a Data analyst who has a passion for analytical problem solving to be part of our growing team. This individual will solve a wide range of problems related to content analytics, and interaction analytics, demand sensing, staffing models, cost reporting, automation, standard reporting, and ad-hoc analytics. Initial projects are likely to focus on Client Demand Sensing, and aligning Research & Advisory expert staffing to areas with the largest economic opportunity. Individuals in this role will work closely with Research Business Analytics leadership to structure problems, identify data sources, perform analysis, and communicate findings. Strong performers will build skills to independently own project workstreams and interact with stakeholders. Projects will include a mix of team problem solving and independent problem solving. Some projects will also involve automation and collaboration with the Information Technology team.

What you‚Äôll do:

Partner with GPM and RBA colleagues to do analysis that surfaces actionable insight for the Research & Advisory organization. Effectively communicate findings to drive adoption and implementation. Build dashboards and reporting.

Project ownership: Contribute to key projects following rollout plan, success criteria and metrics.

Domain expertise: Become a deep subject-matter expert on Gartner‚Äôs data, analytic tools, reports & data infrastructure. Take responsibility for problem solving, root cause analysis, and devising testing methodologies for validation and articulately explaining data sources to senior audiences.

Continuous improvement: Support and enable improvement initiatives related both to RBA deliverables (e.g. new, innovative data sources, analytic insights, tools) as well as operational process improvement (e.g. improving RBA processes and communications).

Collaborate with the Information Technology team and data scientists to ensure data quality, integrity, and consistency.

Job Requirements:

Experience: 5-7 years of experience involving analysis of large volumes of data with strong hands-on experience with analytical tools. Ability to gather, analyze, restructure, identify and articulate insights from qualitative and quantitative data. This role requires U.S. work authorization.

Education: Bachelor‚Äôs Degree, preferably with a quantitative concentration (e.g., statistics, data science, mathematics, engineering, operational research, computer science, or economics).

Exceptional problem solving: Proven track record of solving complex problems, thinking creatively, and using data to tell a story.

Leadership: Shown ability to engage teams and key stakeholders.

Technical competency: Advanced Excel. Intermediate SQL, Python/R.

Collaboration: Strong collaboration and influencing.

Communication: Strong verbal and written communication as well as the ability to work independently.

Location: Gartner offers a hybrid, flexible environment, with remote work that allows associates great flexibility to work from home, and opportunities to connect with colleagues for moments that matter on-site. Candidates that apply will need to reside within a reasonable proximity to a Gartner‚Äôs Centers of Excellence office location (Irving, TX; Fort Myers, FL; Stamford, CT).

Who are we?

At Gartner, Inc. (NYSE: IT), we deliver actionable, objective insight that drives smarter decisions and stronger performance on an organization‚Äôs mission-critical priorities. We‚Äôve grown exponentially since our founding in 1979 and we're proud to have over 19,500 associates globally that support over 15,000 client enterprises in more than 100 countries.

What makes Gartner a great place to work?

Our teams are composed of individuals from different geographies, cultures, religions, ethnicities, races, genders, sexual orientations, abilities and generations. We believe that a diversity of experiences makes us stronger‚Äîas individuals, as communities and as an organization. That‚Äôs why we're recognized worldwide as a great place to work year after year. We've been recognized by Fortune as one of the World‚Äôs Most Admired Companies, named a Best Place to Work for LGBTQ Equality by the Human Rights Campaign Corporate Equality Index and a Best Place to Work for Disability Inclusion by the Disability Equality Index. Looking for a place to turn your big ideas into reality? Join 

What we offer:

Our people are our most valuable asset, so we invest in them from Day 1. When you join our team, you‚Äôll have access to a vast array of benefits to help you live your life well. These resources are designed to support your physical, financial and emotional well-being. We encourage continued personal and professional growth through ongoing learning and development opportunities. Our employee resource groups, charity match and volunteer programs keep you connected to your internal Gartner community and causes that matter to you.

Gartner believes in fair and equitable pay. A reasonable estimate of the base salary range for this role is 88,000 USD - 115,920 USD. Please note that actual salaries may vary within the range, or be above or below the range, based on factors including, but not limited to, education, training, experience, professional achievement, business need, and location. In addition to base salary, employees will participate in either an annual bonus plan based on company and individual performance, or a role-based, uncapped sales incentive plan. Our talent acquisition team will provide the specific opportunity on our bonus or incentive programs to eligible candidates. We also offer market leading benefit programs including generous PTO, a 401k match up to $7,200 per year, the opportunity to purchase company stock at a discount, and more.

The policy of Gartner is to provide equal employment opportunities to all applicants and employees without regard to race, color, creed, religion, sex, sexual orientation, gender identity, marital status, citizenship status, age, national origin, ancestry, disability, veteran status, or any other legally protected status and to affirmatively seek to advance the principles of equal employment opportunity.

Gartner is committed to being an Equal Opportunity Employer and offers opportunities to all job seekers, including job seekers with disabilities. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access the Company‚Äôs career webpage as a result of your disability. You may request reasonable accommodations by calling Human Resources at +1 (203) 964-0096 or by sending an email to ApplicantAccommodations@gartner.com.

Job Requisition ID:87757

By submitting your information and application, you confirm that you have read and agree to the country or regional recruitment notice linked below applicable to your place of residence.

Gartner Applicant Privacy Link: https://jobs.gartner.com/applicant-privacy-policy

For efficient navigation through the application, please only use the back button within the application, not the back arrow within your browser.","Gartner is hiring a Data Analyst Lead within its Research Business Analytics (RBA) team, part of the Global Product Management organization. This role is focused on leveraging data to drive insight into Research & Advisory (R&A) performance, including content analytics, client demand, staffing models, and cost reporting. The analyst will independently lead analytical projects, develop dashboards, and communicate findings to senior stakeholders. Key projects will align R&A staffing to client demand and economic opportunity, supported by collaboration with IT and data science teams.","5–7 years of experience with large-scale data analysis, a bachelor’s degree in a quantitative field, and proficiency in Excel, SQL, and Python/R. Strong problem-solving skills, communication, and the ability to work cross-functionally are essential. The role is hybrid with proximity required to Gartner's Centers of Excellence (Irving, TX; Fort Myers, FL; Stamford, CT). The estimated base salary range is $88,000–$115,920, plus bonus potential and comprehensive benefits.","{' Excel': 'MISC', ' SQL': 'MISC', ' Python/R': 'MISC'}"
115,T-Mobile,Data Analyst,"Be unstoppable with us!

T-Mobile is synonymous with innovation‚Äìand you could be part of the team that disrupted an entire industry! We reinvented customer service, brought real 5G to the nation, and now we‚Äôre shaping the future of technology in wireless and beyond. Our work is as exciting as it is rewarding, so consider the career opportunity below as your invitation to grow with us, make big things happen with us, above all, #BEYOU with us. Together, we won‚Äôt stop!

The Product Manager, Data focuses on how data is employed throughout the Marketing Technology ecosystem to contextualize and automate experiences. This individual helps shape the vision for the contextual experience future of T-Mobile, connecting the customer experience across channels and touchpoints through a strategic data and product lens. They maintain centralized, strategic coordination across multiple business, technology, analytics, and product teams to deliver data driven personalization across channels. They drive creation of the customer profile and contextual data user stories and acceptance criteria, facilitate workshops to maintain and groom a detailed use case/data backlog, participate in agile ceremonies, and own creation and maintenance of a detailed reason to demonstrate value delivered. They are responsible for maintaining the status and progress of features and experiences and creating/maintaining the overall contextual data roadmap. The Contextual Data Product Manager combines a customer experience orientation with data, customer profiles, propensity and data models expertise to drive contextualization/personalization initiatives, innovation, continuous improvement, and efficient scaling to deliver business results.

Job Responsibilities:

Vision, Strategy, and Analysis

Owns product end to end for products or features with moderate level of complexity and scope. This includes creating, managing, maintaining and communicating product vision and strategy.Identifies target customer(s) for existing or future products drives end user product research.Partners with business and internal/external collaborators to understand current customer experiences, identifies areas of opportunity.Conducts analysis of quantitative and qualitative data to identify product innovation opportunities or root cause of issues, and assess opportunity size and impact. May work with data scientists to answer sophisticated questions or identify relevant insights from data.Uses rapid hypothesis driven testing methodologies and experiments (i.e. paper prototype, A/B testing, etc.) to advise direction, prioritize investment.Conducts cost-benefit / return on investment / NPV analysis, competitive product analysis, to support decision making.Works with partners and follows enterprise process to secure and maintain product funding.Communicates, influences, and sells ideas at Director level and below. This includes regularly delivering product presentations.Conducts specific ad hoc analysis and provides insights to management on request.Recommends product feature set and positioning strategies to improve customer experience, and drive or support growth.Develops and maintains current understanding of tech trends. Assesses how trends impact the roadmap or create opportunity for innovation of the product.


Customer Evangelist

Uses customer insights for product vision, strategy, roadmap, priorities.Dedicates time to customers actively meeting with them to build deeper empathy and understand their needs and priorities.Actively looks for opportunities to delight or meet customer‚Äôs unmet needs.Evangelizes and advocates for the customer both internally (IC through C level) and externally, perpetuating the customer-first attitude.


Product Execution / Delivery

Translates product/platform strategy by writing detailed features and user stories consumable for Dev teams for moderately sophisticated products. This work may include creation of prototypes.Owns and manages product backlog and priorities with our business and technology partners.Scopes and prioritizes activities based on business and customer impact.Collaborates with Architecture and Dev teams to ensure technical debt and long term technical investment is factored into roadmap.Ensures existing production defects are factored into regular backlog prioritization for resolution based on priority.Collaborates with partners and Dev / Execution teams to create and communicate anticipated release schedule.Generates and maintains dashboards and reports that supervise product health and success metrics.Runs beta and pilot programs with early-stage products and samples.Supports sales, marketing, and other teams with the vital product knowledge and additional documentation.Assists with the overall execution relating to all aspects of the software development process, from defining the strategy and architecture through deployment and support.Communicates technical challenges to team members and makes educated trade-off decisions based on those challenges.Accountable for product quality and performance in production environment. Accountable for product team response in event of critical or high impacting defect, including communications to partners at all levels.Identify execution, operational, organizational issues that impede product success. Drive improvement plan to change or resolve issues (within sphere of influence).


Relationship & People, Professional Development

Collaborates and develops positive working relationships with many technical and non-technical teams, including sales, commercial accounting, marketing, legal, go-to-market, and finance. Works with outside partners and other third parties.


Education:

Bachelor's Degree or equivalent experience required.


Work Experience:

Required:

4 plus years Relevant Product Management experience in an agile software product development environment.


Preferred:

Demonstrated experience in MarTech data and product management for personalization and omnichannel data needs across a wide array of platforms. 4-5 years‚Äô product management experience with focus on driving customer experience Demonstrated experience in marketing technologies including Adobe Experience Cloud, next best action technologies, and Salesforce Marketing Cloud Past experience working on data products, data warehouses, and/or other data-centric software solutions Experience using data analysis tools (i.e. SQL, Tableau) to extract data and synthesize into actionable insights A minimum of 5 years in a data product management role, with a strong track record of developing data as a product that advises business decisions and powers AI algorithms. 


Knowledge, Skills and Abilities:

Communication Proven track record to effectively and efficiently connect with Leadership, while employing a high degree of collaboration and influence. (Required)Business Analytics Strong analytical skills with demonstrated ability to identify/analyze/synthesize product use data. (Required)Project Management Experience in delivering large and sophisticated business/technology initiatives. (Required)SCRUM Proven success in delivering software with Agile Scrum methodologies (Required)Agile Methodologies Proven success in delivering software with Agile Scrum methodologies (Required)Technical Writing Strong requirements elicitation, and proven writing skills including the ability to write concisely and clearly for different audiences. (Required)Agile Project Management Experience with Agile backlog/project management tools. (Required)Collaboration Experience with successive elaboration and ability to develop Initiatives, Features and User Stories that the DevOps teams can ingest. (Required) At least 18 years of age Legally authorized to work in the United States


Travel:

Travel Required (Yes/No):Yes

DOT Regulated:

DOT Regulated Position (Yes/No):No

Safety Sensitive Position (Yes/No):No

Washington Pay Range : $130,200.00 - $176,100.00

The pay range above is the general base pay range for a successful candidate in the state listed. The successful candidate‚Äôs actual pay will be based on various factors, such as work location, qualifications, and experience, so the actual starting pay may be above or below this range. At T-Mobile, employees in regular, non-temporary roles are eligible for an annual bonus or periodic sales incentive or bonus, based on their role. Most Corporate employees are eligible for a year-end bonus based on company and/or individual performance and which is set at a percentage of the employee‚Äôs eligible earnings in the prior year. Certain positions in Customer Care are eligible for monthly bonuses based on individual and/or team performance, while Retail and Business Sales roles are eligible for monthly or quarterly sales incentives. And since we are ALL owners, EVERY employee at T-Mobile is eligible for an Annual Stock Grant.

At T-Mobile, our benefits exemplify the spirit of One Team, Together! A big part of how we care for one another is working to ensure our benefits evolve to meet the needs of our team members. Full and part-time employees have access to the same benefits when eligible. We cover all of the bases, offering‚ÄØmedical, dental and vision insurance, a flexible spending account, 401(k), employee stock‚ÄØgrants, employee stock purchase‚ÄØplan, paid time off and up to paid 12 holidays - which total about 4 weeks for new full-time employees and about‚ÄØ2.5 weeks for new part-time‚ÄØemployees annually - paid parental and family leave,‚ÄØfamily building benefits, back-up care, enhanced family support, childcare subsidy,‚ÄØtuition‚ÄØassistance, college coaching, short and long term disability, voluntary AD&D coverage, voluntary accident coverage, voluntary life insurance, voluntary disability insurance, and voluntary long-term care insurance.

We don't stop there- eligible employees can receive mobile service & home internet discounts, pet insurance, and access to commuter and transit programs! To learn about T-Mobile‚Äôs amazing benefits,‚ÄØcheck out‚ÄØwww.t-mobilebenefits.com.‚ÄØ

Never stop growing!

T-Mobile doesn‚Äôt have a corporate ladder‚Äìit‚Äôs more like a jungle gym of possibilities! We love helping our employees grow in their careers, because it‚Äôs that shared drive to aim high that drives our business and our culture forward.

T-Mobile USA, Inc. is an Equal Opportunity Employer. All decisions concerning the employment relationship will be made without regard to age, race, ethnicity, color, religion, creed, sex, sexual orientation, gender identity or expression, national origin, religious affiliation, marital status, citizenship status, veteran status, the presence of any physical or mental disability, or any other status or characteristic protected by federal, state, or local law. Discrimination, retaliation or harassment based upon any of these factors is wholly inconsistent with how we do business and will not be tolerated.

Talent comes in all forms at the Un-carrier. If you are an individual with a disability and need reasonable accommodation at any point in the application or interview process, please let us know by emailing ApplicantAccommodation@t-mobile.com or calling 1-844-873-9500. Please note, this contact channel is not a means to apply for or inquire about a position and we are unable to respond to non-accommodation related requests.","T-Mobile is seeking a Product Manager, Data to drive personalized, data-powered customer experiences within its Marketing Technology ecosystem. This role is focused on the strategy, development, and implementation of data products that contextualize and automate omnichannel engagement. Responsibilities include managing data-driven product backlogs, writing user stories, leading cross-functional workshops, and executing strategic roadmaps to enable personalized experiences across the customer journey.","The ideal candidate has 4+ years in product management, preferably in MarTech and data-centric software solutions, with experience in tools like Salesforce Marketing Cloud, Adobe Experience Cloud, SQL, and Tableau. Strong analytical, collaboration, and agile delivery skills are essential. The role offers hybrid work options, travel flexibility, and a comprehensive benefits package including bonuses, stock options, paid leave, and more. The pay range is $130,200–$176,100, based on location and experience.","{' Salesforce Marketing Cloud': 'MISC', ' Adobe Experience Cloud': 'MISC', ' SQL': 'MISC', ' Tableau': 'MISC'}"
117,D. E. Shaw Research,Data Engineer,"Data Infrastructure Engineers are sought to join our interdisciplinary team in New York City. This high-visibility, high-impact role will offer an exciting opportunity to create data infrastructure for our drug discovery efforts, working closely with our world-class team of chemists, biologists, machine learning engineers and researchers, and computer scientists.
Successful hires will directly contribute to creating systems and infrastructure for modeling, curating, and indexing the petabytes of data generated by our special-purpose supercomputers and our large Linux HPC and GPU clusters; to implementing pipelines for processing computational and experimental data sets; and to developing and maintaining data management policies and toolkits for drug discovery data processing.
Ideal candidates will have extensive experience with large-scale data management; strong Python programming skills; experience with ML systems, frameworks, and data lifecycles; and a background in data structures and algorithms. Relevant areas of expertise include engineering of large-scale chemical databases, experience with architecting infrastructure for the handling of life science data, fluency with UNIX/Linux command-line tools like awk and sed, and familiarity writing scientific software, but specific knowledge of any of these areas is less critical than intellectual curiosity, versatility, and a track record of achievement.
D. E. Shaw Research develops and uses advanced computational technologies to understand the behavior of biologically and pharmaceutically significant molecules at an atomic level of detail, and to design precisely targeted, highly selective drugs for the treatment of various diseases. Among our core technologies is a proprietary special-purpose supercomputer called ANTON¬Æ which we designed and constructed to perform molecular dynamics simulations more than 100 times faster than the world's fastest general-purpose supercomputers. We develop and refine advanced biomolecular modeling methods, software, and machine learning techniques in order to pursue both internal and collaborative drug discovery programs. Our research, technologies, and pharmaceutical expertise have each played an important role in bringing six drugs into clinical trials. We are looking to add innovative contributors who share our commitment to fostering a stimulating, positive, and collaborative work environment. To submit an application, please use the link provided below:
https://apply.deshawresearch.com/careers/Register?pipelineId=882&source=LinkedIn
D. E. Shaw Research is an equal opportunity employer, dedicated to the goal of building a diverse workforce. We embrace diversity along all dimensions, and respect and value the unique qualities, perspectives, and identities of every person in our group. We welcome inquiries from all exceptionally well-qualified applicants, regardless of race, color, nationality, national or ethnic origin, religion or religious belief, caste, gender identity, pregnancy, caregiver status, age, military service eligibility, veteran status, sexual orientation, marital or civil partner status, disability, or status in any other category protected in this regard by law in any jurisdiction in which we operate.
The expected annual base salary for this position is $230,000‚Äì$550,000. Our compensation package also includes variable compensation in the form of sign-on and year-end bonuses, and generous benefits, including relocation and immigration assistance. The applicable annual base salary paid to a successful applicant will be determined based on multiple factors including the nature and extent of prior experience and educational background. We follow a hybrid work schedule, in which employees work from the office on Tuesday through Thursday and have the option of working from home on Monday and Friday.","The Data Infrastructure Engineer at D. E. Shaw Research will play a key role in building robust infrastructure to support cutting-edge drug discovery efforts. This includes creating and maintaining systems for modeling, indexing, and curating massive datasets generated by proprietary supercomputers and HPC/GPU clusters. The role involves implementing data pipelines for both experimental and computational data, developing tools and policies for data management, and collaborating closely with chemists, biologists, and ML researchers to streamline workflows and accelerate scientific insights.","Ideal candidates should have strong Python programming skills, deep experience in large-scale data management, and a solid foundation in data structures and algorithms. Familiarity with UNIX/Linux command-line tools, scientific software development, and machine learning data workflows is highly valuable. While specific domain expertise in life sciences or chemical data systems is a plus, the most important qualities are intellectual curiosity, versatility, and a track record of technical excellence.","{' Python': 'MISC', ' UNIX/Linux': 'MISC'}"
118,Lemon Tek,Data Engineer,"Join our dynamic team at Pylon Tech, a leading fintech company revolutionizing the industry with innovative solutions. We are seeking a talented and experienced Data Engineer to drive our big data initiatives, working with cutting-edge technologies in a fast-paced and collaborative environment.
As a Data Engineer at Pylon Tech, you will play a pivotal role in the development and optimization of our big data infrastructure. The ideal candidate will have 3 to 5 years of hands-on experience working with big data tools such as Spark, Hadoop, and Hive. You will be responsible for designing, implementing, and maintaining robust data pipelines to support our analytics and business intelligence needs.
Key Responsibilities:- Develop and maintain scalable data pipelines to ingest, process, and analyze large volumes of financial data.- Collaborate with cross-functional teams to understand data requirements and implement effective data solutions.- Optimize data processing workflows for efficiency, reliability, and performance.- Implement data quality checks and ensure data integrity throughout the pipeline.- Work closely with data scientists to support their analytical needs and model development.- Stay updated with industry trends and best practices in big data technologies.
Qualifications:- Bachelor's degree in Computer Science, Engineering, or related field.- 3 to 5 years of experience as a Data Engineer in a big data environment, preferably in fintech.- Solid understanding of big data tools and frameworks such as Spark, Hadoop, and Hive.- Proficiency in programming languages such as Python, Scala, or Java.- Experience with cloud platforms such as AWS, Azure, or Google Cloud.- Strong SQL skills and experience with relational databases.- Excellent problem-solving skills and attention to detail.- Ability to work independently and in a team-oriented, collaborative environment.
Why Join Us:- Opportunity to work with cutting-edge technologies in the fintech industry.- Collaborative and inclusive work culture that values innovation and creativity.- Competitive salary and benefits package.- Professional development opportunities and room for growth within the company.- Exciting challenges and projects that make a real impact on the business.
If you are passionate about big data, fintech innovation, and are ready to take on new challenges, we would love to hear from you! Apply now to join our talented team and contribute to the future of finance.","At Pylon Tech, the Data Engineer will play a crucial role in building and maintaining scalable big data infrastructure to support analytics and business intelligence across the organization. Responsibilities include developing efficient data pipelines, optimizing workflows, ensuring data quality, and collaborating with cross-functional teams, including data scientists, to enable effective model development and data-driven decision-making. The role offers a hands-on opportunity to work with large volumes of financial data using advanced tools and technologies like Spark, Hadoop, and Hive, while staying at the forefront of fintech innovation.","Qualified candidates should have 3 to 5 years of experience in a big data environment, ideally within fintech, along with a bachelor’s degree in computer science or a related field. Proficiency in Python, Scala, or Java is essential, as well as experience with cloud platforms such as AWS, Azure, or Google Cloud. Strong SQL skills, attention to detail, and the ability to thrive both independently and collaboratively are also key. Pylon Tech offers a dynamic, innovative work culture, competitive compensation, and significant opportunities for growth and professional development.","{' Python': 'MISC', ' Scala': 'MISC', ' Java': 'MISC', ' SQL': 'MISC'}"
120,Jacobs,Data Scientist,"WES0004NS

Your Impact

Our People & Places Solutions business ‚Äì reinforces our drive to improve the lives of people everywhere and epitomizes the ""why"" of what we do ‚Äì the tremendous positive impact and value our solutions bring to our communities and society as a whole. From facilities delivering life-saving therapies and ensuring clean water to enabling the connection of people through all modes of transportation and providing access to technology ‚Äì we're integrating a multitude of these solution elements to build the smart environments of tomorrow.

Start your Jacobs career with a company that inspires and empowers you to deliver your best work so you can evolve, grow and succeed ‚Äì today and into tomorrow.

At Jacobs, we‚Äôre putting our knowledge and imagination together to shape the next generation of innovative transportation solutions, especially in travel demand modeling, traffic microsimulation and Big Data. If you want to join a company invested in you,‚ÄØyour success,‚ÄØand the global community then join us as a Transportation Data Scientist in Austin, Texas.

The ideal candidate will be a motivated individual with recognized expertise in data management, statistics, computer languages, business process engineering, and system integration with the ability to train Jacob‚Äôs consultants/analysts. You will possess the capability to identify opportunities and develop solutions with minimal oversight.

At Jacobs, we‚Äôre partnering across the globe to create the best project outcomes by maximizing the design, digital technology, and support capabilities of our Global Integrated Delivery (GID) teammates. By joining Jacobs, you‚Äôll commit to supporting and engaging with these teams, as we work to build a company like no other.

Principal Duties And Responsibilities

Provide technical leadership within Jacobs‚Äô Transportation GroupResponsible for guiding, developing, and maintaining Jacobs competitive advantage using advanced analytics and data science in support of internal Jacobs‚Äô initiatives and external client needs.Engagements range from data collection, database architecture, statistical analysis, visualization, and reporting.Analytical services range from simple data processing to fully integrated interactive decision support systems installed on existing client systems.


Here‚Äôs What You‚Äôll Need

B.A. or B.S Degree in a quantitative discipline (Computer Science, Data Science, Data Engineering, Artificial Intelligence, Applied Mathematics, Statistics, or related field) from an accredited university; Preferred Masters‚Äô DegreeProficient experience in data science focused on data for client studies, modelling, EDA, data wrangling, ETL, and/or ML/AIFluency in Python, R, and/or other computing languagesFamiliarity with SQL and relational databasesExperience with a variety of Business Intelligence tools including Tableau and PowerBIProven and dynamic leadership capabilities; training relevant staff on technical data skillsProven ability to work directly with clients in complex analyses and presenting deliverables to non-technical personnelAbility to travel as necessary to meet project and client requirementsDemonstrated ability to work autonomously and be self-directedProven ability to work within a collaborative team environment, excellent communication skills, and coordinate activities between program components


At Jacobs, we‚Äôre challenging today to reinvent tomorrow by solving the world‚Äôs most critical problems for thriving cities, resilient environments, mission-critical outcomes, operational advancement, scientific discovery and cutting-edge manufacturing, turning abstract ideas into realities that transform the world for good. With $15 billion in revenue and a talent force of more than 60,000, Jacobs provides a full spectrum of professional services including consulting, technical, scientific and project delivery for the government and private sector.","As a Transportation Data Scientist at Jacobs in Austin, Texas, you will play a pivotal role in advancing transportation solutions through innovative data science and analytics. Your responsibilities will include providing technical leadership in areas such as data collection, ETL pipelines, database architecture, statistical modeling, data visualization, and decision support systems. You will guide internal and external stakeholders by developing tools and strategies that leverage big data and advanced analytics to drive impactful transportation outcomes. This role also includes mentoring Jacobs’ consultants and analysts, ensuring high-quality deliverables, and directly engaging with clients to translate complex data into actionable insights.","deal candidates will have a bachelor’s or master’s degree in a quantitative field such as Data Science, Computer Science, or Applied Mathematics, with hands-on experience in data wrangling, exploratory data analysis, and modeling using languages like Python or R. Proficiency in SQL and familiarity with business intelligence tools such as Tableau or Power BI are required, along with strong communication skills and the ability to work independently and collaboratively. Leadership capabilities, client-facing experience, and willingness to travel as needed are also essential to succeed in this role and contribute to Jacobs’ mission of delivering smart, sustainable infrastructure solutions.","{' Python': 'MISC', ' R': 'MISC', ' SQL': 'MISC', ' Power BI': 'MISC'}"
121,iO Associates - US,Data Analyst,"We're a market leading Investment Bank that is currently in the process of expanding our team of Analysts. We're looking for a talented and ambitious Data Analyst.
Responsibilities:Collaborate with cross-functional teams to gather, analyze, and document business requirements.Assist in the development and implementation of financial models and analysis.Conduct data analysis to identify trends, patterns, and insights to support decision-making.Prepare reports and presentations to communicate findings and recommendations to stakeholders.Participate in the design and optimization of business processes to enhance efficiency.Assist in the testing and validation of financial software applications.Stay informed about industry trends, regulatory changes, and market developments.
Qualifications:Bachelors degree in Computer Science, Statistics or similarExposure to Python, R or SAS would be preferredStrong analytical and quantitative skills.Proficiency in Microsoft Excel, and familiarity with data analysis tools.Excellent communication and interpersonal skills.Ability to work collaboratively in a team environment.Detail-oriented with a proactive and problem-solving mindset.Eagerness to learn and adapt to evolving business needs.","As a Data Analyst at a leading Investment Bank, you will work closely with cross-functional teams to support financial decision-making through data-driven insights. Your role will involve gathering and analyzing business requirements, developing financial models, and identifying key trends from data sets to inform strategic initiatives. You will prepare reports and presentations for stakeholders, contribute to the enhancement of business processes, and support testing of financial applications. Staying up to date with market trends and regulatory developments will also be key to your success.","Ideal candidates will hold a bachelor’s degree in Computer Science, Statistics, or a related field, and demonstrate strong analytical and quantitative abilities. Familiarity with data analysis tools such as Python, R, or SAS is preferred, along with proficiency in Microsoft Excel. You should be detail-oriented, proactive, and able to communicate effectively in a collaborative team setting. A willingness to learn and adapt to the fast-paced financial industry is essential.","{' Python': 'MISC', ' R': 'MISC', ' SAS': 'MISC', ' Microsoft Excel': 'MISC'}"
122,iO Associates - US,Data Engineer,"Are you passionate about database development and data warehousing? We're seeking a talented SQL Server Database Engineer to join our dynamic team. In this role, you'll play a pivotal part in building, managing, and optimizing our enterprise data architecture. 
Responsibilities:Collaborate with software and analytics teams to design and implement robust database architectures and applications.Enhance database performance and automate processes for efficiency.Set and maintain high standards for database development practices.Modernize our data warehouse to ensure reliable, consistent data access.Develop custom data pipelines for ETL processes.Ensure the stability and performance of SQL Server environments (including SSIS/SSRS/MDS).Document configurations, test scripts, and functional specifications for integrations and reporting.
Qualifications:Bachelor's degree in Information Technology, Computer Science, or equivalent professional experience.4-5 years of experience in SQL Server database development and data warehouse design.Proficiency in Azure data services (Azure SQL Database, Azure Data Factory).Experience with Red Gate tools (SQL Source Control, SQL Compare).A strong foundation in data warehousing principles and data analytics.Excellent problem-solving skills to address data issues and logical discrepancies.Familiarity with SQL Server, cloud technologies, microservice architecture, and Azure DevOps.
Join our innovative team and contribute to our growing success! Apply today to be part of our exciting journey.","As a SQL Server Database Engineer, you will be instrumental in designing and maintaining robust database systems and a modern data warehouse architecture. You’ll collaborate with cross-functional teams to create scalable database solutions, optimize performance, and develop efficient ETL pipelines. The role also involves ensuring stability across SQL Server environments—including SSIS, SSRS, and MDS—while documenting key integration and reporting processes.","Ideal candidates will bring 4–5 years of SQL Server development and data warehousing experience, along with proficiency in Azure data services like Azure SQL Database and Azure Data Factory. Familiarity with Red Gate tools, microservice architecture, and Azure DevOps is highly desirable. A strong foundation in data analytics, problem-solving skills, and a proactive mindset are essential to thrive in this role. Join our forward-thinking team and make a lasting impact on our data-driven growth.","{' SQL Server': 'MISC', ' Red Gate': 'MISC', ' Azure DevOps': 'MISC'}"
123,TechDoQuest,Data Engineer,"Key Responsibilities:Design, build, and maintain end-to-end database solutionsWrite complex SQL queries for data extraction and analysisExpertise in Python, SparkSkills and Qualifications:9+ years of experience in data engineering with expertise in SQL, Python, SparkHands-on experience with Snowflake, Databricks toolsKnowledge of cloud technologies like AWS and AzureExperience in building and optimizing data pipelines for large datasetsProficiency in writing and optimizing SQL queriesStrong problem-solving and analytical skillsExcellent communication and teamwork abilitiesBachelor‚Äôs degree in Engineering or related field","As a SQL Server Database Engineer, you will be instrumental in designing and maintaining robust database systems and a modern data warehouse architecture. You’ll collaborate with cross-functional teams to create scalable database solutions, optimize performance, and develop efficient ETL pipelines. The role also involves ensuring stability across SQL Server environments—including SSIS, SSRS, and MDS—while documenting key integration and reporting processes.","Ideal candidates will bring 4–5 years of SQL Server development and data warehousing experience, along with proficiency in Azure data services like Azure SQL Database and Azure Data Factory. Familiarity with Red Gate tools, microservice architecture, and Azure DevOps is highly desirable. A strong foundation in data analytics, problem-solving skills, and a proactive mindset are essential to thrive in this role. Join our forward-thinking team and make a lasting impact on our data-driven growth.","{' SQL Server': 'MISC', ' Red Gate': 'MISC', ' Azure DevOps': 'MISC'}"
124,FedEx Dataworks,Data Engineer,"Job Description

Duties for this role include but not limited to: supporting the design, build, test and maintain data pipelines at big data scale. Assists with updating data from multiple data sources. Work on batch processing of collected data and match its format to the stored data, make sure that the data is ready to be processed and analyzed. Assisting with keeping the ecosystem and the pipeline optimized and efficient, troubleshooting standard performance, data related problems and provide L3 support. Implementing parsers, validators, transformers and correlators to reformat, update and enhance the data. Provides recommendations to highly complex problems. Providing guidance to those in less senior positions.

Additional Job Description:

Data Engineers play a pivotal role within Dataworks, focused on creating and driving engineering innovation and facilitating the delivery of key business initiatives. Acting as a ‚Äúuniversal translator‚Äù between IT, business, software engineers and data scientists, data engineers collaborate across multi-disciplinary teams to deliver value. Data Engineers will work on those aspects of the Dataworks platform that govern the ingestion, transformation, and pipelining of data assets, both to end users within FedEx and into data products and services that may be externally facing. Day-to-day, they will be deeply involved in code reviews and large-scale deployments.

Essential Job Duties & Responsibilities

Understanding in depth both the business and technical problems Dataworks aims to solveBuilding tools, platforms and pipelines to enable teams to clearly and cleanly analyze data, build models and drive decisionsScaling up from ‚Äúlaptop-scale‚Äù to ‚Äúcluster scale‚Äù problems, in terms of both infrastructure and problem structure and techniqueCollaborating across teams to drive the generation of data driven operational insights that translate to high value optimized solutions. Delivering tangible value very rapidly, collaborating with diverse teams of varying backgrounds and disciplinesCodifying best practices for future reuse in the form of accessible, reusable patterns, templates, and code basesInteracting with senior technologists from the broader enterprise and outside of FedEx (partner ecosystems and customers) to create synergies and ensure smooth deployments to downstream operational systems

Skill/Knowledge Considered a Plus

Technical background in computer science, software engineering, database systems, distributed systemsFluency with distributed and cloud environments and a deep understanding of optimizing computational considerations with theoretical propertiesExperience in building robust cloud-based data engineering and curation solutions to create data products useful for numerous applicationsDetailed knowledge of the Microsoft Azure tooling for large-scale data engineering efforts and deployments is highly preferred. Experience with any combination of the following azure tools: Azure Databricks, Azure Data Factory, Azure SQL D, Azure Synapse AnalyticsDeveloping and operationalizing capabilities and solutions including under near real-time high-volume streaming conditions. Hands-on development skills with the ability to work at the code level and help debug hard to resolve issues. A compelling track record of designing and deploying large scale technical solutions, which deliver tangible, ongoing valueDirect experience having built and deployed robust, complex production systems that implement modern, data processing methods at scaleAbility to context-switch, to provide support to dispersed teams which may need an ‚Äúexpert hacker‚Äù to unblock an especially challenging technical obstacle, and to work through problems as they are still being definedDemonstrated ability to deliver technical projects with a team, often working under tight time constraints to deliver valueAn ‚Äòengineering‚Äô mindset, willing to make rapid, pragmatic decisions to improve performance, accelerate progress or magnify impactComfort with working with distributed teams on code-based deliverables, using version control systems and code reviewsAbility to conduct data analysis, investigation, and lineage studies to document and enhance data quality and accessUse of agile and devops practices for project and software management including continuous integration and continuous deliveryDemonstrated expertise working with some of the following common languages and tools:Spark (Scala and PySpark), Kafka and other high-volume data toolsSQL and NoSQL storage tools, such as MySQL, Postgres, MongoDB/CosmosDBJava, Python data toolsAzure DevOps experience to track work, develop using git-integrated version control patterns, and build and utilize CI/CD pipelinesWorking knowledge and experience implementing data architecture patterns to support varying business needsExperience with different data types (json, xml, parquet, avro, unstructured) for both batch and streaming ingestionsUse of Azure Kubernetes Services, Eventhubs, or other related technologies to implement streaming ingestionsExperience developing and implementing alerting and monitoring frameworksWorking knowledge of Infrastructure as Code (IaC) through Terraform to create and deploy resourcesImplementation experience across different data stores, messaging systems, and data processing enginesData integration through APIs and/or REST service PowerPlatform (PowerBI, PowerApp, PowerAutomate) development experience a plus
Minimum Qualifications:

Data Engineer I:

Bachelor‚Äôs Degree in Information Systems, Computer Science or a quantitative discipline such as Mathematics or Engineering and/or One (1) year equivalent formal training or work experience. Basic knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Basic knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Experience as a junior member of multi-functional project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements.

Sponsorship is not available for Data Engineer I role.

Data Engineer II:

Bachelor's Degree in Computer Science, Information Systems, a related quantitative field such as Engineering or Mathematics or equivalent formal training or work experience. Two (2) years equivalent work experience in measurement and analysis, quantitative business problem solving, simulation development and/or predictive analytics. Strong knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Strong knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Strong understanding of the transportation industry, competitors, and evolving technologies. Experience as a member of multi-functional project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements.

Sponsorship is not available for Data Engineer II role.

Data Engineer III:

Bachelor‚Äôs Degree in Information Systems, Computer Science or a quantitative discipline such as Mathematics or Engineering and/or equivalent formal training or work experience. Three to Four (3 - 4) years equivalent work experience in measurement and analysis, quantitative business problem solving, simulation development and/or predictive analytics. Extensive knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Extensive knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Strong understanding of the transportation industry, competitors, and evolving technologies. Experience providing leadership in a general planning or consulting setting. Experience as a senior member of multi-functional project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements.

Data Engineer Lead:

Bachelor‚Äôs Degree in Information Systems, Computer Science, or a quantitative discipline such as Mathematics or Engineering and/or equivalent formal training or work experience. Five to Seven (5 - 7) years equivalent work experience in measurement and analysis, quantitative business problem solving, simulation development and/or predictive analytics. Extensive knowledge in data engineering and machine learning frameworks including design, development and implementation of highly complex systems and data pipelines. Extensive knowledge in Information Systems including design, development and implementation of large batch or online transaction-based systems. Strong understanding of the transportation industry, competitors, and evolving technologies. Experience providing leadership in a general planning or consulting setting. Experience as a leader or a senior member of multi-function project teams. Strong oral and written communication skills. A related advanced degree may offset the related experience requirements.

Domicile / Relocation Information:

This position can be domiciled anywhere in the United States.

Application Criteria:

Upload current copy of Resume (Microsoft Word or PDF format only) and answer job screening questionnaire.

Additional InformationColorado, Nevada, Connecticut, New York, California, Rhode Island, Washington, Hawaii, Illinois and New Jersey Residents Only - Compensation: Monthly Salary: $6,317.00 - $15,477.00. This compensation range is provided as a reasonable estimate of the current starting salary range for this role. Factors that may be used to determine your actual salary may include but are not limited to your specific skills, your work location, how many years of experience you have, and comparison to other employees already in this role.

Born out of FedEx, a pioneer that ships nearly 20 million packages a day and manages endless threads of information, FedEx Dataworks is an organization rooted in connecting the physical and digital sides of our network to meet today's needs and address tomorrow's challenges.

We are creating opportunities for FedEx, our customers, and the world at large by:

Exploring and harnessing data to define and solve true problems;Removing barriers between data sets to create new avenues of insight;Building and iterating on solutions that generate value;Acting as a change agent to advance curiosity and performance. 

At FedEx Dataworks, we are making supply chains work smarter for everyone.

Employee Benefits: medical, dental, and vision insurance; paid Life and AD&D insurance; tuition reimbursement; paid sick leave; paid parental leave, paid vacation, paid military leave, and additional paid time off; geographic pay ranges; 401k with Company match and incentive bonus potential; sales Incentive compensation for selling roles.

Dataworks does not discriminate against qualified individuals with disabilities in regard to job application procedures, hiring, and other terms and conditions of employment. Further, Dataworks is prepared to make reasonable accommodations for the known physical or mental limitations of an otherwise qualified applicant or employee to enable the applicant or employee to be considered for the desired position, to perform the essential functions of the position in question, or to enjoy equal benefits and privileges of employment as are enjoyed by other similarly situated employees without disabilities, unless the accommodation will impose an undue hardship. If a reasonable accommodation is needed, please contact DataworksTalentAcquisition@corp.ds.fedex.com.","This FedEx Dataworks Data Engineer role centers around designing, building, and maintaining scalable data pipelines to support critical business operations. You'll be responsible for transforming and preparing large datasets for processing, optimizing pipeline efficiency, troubleshooting performance issues, and providing level 3 support. This role also involves building tools, automating workflows, integrating systems, and codifying best practices to improve data engineering solutions. You'll work closely with multi-disciplinary teams to deploy production systems and deliver business value.","Candidates should have a solid foundation in computer science, software engineering, and distributed systems, along with expertise in Azure cloud services like Databricks, Data Factory, Synapse, and SQL. Experience in Spark (Scala/PySpark), Kafka, SQL/NoSQL databases, and tools like Azure DevOps and Terraform is highly preferred. Depending on level, qualifications range from one year of experience (for Data Engineer I) to 5–7+ years (for Lead roles), with increasing responsibilities in leading teams and delivering enterprise-grade data solutions. Strong communication, problem-solving abilities, and familiarity with agile/devops methodologies are essential across all levels.","{' SQL': 'MISC', ' Spark': 'MISC', 'Scala/PySpark': 'MISC', ' Kafka': 'MISC', ' SQL/NoSQL': 'MISC', ' Azure DevOps': 'MISC', ' Terraform': 'MISC'}"
125,KACE Company,Data Analyst,"Title: Data Analyst (Data Entry Support) 

Location: Washington, DC

SECURITY CLEARANCE: Public Trust 

About KACE

When you make the decision to join KACE, you are choosing to work alongside talented professionals that have one thing in common; the passion to make a difference! KACE employees bring their diverse talents and experiences to work on critical projects that help shape the nation‚Äôs safety, security, and quality of life.

The desire to have a career that is purposeful and forward thinking is woven into every KACE employee‚Ä¶it‚Äôs The KACE Way. KACE employees are; purpose driven, forward focused, open-minded, trustworthy and invested.

The KACE Way is our commitment to our employees, to our customers, and to our communities. Join KACE and make a difference!

About The Role

The Data Analyst will provide a wide range of clerical and administrative and support-related tasks and should be able to work independently with little or no supervision. The ideal candidate will have knowledge of processes, procedures and practices associated with accessing databases, data entry, administrative office skills, organization skills and attention to detail.

Work Duties And Tasks

Review incoming material and independently perform on-line creation of routine and increasingly more complex debt records by entering data into the debt collection database. Routine cases include special assessment only, fines, restitution, and joint and several debtsPerform on-line data searches to retrieve documentation and analyze data from multiple sourcesCompile case-related information to ensure a complete debt record in the debt collection database; Submit the completed case information to the appropriate district‚Äôs client siteConduct quality control review of team members‚Äô work to ensure accuracy of data in the debt collection databaseResearch and post payments to ensure timely posting to debts in the debt collection databaseReview reports to identify expired debts to be closed in the debt collection database in accordance with established proceduresEnter event codes associated with enforcement actions into the debt collection database to reflect accurate statistical accomplishmentsElectronically initiate generation of form documents that do not require legal interpretation but require consideration of the nature and status of the caseCreate and manipulate spreadsheets to track assignments or review and analyze management reportsCommunicate in a professional and courteous manner with the Office of Legal Programs management, Government officials, and/or delinquent judgment debtorsPerform other related duties as assigned

Minimum Qualifications And Skills

High School diplomaA minimum of one (1) year of professional work experience, including data entry responsibilitiesProficient in Microsoft Office software programs (Word, PowerPoint, Excel and Outlook) and in accessing, learning, and maintaining various databases and online resource search enginesMust be local to areaAbility to work independently and efficiently with guidance from supervisor and team membersAbility to retrieve and analyze data and information from multiple sourcesAttention to detail and quality control techniques to ensure accuracyAbility to operate a variety of office equipment, including personal computers, photocopiers, telephone systems and scannersAbility to perform editing, reformatting and generating written and electronic documents using MS Word and other document generation software

Security Requirements

U.S. Citizenship and Favorable credit checkAbility to pass a Public Trust background investigation

Preferred Qualifications

Four-year undergraduate degreeAbility to deliver the highest quality of work under extreme pressureStrong organizational and communication skillsAnalytical and problem-solving skills

For more information about the company please visit our website at www.kacecompany.com

KACE is an Equal Opportunity Employer and does not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, disability or any other federal, state or local protected class.","As a Data Analyst (Data Entry Support) at KACE in Washington, DC, you will provide critical administrative and clerical support, primarily focused on data entry and database management within a debt collection environment. Your duties will include reviewing incoming materials, entering and analyzing case data, conducting quality control reviews, initiating document generation, and creating spreadsheets for reporting and tracking purposes. You’ll interact with internal teams and external parties professionally and ensure all data entries meet high accuracy standards in accordance with established procedures.","The ideal candidate will have at least one year of professional experience involving data entry, a high school diploma (a bachelor’s degree preferred), and be proficient in Microsoft Office and database tools. Strong organizational skills, attention to detail, and the ability to work independently are essential. U.S. citizenship and the ability to obtain Public Trust clearance are required. This role is well-suited for someone who is purpose-driven, trustworthy, and committed to high-quality, mission-oriented work.",{' Microsoft Office': 'MISC'}
126,Dice,Data Scientist,"Dice is the leading career destination for tech experts at every stage of their careers. Our client, Maxar Technologies, is seeking the following. Apply via Dice today!

Please review the job details below.

Maxar has an exciting opportunity for a TS/SCI cleared Data Scientist. Come support a major program advancing the state of the art in mission-focused big data analytics and predictive analytics. You will support an established program supporting our client's mission to centralize and standardize Tasking, Collection, Processing, Exploitation and Dissemination (TCPED) of Open Source Intelligence (OSINT) across the DoD and IC enterprise. You will be delivering cutting edge data science capabilities to advance national security objectives, swiftly produce and analyze results, disseminate findings, and contribute to publications and presentations with actionable intelligence insights. While most work is conducted on-site at our client location in Bethesda, MD, we offer a flexible schedule and, occasionally, some tasks may be performed remotely. Percentage of remote work will vary based on client requirements/deliverables.

 Life with Us 

 Your Career:  We are quickly growing our team and this opportunity will provide ample opportunity for career growth and skillset development. You will have the opportunity to work closely with leadership to help set your own goals and ensure you are on a path to achieving them.

We offer:

Dedicated professional development time.Peer groups.Education reimbursement.Student loan forgiveness.and much more...

 Day- to-Day with your Colleagues: 

Work closely with a tight-knit team of data scientists, as well as a larger team of software developers, network engineers, senior investigators, program managers, researchers, and data analysts to design, build, and optimize a Data Science platform to produce and analyze results, disseminate findings, and contribute to publications and presentations. Work on small projects analyzing a variety of big data covering national security, cyber security, business intelligence, online social media, human behavior and more. Support multiple simultaneous projects and take open-ended or high-level guidance, independently and collaboratively make discoveries that are mission-relevant, and package and deliver the findings to a non-technical audience.Bring your mix of intellectual curiosity, quantitative acumen, and customer-focus to identify novel sources of data across a range of fields, to improve the performance of predictive algorithms, and to encourage user adoption of high-end data analytics platforms in partnership with a highly qualified, highly motivated team. Leverage your strong background in research design, exploratory analysis, quantitative methods, user interface application design, and experience with customer outreach and engagement.

Minimum Requirements: 

B.S. Degree in a quantitative or analytical field such as Computer Science, Mathematics, Economics, Statistics, Engineering, Physics, or Computational Social Science; or Master's degree or equivalent graduate degree including certificate-based advanced training courses.B.S. with 8+ years of experience OR Master's degree with 6+ years of experience in data science, analytics or quantitative intelligence analysis, and demonstrating progressive technical development and outcomes. Must have an active Top Secret clearance and must be able to achieve a TS/SCI clearance with PolygraphProficiency in one or more scripting languages such as R or PythonExperience working with a hybrid team of analyst, engineers, and developers to conduct research, and build and deploy complex, but easy-to-use algorithms and analytical platformsPrevious experience performing Research in data analytics or big data;Track record of active learning and creative problem solvingAbility to analyze and assess software development or data acquisition requirements and determine optimum, cost-effective solutions.

Desired Skills

Data analytics experience in direct support if military or intelligence community customers, demonstrating progressive technical development and mission-focused outcomes;Significant experience dealing with at least two of the following data classes: open source, publicly available information (PAI); forensic media (i.e. DOMEX); measurement and signatures intelligence (MASINT).Significant experience with Knowledge Graphs and KG tech such as neo4jPrevious experience developing predictive algorithmsSocial network analysis, supply chain analysis, forensic accounting, pattern of life, natural language processing, social media analysis, classification algorithms, and/or image processing;Experience blending analytical methodologies and leveraging existing COTS/GOTS/OS tools in an unconventional manner;Familiarity utilizing virtualization and distributed field systems, such as Hadoop (or similar distributed file systems) in development and deployment environments;Familiarity using git, svn, JIRA, or other version control technologies;Experience with Amazon Web Services (AWS/C2S);Familiarity with hardware platforms, e.g., CPUs, GPUs, FPGAs, etc.

Our salary ranges are market-driven and set to allow for flexibility. Individual pay will be competitive based on a candidate's unique set of knowledge, skills, and geographic diversity, with earnings potential commensurate with experience. The range for this position is:

$130,000.00 - $218,000.00 annually.

Maxar employees must follow all applicable Maxar policies and COVID-19 requirements as well as those of Maxar customers and third parties. Individual job requirements may vary, and Maxar reserves the right to modify its policies and requirements as it deems appropriate in accordance with applicable law.

Maxar Technologies  values diversity in the workplace and is an equal opportunity/affirmative action employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law.  Data Scientist - TS/SCI Hybrid","As a Data Scientist at Maxar Technologies, you will work on high-impact projects in support of national security objectives, primarily focused on enhancing Open Source Intelligence (OSINT) capabilities for the Department of Defense and Intelligence Community. In this role, you will collaborate with multidisciplinary teams to develop, optimize, and deploy advanced data science platforms and predictive analytics. Responsibilities include performing big data analytics, supporting simultaneous research efforts, creating user-friendly algorithmic tools, and delivering insights to non-technical stakeholders. You’ll also explore diverse data sources, contribute to publications, and occasionally work remotely based on client deliverables.","Qualified candidates must have a Bachelor’s or Master’s degree in a quantitative field with 6–8+ years of relevant experience. A Top Secret clearance is required, with eligibility for TS/SCI with polygraph. Strong programming skills in Python or R, experience in algorithm development, and a proven ability to apply data analytics in intelligence or military contexts are essential. Desired skills include familiarity with knowledge graphs (e.g., neo4j), predictive modeling, NLP, AWS, virtualization tools like Hadoop, and hands-on experience with COTS/GOTS/OS tools. Salary ranges from $130,000 to $218,000 based on experience and location.","{' TS/SCI': 'MISC', ' Python': 'MISC', ' R': 'MISC', ' Hadoop': 'MISC', ' COTS/GOTS/OS': 'MISC'}"
127,Ochsner Health,Data Scientist,"We've made a lot of progress since opening the doors in 1942, but one thing has never changed - our commitment to serve, heal, lead, educate, and innovate. We believe that every award earned, every record broken and every patient helped is because of the dedicated employees who fill our hallways. 

At Ochsner, whether you work with patients every day or support those who do, you are making a difference and that matters. Come make a difference at Ochsner Health and discover your future today! 

This job uses advanced and predictive data analytics using machine learning and artificial intelligence technology for healthcare innovation and outcomes. Performs analysis using data science techniques on structured and unstructured data sets and develops algorithms for targeted business needs. Pilots the delivery of patient-centered and personalized advanced analytics solutions that improve contract performance, program effectiveness, and clinical, financial, and utilization outcomes across the continuum of care. Implements advanced scientific techniques, forecasting, and machine learning to predict financial and clinical outcomes in order to guide investments that improve health outcomes and reduce costs.

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable qualified individuals with disabilities to perform the essential duties.

This job description is a summary of the primary duties and responsibilities of the job and position. It is not intended to be a comprehensive or all-inclusive listing of duties and responsibilities. Contents are subject to change at the company‚Äôs discretion.

Job Duties: 

Leads the design and deployment of computational algorithms, statistical methods, and predictive models. Uses machine learning techniques and statistical test, including Pearson correlation, Ttests and Anova statistical tests, for hypothesis testing to assess outcomes of interventions and clinical program. Uses supervised and unsupervised machine learning techniques such as regression, random forest, xgboost, clustering or causal inference techniques, such as hierarchical modeling and propensity score matching, to deliver analytics solutions and researches new methods to evaluate, improve and implement machine learning models to be used in clinical, operational, and corporate areas. Follows best practices for data science and software development (version control, testing, containerization) to create deployable models and repeatable analyses. Heads the creation and dissemination of data mining approaches that facilitate rapid, streamlined detection of outliers, novel patterns of association, and latent, causal connections in high-dimensional data sets. Serve as quantitative subject matter expert (SME) and mentor to colleagues and teammates, providing guidance related to project/program design, statistical methodology, model input/output selection, and interpretation of results. Works directly and maintains a relationship with aligned business partners in requirements definition, project scoping, timeline management, and documentation. Fosters relationships with internal and external stakeholders through regular engagement, communication, and consistent delivery of analytic work products. Authors technical reports, statistical analysis plans (SAP), white papers, enterprise presentations, and peer-reviewed abstracts, posters, and journal articles. Collaborates with data management team to identify required data assets and, in turn, to automate their sourcing, integration, and analysis. Performs other related duties as assigned. Travel as needed to New Orleans worksite 1 or 2 times per month, or more depending on the needs of the work.

Employer: Ochsner Clinic Foundation

Geographic area of employment: New Orleans, LA. May work remotely in U.S. but must meet physically in New Orleans 1-2 days per week.

Education Required: Bachelor‚Äôs degree in Data Analytics, Computer Science, Mathematics, Statistics, Economics, or biomedical informatics.

Experience Required: 24 months in healthcare analytics, Data analyst, or graduate assistant.

Other Requirements:

 Ability to communicate and present data analytics concepts to a non-technical audience. Experience must have included presenting data analytics to laypeople orally and in writing.  At least 24 months coding in R, Python, SQL, or SAS. 

Applicants must reference REQ_ and apply online at www.ochsner.org/careers

The above statements describe the general nature and level of work only. They are not an exhaustive list of all required responsibilities, duties, and skills. Other duties may be added, or this description amended at any time.

Remains knowledgeable on current federal, state and local laws, accreditation standards or regulatory agency requirements that apply to the assigned area of responsibility and ensures compliance with all such laws, regulations and standards.

This employer maintains and complies with its Compliance & Privacy Program and Standards of Conduct, including the immediate reporting of any known or suspected unethical or questionable behaviors or conduct; patient/employee safety, patient privacy, and/or other compliance-related concerns. The employer is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.

Physical and Environmental Demands

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

Sedentary Work - Exerting up to 10 pounds of force occasionally (Occasionally: activity or condition exists up to 1/3 of the time) and/or a negligible amount of force frequently (Frequently: activity or condition exists from 1/3 to 2/3 of the time) to lift, carry, push, pull, or otherwise move objects. Sedentary work involves sitting most of the time but may involve walking or standing for brief periods of time. Jobs are sedentary if walking and standing are required only occasionally and all other sedentary criteria are met.

Normal routine involves no exposure to blood, body fluid or tissue and as part of their employment, incumbents are not called upon to perform or assist in emergency care or first aid.

The incumbent has no occupational risk for exposure to communicable diseases.

Because the incumbent works within a healthcare setting, there may be occupational risk for exposure to hazardous medications or hazardous waste within the environment through receipt, transport, storage, preparation, dispensing, administration, cleaning and/or disposal of contaminated waste. The risk level of exposure may increase depending on the essential job duties of the role.

Are you ready to make a difference? Apply Today!

Ochsner Health does not consider an individual an applicant until they have formally applied to the open position on this careers website.

Individuals who reside in and will work from the following areas are not eligible for remote work position: Colorado, California, Washington, and New York.

Ochsner Health endeavors to make our site accessible to all users. If you would like to contact us regarding the accessibility of our website, or if you need an accommodation to complete the application process, please contact our HR Employee Solution Center at 504-842-4748 (select option 1) or careers@ochsner.org. This contact information is for accommodation requests only and cannot be used to inquire about the status of applications.

We are proud to be an Equal Employment Opportunity and Affirmative Action employer. We are committed to the principles of equal employment opportunity and providing a workplace that is free from discrimination based on race, color, creed, religion, pregnancy status, pregnancy-related conditions, national origin, ancestry, mental or physical disability, medical condition, age, veteran status, military status, citizenship status, marital status, familial status, sexual orientation, gender, gender identity or expression, genetic information, political affiliation, unemployment status, or any other characteristic protected under applicable federal, state or local law. These protections extend to applicants and all employment related decisions. View the‚ÄØEEO is the Law poster‚ÄØand its‚ÄØsupplement, as well as the‚ÄØpay transparency policy‚ÄØfor more information.

Affirmative Action Policy Statement","Ochsner Health is seeking a Data Scientist to lead the development and implementation of predictive analytics and machine learning solutions for healthcare innovation. This role focuses on using advanced statistical techniques and artificial intelligence to enhance patient outcomes, improve clinical efficiency, and optimize healthcare delivery. Responsibilities include designing and deploying statistical models, utilizing machine learning techniques such as regression, random forest, and xgboost, and conducting causal inference analyses. The role also involves contributing to technical documentation, collaborating with cross-functional teams, automating data integration processes, and presenting findings to both technical and non-technical audiences. Travel to the New Orleans worksite is required 1–2 times per month, or more depending on business needs.","Qualified candidates must have a Bachelor’s degree in Data Analytics, Computer Science, Mathematics, Statistics, Economics, or Biomedical Informatics, along with at least 24 months of experience in healthcare analytics or as a data analyst. Candidates should demonstrate the ability to communicate complex analytical concepts clearly to non-technical audiences and must have 2+ years of coding experience in R, Python, SQL, or SAS. Strong understanding of data science best practices, including software development techniques like version control and containerization, is essential. Applicants must be eligible to work in the U.S. and be available for occasional on-site meetings in New Orleans.","{'.': 'LOC', ' R': 'MISC', ' Python': 'MISC', ' SQL': 'MISC', ' SAS': 'MISC', ' U': 'LOC', 'S.': 'LOC', ' New Orleans.': 'LOC'}"
128,"Morgan, Lewis & Bockius LLP",Data Analyst,"Morgan, Lewis & Bockius LLP, one of the world‚Äôs leading global law firms with offices in strategic hubs of commerce, law, and government across North America, Asia, Europe, and the Middle East, is seeking to hire a Data Privacy Specialist. Reporting to the Global Chief Privacy Officer, the Data Privacy Specialist fulfills an integral role in the Privacy Office overseeing technical and administrative aspects of the Firm‚Äôs privacy compliance as well as providing support for global privacy initiatives.

This position will reside in our Philadelphia office and offers a hybrid in-office/remote working schedule.

Responsibilities

Manage and support privacy related projects with IT staff, administrative personnel, senior lawyers, and Partners in the U.S. and Europe/Middle East/Asia offices.Assist in tracking the completion of training modules for legal staff and attorneys about general data privacy and country specific regulations.Maintain awareness of privacy regulation developments for compliance purposes.Manage content of privacy agreement, incident and DSRR databases.Oversee firmwide data mapping activities and preparation of record of processing.Responsible for managing access, as needed, to privacy walls.Coordinate the development of databases for various compliance activities. 

Experience And Qualifications

Bachelor's degree from four-year college or university.Minimum 3 years of privacy compliance and data protection experience.Proficient technical skills including MS World, PowerPoint, and Excel.Ability to read and interpret general business documents, instructions, and manuals, write routine business correspondence, and speak effectively with employees, clients, and vendors.Superior written/verbal communication skills, strong interpersonal skills, and the ability to work independently and within a team environment.Privacy certification from the IAPP is a plus.

Qualified candidates can apply online by visiting our website at www.morganlewis.com and selecting ‚ÄúCareers.‚Äù

Morgan, Lewis & Bockius LLP is committed to equal employment opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. We value and encourage diversity and solicit applications from all qualified applicants without regard to race, color, gender, sex, age, religion, creed, national origin, ancestry, citizenship, marital status, sexual orientation, physical or mental disability, medical condition, veteran status, gender identity, genetic information, or any other characteristic protected by federal, state, or local law.

Pursuant to applicable state and municipal Fair Chance Laws and Ordinances, we will consider for employment qualified applicants with arrest and conviction records.

California Applicants: Pursuant to the California Consumer Privacy Act, the following link contains the Firm's California Consumer Privacy Act Privacy Notice for Candidates which explains the categories of personal information that we collect and the purposes for which we use such personal information. CCPA Privacy Notice for Candidates

Morgan Lewis & Bockius LLP is also an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

If You Are Interested In Applying For Employment With Morgan Lewis And Need Special Assistance Or An Accommodation To Use Our Website Or To Apply For a Position, Please Call Or Email The Following Contacts

Professional Staff positions ‚Äì 1.888.534.5003 / talent.acquisition@morganlewis.com 

Morgan, Lewis & Bockius, LLP reasonably accommodates applicants and employees who need them to perform the essential functions of the job because of disability, religious belief, or other reason protected by applicable law. If you believe you need a reasonable accommodation during the application process, please contact Talent Acquisition at talent.acquisition@morganlewis.com.","Morgan, Lewis & Bockius LLP is seeking a Data Privacy Specialist to support the firm’s global privacy compliance efforts under the direction of the Global Chief Privacy Officer. This role involves managing technical and administrative aspects of privacy programs, supporting compliance initiatives across international offices, and coordinating privacy training for legal and administrative staff. Key duties include managing privacy-related projects, overseeing data mapping activities, maintaining incident and DSRR databases, monitoring access to privacy walls, and tracking developments in global data protection regulations. The role is based in Philadelphia and offers a hybrid work schedule.","The ideal candidate will have a bachelor's degree and at least three years of experience in privacy compliance or data protection. Strong proficiency in Microsoft Word, Excel, and PowerPoint is required, along with excellent communication skills and the ability to work both independently and collaboratively. Familiarity with business correspondence and documentation is essential. A privacy certification from the International Association of Privacy Professionals (IAPP) is preferred. Candidates must demonstrate attention to detail, strong organizational skills, and a proactive attitude toward managing sensitive data in a legal environment.","{' Microsoft Word': 'MISC', ' Excel': 'MISC', ' PowerPoint': 'MISC'}"
129,Eversource Energy,Data Analyst,"This data analyst position is responsible for supporting energy efficiency Business Operations group in CT, MA and NH with an increased focus on supporting our tracking and reporting system (TrackSys) . The Business Operations group supports corporate budgets, accounting and reporting, regulatory reporting, key performance indicators, metrics activities and audit activities. This position is focused on supporting TrackSys energy efficiency measures and data support functions for Massachusetts but will also support Connecticut and New Hampshire measures and programs as necessary to provide consistency across all three states. The activities will include providing senior-level support to the management of Eversource‚Äôs Energy Efficiency (EE) organization, including interfacing with various energy efficiency functions, and our systems support vendor(s).




This is a hybrid role.‚ÄØThe first three months are fulltime in the office. 




Essential Functions
Responsible for working with our reporting teams across CT, MA and NH, and our energy efficiency tracking system vendor to implement program and measure (i.e., HVAC, heat pumps, etc.) changes related to data maintained in our tracking system to ensure savings are accurately captured and reported to internal and external stakeholders.Direct quality control analysis of our software platform (TrackSys) data to ensure that measures are configured correctly. This includes the following:Working with members of the evaluation and regulatory teams to ensure that savings formulas are calculating correctly.Working with members of the finance team to ensure that accounting data captured within Tracksys is correct.Working with members of the implementation and engineering staff to ensure that user input screens are functioning as expected.
Provide support for the ongoing maintenance of measures and updating configurations as needed to reflect changes to program designs or evaluated savings. Tasks to include:Interfacing with the software vendor to request the changes, including detailing the requirements.Testing measure configuration changes and working with the vendor to implement corrections if needed.On an annual basis, conduct a detailed review of all energy efficiency measures to ensure that they are correctly configured for the next program year.
Work with reporting team members to update system process improvement and training manuals to include current processes and controls for all residential, commercial, and industrial programs.Support the implementation teams in their evaluation of energy efficiency initiative spending and energy efficiency savings by ensuring that data in the Tracksys system is accurate and reported on a timely basis. Assist with creation of reports and dashboards as needed to provide insight regarding energy efficiency program and measure spending and savings trends.Provide support to business operations resources, vendors, and implementation staff on data uploads as it relates to TrackSys energy efficiency measure configurations. For example, assist vendors with understanding measure mapping, savings calculations, and upload template information.Responsible for, demonstrating expertise in organization, schedule development, prioritization, and deadline management.




Qualifications

Technical Knowledge/Skill:
Knowledge of energy efficiency engineering concepts related to measures and measure calculations. (i.e., energy engineering formulas to calculate savings from measures that impact end uses such as lighting, heating, cooling, refrigeration, motors, process)Knowledge of IT product management concepts and experience with working in a project role on IT implementation and or software project implementationStrong knowledge, experience and demonstrated ability in data analysis, and database management. Must be customer driven, display initiative, accepts responsibility, holds others accountable, participates in and facilitates team effectiveness, thinks, and acts analytically.Demonstrated ability to make sound decisions to support the mission, work independently and apply knowledge and skill to solve problems.Develop and maintain an excellent working relationship with management.Demonstrated proficiency in Microsoft Excel, in addition to other Microsoft Office applications (MS Power point, MS Word) and other business system applications.Demonstrated technical proficiency in running queries in various systems and data gathering. Effective written and oral communication skills.



Education:
Bachelor‚Äôs degree in engineering, Engineering Technology, Statistics, Economics/Mathematics or a related discipline or equivalent experience. 

Experience: 
Five (5) plus years related experience. Energy Efficiency, Statistics, Economics/Mathematics 

 

Compensation and Benefits:
Eversource offers a competitive total rewards program. The annual salary range for this position is $86,000 - $96,000 plus incentive. Salary is commensurate with your experience. Check out the career site for an overview of benefits.



#cengajd



Worker Type:
Regular
Number of Openings:

1

EEO Statement

Eversource Energy is an Equal Opportunity and Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to age, race, color, sex, sexual orientation, gender identity, national origin, religion, disability status, or protected veteran status.

VEVRRA Federal Contractor






Emergency Response:

Responding to emergency situations to meet customers‚Äô needs is part of every employee‚Äôs role. If employed, you will be given an Emergency Restoration assignment. This means you may be called to assist during an emergency outside of your normal responsibilities, work hours and location.","In this role, the Data Analyst will support Eversource’s Energy Efficiency Business Operations group across Connecticut, Massachusetts, and New Hampshire, with a primary focus on Massachusetts. The position is responsible for maintaining and enhancing the accuracy of the Energy Efficiency tracking system (TrackSys), including implementing updates for programs and energy-saving measures, conducting data quality control, and supporting regulatory and reporting functions. Key responsibilities include working with internal teams and external vendors to ensure accurate configuration of energy-saving measures like HVAC and heat pumps, supporting annual measure reviews, and helping improve reporting processes and training materials.","Qualified candidates should have a bachelor’s degree in engineering, statistics, economics/mathematics, or a related field, with at least five years of relevant experience in energy efficiency, data analysis, or IT product support. The role requires a strong understanding of energy efficiency engineering concepts and software project implementation, proficiency in Microsoft Excel and data querying tools, and excellent communication and organizational skills. Knowledge of TrackSys or similar data tracking systems and the ability to translate complex energy metrics into actionable insights is critical. The role begins with a full-time, in-office commitment for the first three months, transitioning into a hybrid model thereafter.","{' Microsoft Excel': 'MISC', ' TrackSys': 'MISC'}"
130,Moody's Corporation,Data Engineer,"4409

Moody‚Äôs is a developmental culture where we value candidates who are willing to grow. So, if you are excited about this opportunity but don‚Äôt meet every single requirement, please apply! You may be a perfect fit for this role or other open roles.

Moody's is a global integrated risk assessment firm that empowers organizations to make better decisions.

At Moody‚Äôs, we‚Äôre taking action. We‚Äôre hiring diverse talent and providing underrepresented groups with equitable opportunities in their careers. We‚Äôre educating, empowering and elevating our people, and creating a workplace where each person can be their true selves, reach their full potential and thrive on every level. Learn more about our DE&I initiatives, employee development programs and view our annual DE&I Report at moodys.com/diversity

Responsibilities:

The Data Analytics Engineer will provide guidance and support in the development of different analytical projects Design and develop complex workflows in Alteryx Develop and maintain dashboards and visualizations in Tableau Ability to write/understand complex SQL queries Coordinating with various stakeholders to understand the business requirements and present the developed reports As a Data Analytics Engineer, you will collaborate with various lines of business and technology teams in an Agile environment

REQUIREMENTS:

Experience in Alteryx, Tableau and SQL are crucial for the success of this roleKnowledge of KNIME and Python are highly desirableExperience in data analytics or reporting using Tableau or similar Hands on experience using data Analytics tools such as Alteryx or similar Hands-on experience writingdebugging complex SQL queries Knowledgeable in data modeling techniques Strong communication skills: confident interacting with business stakeholders and managing their expectations Analytical, logical, and strategic thinker, able to structure and communicate ideas clearly 

For US-based roles only: the anticipated hiring base salary range for this position is [[$94,800]] - [[$137,400]], depending on factors such as experience, education, level, skills, and location. This range is based on a full-time position. In addition to base salary, this role is eligible for incentive compensation. Moody‚Äôs also offers a competitive benefits package, including not but limited to medical, dental, vision, parental leave, paid time off, a 401(k) plan with employee and company contribution opportunities, life, disability, and accident insurance, a discounted employee stock purchase plan, and tuition reimbursement.

Moody‚Äôs is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, sex, gender, age, religion, national origin, citizen status, marital status, physical or mental disability, military or veteran status, sexual orientation, gender identity, gender expression, genetic information, or any other characteristic protected by law. Moody‚Äôs also provides reasonable accommodation to qualified individuals with disabilities or based on a sincerely held religious belief in accordance with applicable laws. If you need to inquire about a reasonable accommodation, or need assistance with completing the application process, please email accommodations@moodys.com. This contact information is for accommodation requests only, and cannot be used to inquire about the status of applications.

For San Francisco positions, qualified applicants with criminal histories will be considered for employment consistent with the requirements of the San Francisco Fair Chance Ordinance.

This position may be considered a promotional opportunity, pursuant to the Colorado Equal Pay for Equal Work Act.

Click here to view our full EEO policy statement. Click here for more information on your EEO rights under the law. Click here to view our Pay Transparency Nondiscrimination statement. Click here to view our Notice to New York City Applicants.

Candidates for Moody's Corporation may be asked to disclose securities holdings pursuant to Moody‚Äôs Policy for Securities Trading and the requirements of the position. Employment is contingent upon compliance with the Policy, including remediation of positions in those holdings as necessary.

For more information on the Securities Trading Program, please refer to the STP Quick Reference guide on ComplianceNet

Please note: STP categories are assigned by the hiring teams and are subject to change over the course of an employee‚Äôs tenure with Moody‚Äôs.","The Data Analytics Engineer at Moody’s will be responsible for developing, maintaining, and optimizing advanced analytics workflows and data visualizations to support business decision-making. This includes designing complex Alteryx workflows, creating insightful dashboards in Tableau, and crafting or debugging sophisticated SQL queries. The engineer will work closely with stakeholders across various teams to understand business needs and translate them into robust analytical solutions within an Agile environment. Communication and collaboration will be key, as the role involves presenting findings and coordinating development initiatives across departments.","Qualified candidates should have hands-on experience with Alteryx, Tableau, and SQL, along with a strong grasp of data modeling and analytics. Additional proficiency in KNIME and Python is highly desirable. Candidates should be analytical thinkers with strong communication skills and the ability to structure, interpret, and convey complex data insights to both technical and non-technical audiences. Moody’s offers a supportive, inclusive workplace and encourages applicants from all backgrounds to apply—even if all listed qualifications are not met. This role includes competitive compensation and benefits.","{' Tableau': 'MISC', ' SQL': 'MISC', ' Python': 'MISC'}"
132,TikTok,Data Engineer,"Responsibilities

 About TikTok U.S. Data Security
TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. U.S. Data Security (‚ÄúUSDS‚Äù) is a subsidiary of TikTok in the U.S. This new, security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and U.S. user data, so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span across Trust & Safety, Security & Privacy, Engineering, User & Product Ops, Corporate Functions and more.

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 
Join us.

Team Intro
Our User Operations team is focused on bringing a world-class experience to our users, and in doing so we are partnering with the Global Business Solutions Research and Insights team. The Analysts/Insights Partner global community under the Research and Insights (R&I) teams across the globe, is a thriving and critical resource for TikTok's Global Business Solutions team providing custom analysis of consumer behavior through 1P content data hosted on data tables spread across different teams/owners. We are looking for a Data Engineer with the skills and curiosity to see the human being behind the swipes, views, clicks and likes and build the data infrastructure to organize and access this data in a privacy compliant, aggregated and anonymized way, so Research and Insights' Analysts can query it to draw consumer insights for our clients.

In order to enhance collaboration and cross-functional partnerships, among other things, at this time, our organization follows a hybrid work schedule that requires employees to work in the office 3 days a week, or as directed by their manager/department. We regularly review our hybrid work model, and the specific requirements may change at any time.

Responsibilities
- Collaborate with cross-functional teams, including analysts, and software engineers, to understand data requirements and develop scalable solutions
- Design, build, and maintain efficient and reliable data pipelines from our data lake to our data marts, ensuring data quality and integrity
- Define metrics and create / maintain dashboards for measuring and reporting key performance indicators 
- Build and manage data inventories and data flow mappings by collecting and aggregating datasets from multiple data source systems
- Implement data governance and security measures to protect sensitive information and comply with industry regulations
- Monitor and optimize the performance of data infrastructure, troubleshoot issues, and propose enhancements to ensure maximum efficiency and reliability
- Stay up to date with emerging technologies and trends in data engineering and make recommendations for their implementation when relevant. 
- Contribute to developing and maintaining documentation for data pipelines, processes, and systems 

Qualifications

 Minimum Qualifications
- Bachelor‚Äôs degree in computer science, Engineering, or a related field.
- Proficiency in programming languages such as Python, SQL, and experience with ETL tools
- Proficiency working with multiple large and linked databases
- Strong understanding of data modeling and database design principles.
- Experience with big data technologies such as PostgreSQL databases. Familiarity with data governance, privacy, and security practices. 
- Proficiency in writing and communicating in Mandarin, due to cross functional partnerships with Mandarin speaking colleagues

Preferred Qualifications
- 3 years of experience operating within a data engineer facet or a related field. 
- Excellent problem-solving skills and ability to work independently and in a team environment. 
- Strong communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams and present technical concepts to non-technical stakeholders.


D&I Statement
TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.

Accommodation Statement
TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/ktJP6

Data Security Statement
This role requires the ability to work with and support systems designed to protect sensitive data and information. As such, this role will be subject to strict national security-related screening. 

Job Information:

„ÄêFor Pay Transparency„ÄëCompensation Description (annually) The base salary range for this position in the selected city is $108300 - $168800 annually.Compensation may vary outside of this range depending on a number of factors, including a candidate‚Äôs qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","The Data Engineer role at TikTok U.S. Data Security focuses on building and maintaining data infrastructure to support insights-driven decision-making while ensuring compliance with privacy and security standards. Key responsibilities include developing scalable data pipelines, managing data inventories, implementing governance practices, and collaborating with cross-functional teams. The role also requires defining metrics, building dashboards, and staying current with evolving data engineering technologies.","To qualify, candidates must have a bachelor's degree in a related field, strong proficiency in Python and SQL, and experience working with large databases and ETL tools. Familiarity with PostgreSQL and data governance is essential, along with the ability to communicate in Mandarin due to global team collaboration. Preferred qualifications include 3+ years of experience in data engineering, excellent problem-solving skills, and the ability to communicate technical concepts to non-technical stakeholders.","{' Python': 'MISC', ' SQL': 'MISC', ' PostgreSQL': 'MISC', ' Mandarin': 'MISC'}"
133,InMobi,Data Scientist,"The InMobi Story

We like big challenges. Building a new company in 2007 was no ordinary task. As the‚ÄØrecession hit, the iPhone was born and launched a revolution.‚ÄØMobile advertising wasn‚Äôt yet a thing, other than SMS, and venture capital funding was‚ÄØhard to come by for four guys in India.

Yet with passion, foresight, and conviction, InMobi charted its own course - helping to‚ÄØtransform the way consumers engage with their phones and create today's booming‚ÄØapp economy wherein‚ÄØconsumers now spend 4.2 hours per day.

After fourteen years of innovation, our end-to-end advertising software platform, connected content and‚ÄØcommerce‚ÄØexperiences have formed a powerful engine for‚ÄØgrowth that activates audiences, drives‚ÄØreal‚ÄØconnections, and diversifies revenue for‚ÄØcompanies around the world.

Our‚ÄØglobal organization of InMobians are excited to continue‚ÄØdiscovering and developing impactful‚ÄØtechnologies that will continue to transform people, businesses,‚ÄØand society.

Overview

There are trillions of events a day in our system. That means that whatever models we use must be run at a tremendous scale with milliseconds in latency. We see the success of our models and experiments astonishingly quickly ‚Äì our learning loop is not measured in weeks or days. It is hours and minutes. We live in what might be the fastest model-learning playgrounds in the world. We have built an infrastructure that enables model deployment at scale and speed. As data scientists, we sit alongside engineering colleagues who enable our models to deploy. Combine this with our growing variable set of hundreds of potential features (and growing!), and this is a highly fertile environment for building, experimenting, refining and achieving real impact from your models. If models fire, the bottom-line impact to our teams is immediate ‚Äì you see the value of your work incredibly fast.

The Experience You'll Need

 The core foundation we look for is an aptitude with Mathematics, Statistics, Algorithms, Optimization and a competent ability in coding and with data science languages and tools, such as Python or Apache Spark. Most importantly, we look for a passion to investigate and learn about the world from data, to ask interesting and provocative questions, and be driven to put real models into production that drive real business value.  Basics of big data processing and cloud computing will be critical to succeed in this environment.  We are open to diverse academic backgrounds, providing an intent to think and problem-solve like a data scientist. Our team includes engineers, mathematicians, computer scientists, statisticians, physicists, economists and social scientists ‚Äì a rock-star data scientist can come from any academic field. We are looking for a Staff level Data Scientist, but depending on the experience we may hire at a higher or lower level. 


Required

 Master‚Äôs in a quantitative field such as Computer Science, Statistics, Electrical Engineering, Statistics, Mathematics, Operations Research or Economics, Analytics, Data Science. Ph.D. is a huge plus.  Depending on the level we are looking for experience in the Ad Tech Industry working in Data Science teams. You would have applied algorithms and techniques from Machine Learning, Statistics, Time Series or other domains in solving real world problems and understand the practical issues of using these algorithms especially on large datasets.  You are passionate about Mathematics, Algorithms, Machine Learning and eager to learn and apply cutting edge Science to Inmobi business problems. You are excited when you see the real world impact of your models in production. You are fast to execute.  You have intellectual depth to translate fuzzy business problems into rigorous mathematical problem statements and algorithms.  You have experience and passion in figuring out what to do when ML models don't produce any production lift.  Comfortable with software programming and statistical platforms such as R,Python etc. Comfortable with the big data ecosystem. Experience in Apache Spark will be a bonus.  Comfortable collaborating with cross-functional teams.  Excellent technical and business communication skills and should know how to present technical ideas in a simple manner to business counterparts.  Possess a high degree of curiosity and ability to rapidly learn new subjects and systems. 


The Impact You'll Make

 You will be responsible for leading the data science efforts for one of the biggest in-app programmatic exchange in the world. This involves project ideation and conceptualization, solution design, measurement and solution iteration, coaching, deployment and post deployment management.  This will also include designing, development, testing of product experiments. You will need to guide the team in practical experiments, product design, model development and model evaluation. It is vital to be agile and iterate fast across experiment to deliver go-to-market ready products.  You are expected to be a hands-on part of the role where you will also actively analyse data, design and develop models, and problem-solve solutions with the rest of the team.  Additionally, stakeholder management is needed. It will involve being the interface with internal stakeholders such as our Product, Engineering, Data, Infrastructure, and Business teams.  Our team strives for thought leadership in the sector. We encourage and support all team members to write blogs, commentary and case studies published on the InMobi blog.  We also support team members across our ML/AI team to speak at industry conferences and represent InMobi‚Äôs work.  You will learn how to design and build models for specific business problems. Even before that, you will be responsible for identifying the problem areas where AI can be applied to best business impact. You will learn to start a model design by anchoring in the business context and end user needs. You will learn how to connect model impact with real and measurable business impact.  You will work in a multi-functional team environment. You will collaborate and benefit from the skills of a diverse group of individuals from teams such as engineering, product, business, campaign management and creative development.  You will have the opportunity to experiment with multiple algorithms. Enduring learning comes from building, launching and reviewing performance of a particular algorithm; from asking why something worked or why it did not work; from asking how to tailor techniques to fit the problem at hand. We have an environment that makes this possible at speed.  Importantly, you will learn to become creative in designing models to be successful. Model design is not one-size-fits. Our models need to fit our particular problems and be modified to perform. Tougher problems require layers of models, and feedback mechanisms in a dynamic environment such as ours.  We are a company that innovates and demonstrates our thought leadership to the world, whether in products, research papers or conferences ‚Äì there are many opportunities for you to shine. 


About Us

InMobi is the‚ÄØleading provider of content, monetization, and‚ÄØmarketing‚ÄØtechnologies‚ÄØthat fuel growth‚ÄØfor industries around the world.‚ÄØOur‚ÄØend-to-end advertising software platform, connected‚ÄØcontent‚ÄØand‚ÄØcommerce‚ÄØexperiences‚ÄØactivate audiences, drive‚ÄØreal‚ÄØconnections, and diversify revenue for businesses everywhere. With‚ÄØdeep expertise and unique reach in mobile, InMobi is‚ÄØa‚ÄØtrusted‚ÄØand‚ÄØtransparent‚ÄØtechnology partner for marketers, content creators‚ÄØand‚ÄØbusinesses of all kinds.

Incorporated in Singapore, InMobi maintains a large presence in‚ÄØSan Mateo and Bangalore and has operations in New York, Delhi, Mumbai, Beijing,‚ÄØShanghai, Jakarta, Manila, Kuala Lumpur, Sydney, Melbourne,‚ÄØSeoul, Tokyo, London and Dubai. To learn more, visit inmobi.com.

Our Purpose 

InMobi creates transformative‚ÄØmobile‚ÄØexperiences and software platforms‚ÄØto positively impact people, businesses, and societies around the world.

We believe that our‚ÄØinnovations at‚ÄØthe intersection of artificial intelligence, commerce,‚ÄØand the‚ÄØcreator economy‚ÄØwill revolutionize the way‚ÄØconsumers use their mobile‚ÄØdevices.‚ÄØOur mission is‚ÄØto power our‚ÄØcustomers‚Äô growth with‚ÄØinnovative content and commerce experiences that help‚ÄØthem‚ÄØactivate their audiences and drive real connections. How do we do it?

 An End-to-End‚ÄØContent, Monetization, & Marketing‚ÄØPlatform the fuels industry growth  AI-Powered Audience Activation‚ÄØfor‚ÄØthe open content, media and marketing ecosystem  New‚ÄØContent‚ÄØand Commerce‚ÄØexperiences‚ÄØfor a world of connected devices 


Award-winning Culture, Best-in-class Benefits

Our compensation philosophy enables us to provide competitive salary that drives high performance while balancing business needs and pay parity. We determine compensation based on a wide variety of factors including role, nature of experience, skills and location.

The base (fixed) pay range for this role would range from what $168,630 USD to $240,901 USD (Min and Max of Base Pay range). This salary range is in applicable for our offices located in California and New York*.

Our ranges may vary basis final location / region / or fully remote roles in accordance to the geographical differentiation in pay scales in the country.


In addition to cash compensation, based on the position, an InMobian can receive equity in the form of Restricted Stock Units. We believe that our employees/personnel should have the ability to own a part of the entity they are a part of. Therefore, the entity employing you may elect to provide such stocks to you. Ownership of stock aids us to treat our employer company as our own and base our decisions on such a company‚Äôs best interest at heart. To encourage a spirit of shared ownership, we grant InMobians relevant company stock(s). As you contribute to the growth of your company, certain stocks may be issued to you in recognition of your contribution.

A Quick Snapshot Of Our Benefits

Competitive salary and RSU grant (where applicable) High quality medical, dental, and vision insurance (including company-matched HSA) 401(k) company match Generous combination of vacation time, sick days, special occasion time, and company-wide holidays Substantial maternity and paternity leave benefits and compassionate work environment Flexible working hours to suit everyone Wellness stipend for a healthier you! Free lunch provided in our offices daily Pet friendly work environment and robust pet insurance policy - because we love our animals! LinkedIn Learning on demand for personal and professional developmentEmployee Assistance Program (EAP) 


InMobi is an equal opportunity employer

InMobi is a place where everyone can grow. Howsoever you identify, and whatever background you bring with you, we invite you to apply if this sounds like a role that would make you excited to work.

InMobi provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.

InMobi has implemented a mandatory COVID vaccination policy for all employees in the U.S. Employees who are unable to be vaccinated may request an exemption under certain circumstances.","InMobi is seeking a Staff Data Scientist to drive large-scale, real-time machine learning initiatives in the dynamic mobile advertising space. This role involves building and deploying scalable models that deliver immediate business impact by analyzing trillions of daily events. You’ll be expected to lead the full model lifecycle—from ideation and experimentation to production deployment—while collaborating with engineering, product, and business teams. You will also contribute to innovation through thought leadership and engagement with the broader AI/ML community.","Ideal candidates will have a Master’s or PhD in a quantitative field, strong skills in Python or Apache Spark, and hands-on experience solving real-world problems with machine learning in high-volume environments such as ad tech. Comfort with big data ecosystems, deep algorithmic understanding, and a passion for rapid experimentation and production model optimization are essential. InMobi offers a competitive salary ($168K–$240K base), RSUs, and generous benefits in a collaborative, fast-paced environment.","{' Python': 'MISC', ' Apache Spark': 'MISC'}"
134,International Paper,Data Analyst,"What if you were given the opportunity and responsibility to make a difference? At International Paper, you control your destiny. We offer challenging assignments and total rewards in countries around the world. When we say infinite possibilities, we mean it. Apply now and join a community that improves people‚Äôs lives, the planet and our company‚Äôs performance by transforming renewable resources into products people depend on every day.

Position Title

Data Analyst

Category/Shift

Salaried Full-Time

Physical Location:

Cedar River Mill

4600 C St SW

Pay Range

$68, 300-$91,000

The Job You Will Perform

Collaborate with departments to develop an understanding of needsResearch and devise innovative statistical models for data analysisCommunicate findings to stakeholdersEnable smarter processes and implement analytics for meaningful insights to cost reduction and process optimizationStructure, develop and optimize data lake and data enginesKeep current with technical and industry developmentsImplement analytical models into production by collaborating with internal and external stakeholdersCommunicate analytic solutions to stakeholders and implement improvements as needed to operational systemsInterface with corporate data analytics groups and other mills, participate in analytics update meetings

Key Challenges

As this is a newly created role the successful candidate will have to be a self-starter and show value and results quickly by applying the right approach into data management with a large number of different stakeholders across the departments and millDrive execution of action plans through leadership by influence

Scope

Manage databases including Braincube, Simca, and various DA toolsWork with IT Support to ensure data delivered to the data analytical tools is accurate and meets the needs of the usersBuild and sustain applications and visual management toolsSupport data requests from all areas within the millTrain and develop new powers users

The Skills You Will Bring

Bachelor‚Äôs degree in statistics, applied mathematics, Computer Science (CS) or Computer Informational Systems (CIS)3+ years‚Äô experience, preferably in manufacturingProficiency with data mining, mathematics, and statistical analysisExperience building and maintaining digital twin, including working with stakeholders to construct model, manage data connectivity and flow, model calibration, and end user interfaceExperience with manufacturing analytical models, using Simca or similar platforms.Familiarity with Power BI, Tableau, Matlab, Minitab, Microsoft Excel, Advanced Pattern Recognition, PI Data Archive Tools, GE Proficy, etcExperience with PI, PI Vision and AF, and Plant ApplicationsComfort working in a dynamic, manufacturing based, results oriented group with several ongoing concurrent projects

The Benefits You Will Enjoy

Paid time off including Vacation and HolidaysRetirement and 401k Matching ProgramMedical & DentalEducation & Development (including Tuition Reimbursement)Life & Disability Insurance

The Career You Will Build

Leadership trainingPromotional opportunities

The Impact You Will Make

We continue to build a better future for people, the plant, and our company! IP has been a good steward of sustainable practices across communities around the world for more than 120 years. Join our team and you‚Äôll see why our team members say they‚Äôre Proud to be IP.

The Culture You Will Experience

International Paper promotes employee well-being by providing safe, caring and inclusive workplaces. You will learn Safety Leadership Principles and have the opportunity to opt into Employee Networking Circles such as IPVets, IPride, Women in IP, and the African American ENC. We invite you to bring your uniqueness, creativity, talents, experiences, and safety mindset to be a part of our increasingly diverse culture.

The Company You Will Join

International Paper (NYSE: IP) is a leading global supplier of renewable fiber-based products. We produce corrugated packaging products that protect and promote goods, and enable worldwide commerce, and pulp for diapers, tissue and other personal care products that promote health and wellness. Headquartered in Memphis, Tenn., we employ approximately 38,000 colleagues globally. We serve customers worldwide, with manufacturing operations in North America, Latin America, North Africa and Europe.

International Paper is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity, sexual orientation, race, color, religion, national origin, disability, protected veteran status, age, or any other characteristic protected by law. International Paper complies with federal and state disability laws and makes reasonable accommodations for applicants and employees with disabilities. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact reasonable.accommodations@ipaper.com or (877) 973-3919.

Cedar Rapids IA 52404","As a Data Analyst at International Paper’s Cedar River Mill, you will play a pivotal role in transforming how the mill utilizes data to drive operational efficiency and cost savings. You’ll work cross-functionally to understand departmental needs, build and maintain analytical models, optimize the mill’s data lake and engines, and implement machine learning insights that support smarter decision-making. You will also ensure the accuracy of data systems like Braincube and Simca, train power users, and develop interactive visual tools using platforms such as Power BI and PI Vision. A strong focus will be placed on communication with stakeholders, modeling real-world manufacturing processes, and aligning with corporate analytics initiatives.","To succeed in this role, you should bring a bachelor’s degree in Statistics, Computer Science, Applied Mathematics, or related fields, along with 3+ years of relevant experience, preferably in a manufacturing setting. Technical expertise should include proficiency in statistical tools (e.g., Simca, Minitab, Matlab), BI dashboards (Power BI or Tableau), and familiarity with PI systems and advanced pattern recognition. A self-starter mentality is essential, as this is a newly created position with significant opportunity to demonstrate leadership through influence and data-driven decision-making.","{' Simca': 'MISC', ' Minitab': 'MISC', ' Matlab': 'MISC', 'Power BI': 'MISC'}"
135,Sourcechange,Data Engineer,"About The Role

Our client is seeking a highly experienced and skilled VP of Data Engineering to join their team. The ideal candidate will deeply understand data architecture, cloud infrastructure and the ability to design and implement scalable, secure, and reliable data solutions.

Key Responsibilities

Lead the design, development, and implementation of data infrastructure solutions in multiple public Cloud platforms and services (Azure, AWS, and GCP) using industry standards and best practicesTranslate business needs into data models supporting long-term solutions using SQL and non-SQL databases on cloud-based platforms. Create and maintain conceptual, logical, and physical data models and corresponding metadata using best practices to ensure high data quality and access. Identify data gaps and enforce strong practices to close any data quality issues promptly; establish a single version of truth for reference data that benefits consumers. Contribute to and implement a strategy for data management in private and public clouds, leveraging cloud-native tools and techniques. Establish and keep up with Data Non-Functional Requirements (NFR) to ensure that metadata, data mappings, data lineage, and other related items meet the policy requirements for being complete, accurate, and consistent. Manage data as a strategic asset and operationalize data governance, data quality, data integrity, and controls across the organization. Introduce and propagate modern engineering practices around data, including reusable/configurable data quality and data access control frameworks. Drive consistency, efficiency, and cost benefits through establishing and continuously improving data management practices and standards. Stay current on the latest trends and technologies in data and cloud infrastructure. 

Skills & Qualifications

10+ years of experience in data architecture and cloud infrastructure8+ years of experience with reference data management, business information architecture, analytics, business process re-engineering, and Product Management7+ of experience demonstrating expert-level knowledge of cloud architecture patterns (microservices, event-driven, serverless, API first and API gateways, service mesh, CQRS, stateless design)5+ years of data mapping and data lineage (create or analyze)3+ years of technical leadership in a data and technical environment, including Data Engineering, Data modeling, Metadata management, etc. A master's or bachelor's degree in computer science, information systems, or a related fieldStrong SQL and Python knowledgeStrong knowledge of business operational processes, data, and technology platformsAbility to prioritize deliverables and manage multiple complex work streams simultaneouslyExperience with data warehousing, data lakes, and data pipelinesFundamental knowledge of database systems (relational and object stores), including scaling, sharing, and replicationDeep understanding of monitoring and logging in Cloud environments, including retention and cost optimization strategiesAbility to create high-quality documentation about data architectural decisions, design rationale, and implementation guidelines. Secure Development Lifecycle and Agile Development Methodology using DevSecOps and CI/CD concepts and practicesInfrastructure as code and Continuous integration and delivery/deploymentDemonstrated ability to work well in a cross-functional environment with both technical and non-technical team members. Understanding of energy markets a plusExcellent communication and interpersonal skills","The VP of Data Engineering will be responsible for leading the design, implementation, and governance of scalable and secure data infrastructure across multiple public cloud platforms including AWS, Azure, and GCP. This executive-level role will translate complex business needs into sustainable data architecture solutions, manage the entire data lifecycle, and establish best-in-class data practices. Key responsibilities include building high-quality conceptual and physical data models, enforcing data governance and quality, creating reusable data frameworks, and staying ahead of trends in cloud infrastructure and data engineering.","Ideal candidates will have 10+ years of experience in data architecture and 8+ years in reference data and business information architecture, with demonstrated expertise in modern cloud-native architecture patterns such as microservices, event-driven systems, and API-first design. Strong proficiency in SQL, Python, metadata management, and cloud tools is essential. Candidates should also bring a background in Agile methodologies, DevSecOps, and CI/CD, with excellent cross-functional communication skills. A degree in computer science or related field is required, and experience in the energy industry is a plus.","{' SQL': 'MISC', ' Python': 'MISC', ' Agile': 'MISC'}"
136,Cogent Communications,Data Engineer,"Company: 

Cogent Communications is a global, Tier 1 facilities-based ISP, consistently ranked as one of the top five networks in the world and is publicly traded on the NASDAQ Stock Market under the ticker symbol CCOI. Cogent specializes in providing businesses with high speed Internet access and Ethernet transport services. Cogent's facilities-based, all-optical IP network backbone provides IP services globally. Since its inception, Cogent has unleashed the benefits of IP technology, building one of the largest and highest capacity IP networks in the world. This network enables Cogent to offer large bandwidth connections at highly competitive prices. Cogent also offers superior customer support by virtue of its end-to-end control of service delivery and network monitoring. A competitive base salary and a full benefits package including; Health, Dental, Vision, Paid Time Off ( PTO), Short- and Long-Term Disability, Life Insurance, Holidays, Parental Leave, 401 ( k) plan with employer match, stock options, and an Employee Assistance Program. Most benefits take effect within 30 days of employment, and some require a waiting period.

 Job Summary: 

The SQL Server DBA will be responsible for the implementation, configuration, maintenance, performance and support of critical SQL Server DB systems, to ensure the availability and consistent performance of our corporate and business applications. This is a ‚Äúhands-on‚Äù position requiring solid technical skills, as well as excellent interpersonal and communication skills.

The successful candidate will be responsible for the development and support of different versions of SQL server and other database technologies like MySQL, Oracle, etc., ensuring their optimal functioning ( security, health, performance, etc.).

The successful candidate must be capable of working independently or collaboratively with other team members.

 Essential Duties and Responsibilities: 

Manage SQL Server databases and other RDBMS through different product lifecycle from development to mission-critical production systemsInstall, Configure and maintain database servers and processes, including monitoring of system health and performance, to ensure high levels of performance, availability, and securitySupport 24x7 operational database support including periodic on-call rotationConduct diagnostic tests and evaluate performance metrics on the databasesMonitor the databases to ensure system health, functionality and remediate problems/issues in a timely mannerMigrate/convert databases from Oracle 11g, 12c and 19c to MS SQL serverExecute & maintain SQL scripts and utility jobs for MS SQL database maintenanceImplement & manage MS SQL database backups and restore, clustering, always on, failover and load balancing technologiesPerform DB refreshes from Prod to lower environmentsMonitor database status, logs, space utilization, extents, locks, blockings and deadlocks and clearing them accordinglyImplement and support MS SQL ( Active/Passive & Active/Active), Multi Node Clustering for four node clustersApply data modeling techniques to ensure that development and implementation support efforts meet integration and performance expectationsIndependently analyze, solve, and correct issues in real time, providing end-to-end problem resolutionRefine and automate regular processes, track issues, and document changesAssist developers and application owners with complex query tuning and optimizationPerform scheduled maintenance and support release deployment activities after hoursShare domain and technical expertise, providing technical mentorship and cross-training to other peers and team membersPerform all other DB related tasks and activities as assigned
 Qualifications: 

3+ years of experience supporting MS SQL Server DatabasesExperience with Performance Tuning and Optimization ( PTO), using native monitoring and troubleshooting toolsExperience with backups, restores and recovery modelsKnowledge of High Availability ( HA) and Disaster Recovery ( DR) options for SQL ServerExperience working with Windows server, including Active DirectoryExperience creating and deploying SSRS, SSIS and SSAS packagesAbility to organize and plan work independentlyAbility to multi-task and context-switch effectively between different activities and teamsExperience with MySQL, Oracle and MariaDB running on LinuxExperience with VMware, NetApp and SSRS a plusAbility to write, keep and maintain SOP, documentation, etc

 Other qualification that would be nice to have include: 

Oracle DB knowledge in a Unix environmentKnowledge with Rubrik MS SQL backup technologyKnowledge with SQL Monitor MS SQL performance monitoring toolKnowledge with Power Script/DBAToolsExcellent written and verbal communicationFlexible, team player, ‚Äúget-it-done‚Äù personality

 Physical Requirements: 

Remains in a sitting/stationary position continually or almost continually during the work dayOperates a computer and performs desk-based computer tasks continually; frequently viewing a computer screenPrefer the ability to lift, carry, push, pull objects and/or equipment that weighs up to 50 pounds on rare occasions

 COVID-19 Policy: 

Cogent has adopted a mandatory vaccination and booster policy which requires all U.S. employees to be fully vaccinated with one booster against COVID-19. Prior to beginning employment, new employees must provide proof of vaccination or apply for and receive an accommodation to be exempt from the policy.

By submitting an application or resume for this position, I understand that is an in-office position and agree to abide Cogent‚Äôs mandatory vaccination policy.

To apply for the MS SQL, Database Administrator position, please submit your resume and cover letter to careers@cogentco.com .

 Cogent Communications is an Equal Opportunity Employer.","The SQL Server DBA at Cogent Communications will be responsible for ensuring the high availability, optimal performance, and security of mission-critical database systems. The role includes installing, configuring, maintaining, and supporting SQL Server and other RDBMS platforms (including MySQL, Oracle, and MariaDB), while also supporting developers with query tuning, database migrations, backups, and failover implementations. The DBA will work across environments and life cycles, handling tasks like system health checks, data modeling, automation, and documentation, while participating in on-call rotations and collaborating with cross-functional teams.","Candidates should have 3+ years of experience supporting MS SQL Server, strong expertise in performance tuning, backup/recovery models, and experience with SSRS/SSIS/SSAS. Proficiency in high-availability solutions (clustering, AlwaysOn), Windows Server/Active Directory, and familiarity with additional technologies (VMware, NetApp, Rubrik, PowerShell, DBA tools) is preferred. Strong communication skills, flexibility, and a collaborative mindset are essential. The role is on-site and subject to Cogent’s mandatory COVID-19 vaccination and booster policy.",{' MS SQL Server': 'MISC'}
137,Comcast,Data Engineer,"Make your mark at Comcast -- a Fortune 30 global media and technology company. From the connectivity and platforms we provide, to the content and experiences we create, we reach hundreds of millions of customers, viewers, and guests worldwide. Become part of our award-winning technology team that turns big ideas into cutting-edge products, platforms, and solutions that our customers love. We create space to innovate, and we recognize, reward, and invest in your ideas, while ensuring you can proudly bring your authentic self to the workplace. Join us. You‚Äôll do the best work of your career right here at Comcast. (In most cases, Comcast prefers to have employees on-site collaborating unless the team has been designated as virtual due to the nature of their work. If a position is listed with both office locations and virtual offerings, Comcast may be willing to consider candidates who live greater than 100 miles from the office for the remote option.)

Job Summary

Our 10‚Äì12-week program as an intern at Comcast will help you cultivate meaningful relationships, develop professional skills, gain insight into the day-to-day operations of a top media and technology company, and receive mentorship opportunities to expand your professional network. You will gain invaluable knowledge of our industry, be part of our diverse and welcoming culture and receive exposure to other areas of the business, all while working on real-life business projects and functions.

Job Description

In the role of DataBee Intern, you will contribute to Comcast Technology Solution‚Äôs exciting cyber security business unit, which sells a security data fabric solution to large enterprises and the federal government. You will be primarily responsible for developing data analytics and software for DataBee, a new SaaS security, risk and compliance platform and dual-use data fabric that improves customer security hygiene and threat detection. You will work in a high pace, collaborative engineering environment to deliver value for DataBee customers. While working with a team of software engineers and data analysts, you will contribute directly to the product and gain experience in commercial product development. You will be influential in creating a startup culture for the DataBee business unit, enabling and empowering your teammates to work in an agile fashion.

Core Responsibilities

Interacts with product and field engineering teams to identify questions and issues for data analysis and experiments.Develops software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources in a production environment.Uses analytical rigor and statistical methods to analyze large amounts of data, extracting actionable insights using advanced statistical techniques such as data analysis, data mining, optimization tools and machine learning techniques and statisticsResearches and applies knowledge of existing and emerging software development and data science principles, theories, and techniques.Understands platform usage and assist with production deployments and customer issue triage.Embraces our DevSecOps culture.Uses content management systems as applicable and global design patterns and defined coding standards and practices established by the team.Learns continually by seeking out opportunities to engage in new and challenging problems.Other duties and responsibilities as assigned.

Additional Required Skills And Experience

Experience with software development in Python.Experience developing machine learning-based or other statistical analytics or models.A strong desire to learn from and contribute to a team.

Comcast is proud to be an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law. Comcast will consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of applicable law, including the Los Angeles Fair Chance Initiative for Hiring Ordinance and the San Francisco Fair Chance Ordinance.

Relevant Work Experience

0-2 Years","As a DataBee Intern at Comcast Technology Solutions, you will be part of a dynamic cyber security business unit, working on the cutting-edge DataBee platform—a SaaS solution for enterprise-level security, risk, and compliance. Your primary responsibilities will include developing software and data analytics solutions in a collaborative, agile environment. You’ll gain hands-on experience in building algorithms and automated processes to analyze and integrate large datasets, contribute to machine learning models, and assist with real-time product deployment and customer support initiatives. This role will expose you to DevSecOps principles, production-grade development practices, and startup culture within a Fortune 30 company.","a strong foundation in Python programming, experience or coursework related to machine learning or statistical modeling, and a collaborative, problem-solving mindset. Applicants should have 0–2 years of experience and a desire to engage with real-world software engineering and data science challenges. The internship provides mentorship, cross-functional exposure, and the chance to make a direct impact on a growing product in the cybersecurity space.",{' Python': 'MISC'}
138,Homesite Insurance,Data Analyst,"You will support our Contact Centers as well as creating actionable performance management reports, uncovering insights through data analysis, developing data sources to support key initiatives, and collaborating across the enterprise to bring consistency. You will be a part of an agile team in which collaboration, empowerment, and growth are at the center.

You will report to the Senior Manager, Data Analytics.

Position Compensation Range

$67,000

00 $111,00000

Pay Rate Type

Salary

Compensation may vary based on the job level and your geographic work location.

Job Description

The Data Analyst position resides within the Enterprise Contact Center Shared Service Analytics division.

You will support our Contact Centers by creating actionable performance management reports, uncovering insights through data analysis, developing data sources to support initiatives, and collaborating across the enterprise to bring consistency. You will be a part of an agile team in which collaboration, empowerment, and growth are at the center.

Responsibilities

Develop actionable performance management reports for the Contact Center and back-office teams.Manage the monthly Contact Center incentive process.Analyze Contact Center metric trends to uncover insights. Build and deliver compelling presentations of analyses.Help develop future-state tools and data.Create resolution plans to increase customer satisfaction, Key Performance Indicators.Build relationships with team members and all supported customers. Collaborate with team members to identify opportunities and implement solutions.Execute and ensure compliance of excellence standards, policies, procedures, and data governance.

Qualifications

3+ years of relevant work experience with a Bachelor's Degree or an Advanced Degree.Ability to run complex analytical projects from data gathering through analysis.A strong understanding of how to gather data across diverse data sources.Demonstrate an appetite and knowledge to solve our challenges.Intermediate to advanced SQL scripting.Demonstrated ability to provide data insights via visualization tools (Tableau preferred) and presentations.Excellent written, verbal,. Comfortable with speaking to internal and external partners at all levels.

In this flex office/home role, you will be expected to work a minimum of 10 days per month from one of the following office locations: Madison, WI 53783; Boston, MA 02110; Chicago, IL 60601*; Denver, CO 80112; Eden Prairie, MN 55343; Keene, NH 03431; St. Joseph, MO 64507; Phoenix, AZ 85034; Nashville, TN

We encourage you to apply even if you do not meet all of the requirements listed above. Skills can be used in many different ways, and your life and professional experience may be relevant beyond what a list of requirements will capture. We encourage those who are passionate about what we do to apply!

We provide benefits that support your physical, emotional, and financial wellbeing. You will have access to comprehensive medical, dental, vision and wellbeing benefits that enable you to take care of your health. We also offer a competitive 401(k) contribution, a pension plan, an annual incentive, 9 paid holidays and a paid time off program (23 days accrued annually for full-time employees). In addition, our student loan repayment program and paid-family leave are available to support our employees and their families. Interns and contingent workers are not eligible for American Family Insurance Group benefits.

We are an equal opportunity employer. It is our policy to comply with all applicable federal, state and local laws pertaining to non-discrimination, non-harassment and equal opportunity. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law.","As a Data Analyst within the Enterprise Contact Center Shared Service Analytics division, you will play a crucial role in supporting the performance of Contact Centers by developing actionable performance reports, managing incentive processes, analyzing trends, and uncovering insights that drive strategic improvements. Your work will focus on building future-state tools, creating data-driven resolution plans, and providing compelling presentations to internal stakeholders. Collaboration with cross-functional teams is key, as is a strong commitment to data governance and process excellence.","Qualifications include a minimum of 3 years of relevant experience, a Bachelor’s degree (or advanced degree), and proficiency in SQL and data visualization tools (Tableau preferred). You should demonstrate strong analytical capabilities, comfort presenting to various audiences, and a passion for solving complex challenges. This is a hybrid role, requiring at least 10 days per month in one of the company’s designated office locations. Candidates are encouraged to apply even if not all requirements are met, as diverse experience and potential are highly valued.","{' SQL': 'MISC', 'Tableau': 'MISC'}"
139,S&P Global,Data Scientist,"About The Role

Grade Level (for internal use):

05

The Role: Data Scientist Intern

The Team: The Data Transformation team is responsible for driving key automation projects, machine learning based solutions and lean initiatives across S&P Global Market Intelligence.

As custodians of the transformation strategy for the Chief Data Office, we are responsible for creating, planning, and delivering transformational projects for the company using state of the art technologies and data science methods, developed either in house or in partnership with vendors.

We are transforming the way we are collecting the essential intelligence our clients need to do decision with conviction, delivering it faster and at scale while maintaining the highest quality standards.

Responsibilities And Impact

Create cloud native dashboards and prototypes mainly in PythonUtilize Natural Language Processing (NLP) to extract data from structured and unstructured documents Analyze data sets to understand performance of our collection tools and provide actionable insights 

Our Internship Program: During your summer at S&P Global you'll have the chance to partner with our industry experts, with on-the-job experience focusing on high impact work that allows you to apply and develop your skills. Networking, business insights and tailored learning opportunities all support your growth and development, setting you up for success as you begin your career.

The Summer 2024 Internship Program will provide you with a variety of experiences to help you identify your strengths, develop highly transferable skills, and align you to a successful career path for a bright future at S&P Global.

Qualifications

What We‚Äôre Looking For:

Pursuing Bachelor's Degree in Computer Science, Mathematics, Statistics or equivalent completed no later than May 2025.Proficiency in using Python. Familiarity with core Machine Learning concepts is a big plusComfortable with using SQL and working with large datasets.Proven track record of strong analytical skills, learning agility, and independent thinking. Ability to make observations, form an opinion, and articulate to the team 

About S&P Global Market Intelligence

At S&P Global Market Intelligence, a division of S&P Global we understand the importance of accurate, deep and insightful information. Our team of experts delivers unrivaled insights and leading data and technology solutions, partnering with customers to expand their perspective, operate with confidence, and make decisions with conviction.

For more information, visit www.spglobal.com/marketintelligence.

What‚Äôs In It For You?

Our Purpose

Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technology‚Äìthe right combination can unlock possibility and change the world.

Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence¬Æ, pinpointing risks and opening possibilities. We Accelerate Progress.

Our People

We're more than 35,000 strong worldwide‚Äîso we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.

From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. We‚Äôre committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. We‚Äôre constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.

Our Values

Integrity, Discovery, Partnership

At S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of integrity in all we do, bring a spirit of discovery to our work, and collaborate in close partnership with each other and our customers to achieve shared goals.

Benefits

We take care of you, so you can take care of business. We care about our people. That‚Äôs why we provide everything you‚Äîand your career‚Äîneed to thrive at S&P Global.

Our Benefits Include

Health & Wellness: Health care coverage designed for the mind and body.Flexible Downtime: Generous time off helps keep you energized for your time on.Continuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.Invest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.Family Friendly Perks: It‚Äôs not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.Beyond the Basics: From retail discounts to referral incentive awards‚Äîsmall perks can make a big difference.

For more information on benefits by country visit: https://www.spglobal.com/en/careers/our-culture/

Diversity, Equity, And Inclusion At S&P Global

At S&P Global, we believe diversity fuels creative insights, equity unlocks opportunity, and inclusion drives growth and innovation ‚Äì Powering Global Markets. Our commitment centers on our global workforce, ensuring that our people are empowered to bring their whole selves to work. It doesn‚Äôt stop there, we strive to better reflect and serve the communities in which we live and work, and advocate for greater opportunity for all.

Equal Opportunity Employer

S&P Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.

If you need an accommodation during the application process due to a disability, please send an email to:‚ÄØEEO.Compliance@spglobal.com‚ÄØand your request will be forwarded to the appropriate person.‚ÄØ

US Candidates Only:  The EEO is the Law Poster http://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf‚ÄØdescribes discrimination protections under federal law.

20 - Professional (EEO-2 Job Categories-United States of America), DTMGOP203 - Entry Professional (EEO Job Group), SWP Priority ‚Äì Ratings - (Strategic Workforce Planning)

Job ID: 297865

Posted On: 2024-04-08

Location: New York, New York, United States","As a Data Scientist Intern on the Data Transformation team, you’ll support cutting-edge automation and data science initiatives that enhance S&P Global’s ability to collect and deliver high-quality financial intelligence. You will create cloud-native dashboards and prototypes using Python, work with Natural Language Processing (NLP) to extract data from both structured and unstructured documents, and analyze large datasets to derive actionable insights. This role offers hands-on experience with real-world data challenges and meaningful contributions to the company’s transformation strategy.","pursuing a Bachelor's degree in Computer Science, Mathematics, Statistics, or a related field with an expected graduation date no later than May 2025. Proficiency in Python and SQL is required, and familiarity with machine learning concepts is a strong plus. Successful candidates will demonstrate strong analytical thinking, learning agility, and the ability to articulate insights clearly. This is a unique opportunity to learn within a collaborative environment and contribute to impactful data projects at a global industry leader.","{' Python': 'MISC', ' SQL': 'MISC'}"
140,Recursion,Data Scientist,"Your work will change lives. Including your own. 

The Impact You‚Äôll Make

We are seeking a Senior Data Scientist to play a critical role on a fast-paced research and development team dedicated to generating and de-risking ideas that add fundamental new capabilities to Recursion‚Äôs tech-enabled drug discovery platform. You can expect to work on 1-2 early stage development projects at a time, in a fast-paced and exciting environment. You will take these projects from initial pilot work through onboarding to our larger technical and scientific platforms. On this team, you will

Answer key scientific questions by analyzing the large and novel biological datasets generated as we onboard new experimental techniques and technologiesCreate and execute on 3-6 month high-impact projects as part of cross-functional workstreamsDevelop new statistical and ML approaches to understand, de-risk, and drive decisions about these new technologiesDesign critical experiments to make go/no-go decisions on R&D projects to assess project approaches, feasibility, and potential impactPartner closely with an interdisciplinary team of scientists and technologists to build tools and techniques that will drive the entire company forwardCommunicate with a diverse range of collaborators, including company leadership (VP+)Learn new ways to code, answer quantitative questions, and think about challenging science as neededMentor other data scientists, computational biologists, and machine learning scientists

Location:

This position is based at our headquarters in Salt Lake City | expected to be on-site 50% of the time

The Team You‚Äôll Join 

You will be joining Inception Labs, a research and development team within Recursion. This team is a cross-functional group of exceptional biologists, engineers, product managers, machine learning scientists, computational biologists, and data scientists. Together, we are working to prove out novel technologies including new biological assays and data modalities, statistical and ML techniques, and computational approaches for multimodal data. This team works rapidly on a project-by-project basis to either prove or disprove the value and feasibility of these new ideas and approaches.

The Experience You‚Äôll Need

A PhD in statistics, mathematics, data science, machine learning, computer science, a related quantitative discipline, or equivalent work experienceDeep statistical, probabilistic, and ML expertise and intuition demonstrated by 5-7+ years of experience applying tools from those domains to answer questions in real-world datasetsStrong preference for experience working with large, experimentally generated biological datasets (microscopy, genomic, proteomic, etc) Experience independently developing and leading quantitative research projects in biology or chemistry as part of an interdisciplinary teamHigh fluency with Python, including a strong background in scientific computing using the Python numerical and data stackExperience collaboratively writing high-quality, reusable code in Python in version-controlled environmentsExperience working collaboratively in an interdisciplinary environment and communicating complex technical concepts and ideas to broad audiencesComfort and familiarity working in a cutting-edge research environment where scientific and technological setbacks and failures are likely to occur
How You‚Äôll Be Supported

You will be assigned a peer trail guide to support and mentor you as you onboard and get familiar with Recursion systemsReceive real-time feedback from peers on analysis results, scientific methodology, and code quality and best practicesAbility to learn from and participate regularly in scientific brainstorming sessions and discussions with the entire Inception Labs teamOption to attend an annual conference to learn more from colleagues, network, and build your skillset

The Values That We Hope You Share

We Care: We care about our drug candidates, our Recursionauts, their families, each other, our communities, the patients we aim to serve and their loved ones. We also care about our work. We Learn: Learning from the diverse perspectives of our fellow Recursionauts, and from failure, is an essential part of how we make progress. We Deliver: We are unapologetic that our expectations for delivery are extraordinarily high. There is urgency to our existence: we sprint at maximum engagement, making time and space to recover. Act Boldly with Integrity: No company changes the world or reinvents an industry without being bold. It must be balanced; not by timidity, but by doing the right thing even when no one is looking. We are One Recursion: We operate with a 'company first, team second' mentality. Our success comes from working as one interdisciplinary team. 

Recursion spends time and energy connecting every aspect of work to these values. They aren‚Äôt static, but regularly discussed and questioned because we make decisions rooted in those values in our day-to-day work. You can read more about our values and how we live them every day here .

More About Recursion

Recursion is a clinical stage TechBio company leading the space by decoding biology to industrialize drug discovery. Enabling its mission is the Recursion OS, a platform built across diverse technologies that continuously expands one of the world‚Äôs largest proprietary biological and chemical datasets. Recursion leverages sophisticated machine-learning algorithms to distill from its dataset a collection of trillions of searchable relationships across biology and chemistry unconstrained by human bias. By commanding massive experimental scale ‚Äî up to millions of wet lab experiments weekly ‚Äî and massive computational scale ‚Äî owning and operating one of the most powerful supercomputers in the world, Recursion is uniting technology, biology and chemistry to advance the future of medicine.

Recursion is headquartered in Salt Lake City, where it is a founding member of BioHive , the Utah life sciences industry collective. Recursion also has offices in London, Toronto, Montreal and the San Francisco Bay Area. Learn more at www.Recursion.com , or connect on X (formerly Twitter) and LinkedIn .

Recursion is an Equal Opportunity Employer that values diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected under applicable federal, state, local, or provincial human rights legislation.","As a Senior Data Scientist on the Inception Labs team, you will drive early-stage R&D projects that integrate new biological assays, data modalities, and computational techniques into Recursion’s platform. You will lead high-impact 3–6 month projects that de-risk and validate novel approaches to data collection and analysis, design critical experiments, and develop statistical or machine learning models using large, experimentally generated biological datasets. Your role will involve hands-on coding in Python, conducting cross-functional collaborations, mentoring junior team members, and presenting insights to leadership.","a Ph.D. in a quantitative field or equivalent experience, along with 5–7+ years applying ML and statistical methods to real-world problems. Strong experience working with large biological datasets (e.g., microscopy, genomics), proficiency in Python and scientific computing tools, and a background in version-controlled, collaborative coding environments are essential. Candidates should be comfortable in a fast-paced, interdisciplinary research environment where setbacks are part of the innovation process. This hybrid role is based in Salt Lake City with on-site work expected 50% of the time.",{' Python': 'MISC'}
141,Talentify.io,Data Analyst,"Employer Industry: Data Analysis

Why Consider This Job Opportunity

 Salary up to $[highest pay] Opportunity for career advancement and growth within the organization Remote work flexibility Competitive benefit packages including medical, dental, and vision insurance Access to 401k retirement account with employer matching Paid sick leave and other paid time off benefits

What To Expect (Job Responsibilities)

 Analyze, sort, and interpret large data sets to assist the construction team Understand source systems, data flows, and data models Adhere to data governance strategy and guidelines

What Is Required (Qualifications)

 5+ years of data analytic, data validation, data manipulation experience Six Sigma yellow or green belt certification Strong Power BI skills Strong Excel skills

How To Stand Out (Preferred Qualifications)

 Six Sigma Black Belt certification

#DataAnalysis #RemoteWork #CareerGrowth #CompetitivePay #Benefits

At Talentify, we prioritize candidate privacy and champion equal-opportunity employment. Central to our mission is our partnership with companies that share this commitment. We aim to foster a fair, transparent, and secure hiring environment for all. If you encounter any employer not adhering to these principles, please bring it to our attention immediately. Talentify is not the EOR (Employer of Record) for this position. Our role in this specific opportunity is to connect outstanding candidates with a top-tier employer.

Talentify helps candidates around the world to discover and stay focused on the jobs they want until they can complete a full application in the hiring company career page/ATS.","In this role, you will support the construction team by analyzing, interpreting, and validating large datasets. You will be responsible for understanding source systems, data flows, and implementing data models while ensuring adherence to a comprehensive data governance strategy. Your ability to work with Power BI and Excel will be key to delivering insights and visualizations that drive informed decision-making and operational improvements.","candidates must have at least 5 years of experience in data analytics, validation, and manipulation. Proficiency in Power BI and Excel is essential, and Six Sigma Yellow or Green Belt certification is required. A Six Sigma Black Belt certification is a plus and will help distinguish candidates with advanced process improvement expertise. This remote position offers competitive salary and benefits, including health insurance, a 401(k) with matching, and paid leave.","{' Power BI': 'MISC', ' Excel': 'MISC', ' Six Sigma Yellow': 'MISC', ' Green Belt': 'MISC', ' Six Sigma Black Belt': 'MISC'}"
144,ClearanceJobs,Data Engineer,"Are youaPostgres Database Administrator with a Secret clearance? If so, we have an opportunity for you! We are looking for a Postgres Database Administrator to work as a telecommuter with the requirement to be in Mechanicsburg, PA up to 1 time per week. 3K Sign on Bonus included! As Postgres Database Administrator, you will:

Work with a team of driven, supportive and highly skilled professionals.Receive a robust benefits package that includes our Employee Stock Ownership Plan! (ESOP).Enjoy flexibility managing your work hours and personal needs with a single accrual leave plan. A week in the life of a Postgres Database Administrator:Provide Subject Matter Expert (SME) support for PostgreSQL in a AWS Cloud environment.Provide PostgreSQL database management and life cycle support for a collaborative engineering tools environment.Implement the conversion of existing databases to meet new release requirements.Evaluate the effectiveness of database management technology and investigates problems and inefficiencies in a well-established data base environment.Determine the impact of new or revised software on system operations and applications.Investigate factors such as amount of storage space consumed, access times, frequencies of reads and writes, and problems encountered by other application and systems programmers using the DBMS software.Evaluate and determines alternatives and initiates corrective action to recover/restore data and return system back to normal operations.Administer day-to-day database operation and maintenance in an environment in which the system software is typically available from vendors and widely used.Ensure that the database efficiently collects, stores, and processes data.Runs utility routines/programs and investigates when reports indicate a decline in computer performance.Develop and maintains security procedures to guard against unauthorized intrusion into databases.Develop procedures and recommends methods to insure rapid access to all data. Analyzes use of archived data and develops ways to insure optimum use of existing systems.Provide assistance to programmers/analysts in program development, testing, and implementation of modified programs. Job RequirementsSecret Clearance required.Must be able to work in Mechanicsburg, PA up to 1 time per week.5+ Years DBA Experience3+ Years Postgres SQL DBA2+ Years AWS/Cloud ExperienceCOMPTIA Security + REQUIRED! Founded in 1975, AMERICAN SYSTEMS is one of the largest employee-owned companies in the United States. We are a government services contractor focused on delivering Strategic Solutions to complex national priority programs with 100+ locations worldwide. Through our focus on quality, strong cultural beliefs, and innovation we deliver excellence every day. Company Awards:Forbes National Best Midsize Companies 2021Energage National Best Workplaces, National 2021Washington Post Best Workplaces 2021 Veteran Hiring Awards:U.S. Department of Labor Hire Vets MedallionBEST FOR VETS by Military TimesTOP 10 MILITARY FRIENDLY COMPANY by MilitaryFriendly.com AMERICAN SYSTEMS is committed to pay transparency for our applicants and employee-owners. The salary range for this position is $150,000 - $160,000. Actual compensation will be determined based on several factors permitted by law. AMERICAN SYSTEMS provides for the welfare of its employees and their dependents through a comprehensive benefits program by offering healthcare benefits, paid leave, retirement plans (including ESOP and 401k), insurance programs, and education and training assistance. EOE Minorities/Women/Disabled/Veterans/Gender Identity/Sexual Orientation","As a Postgres DBA, you will be the Subject Matter Expert supporting PostgreSQL databases within an AWS cloud environment. You'll be responsible for database lifecycle management, performance tuning, data recovery, security procedures, and helping convert and optimize legacy systems to meet new standards. Key tasks include analyzing database performance, ensuring system availability, developing procedures for secure and rapid data access, and assisting application developers with integration and troubleshooting.","a current Secret clearance, 5+ years of experience as a DBA (minimum 3 years with Postgres), 2+ years of AWS/cloud experience, and a CompTIA Security+ certification (required). This role offers hybrid flexibility with occasional travel to Mechanicsburg, PA (up to once per week), a $3K sign-on bonus, and a comprehensive benefits package including ESOP, healthcare, and paid leave.",{' AWS': 'MISC'}
146,Talentify.io,Data Engineer,"Employer Industry: Healthcare Services

Why Consider This Job Opportunity

 Competitive salary up to $100,000 Opportunity for career advancement and growth within the organization Work remotely with flexibility Comprehensive benefits package including health insurance and retirement plans Chance to work on cutting-edge technology in the healthcare industry Supportive and collaborative work environment

What To Expect (Job Responsibilities)

 Consult on complex data product projects by analyzing end-to-end data product requirements Build data cleansing and standardization routines from source systems Produce data views and flows for different client demands Translate business data stories into technical breakdown structures Implement production processes to monitor data quality

What Is Required (Qualifications)

 Undergraduate studies in computer science, management information systems, business, statistics, math, or related field 5-8 years of experience with data quality rules and data management 3-5 years of experience in data warehousing and queries Strong problem-solving and communication skills Advanced skills in Python and SQL

How To Stand Out (Preferred Qualifications)

 Experience in healthcare, insurance, or financial services industry Knowledge of Cyber Security Experience with AI/Machine Learning Familiarity with Google Dataflow or Dataproc Experience with sensitive data handling and Collibra

#HealthcareServices #CyberSecurity #DataEngineering #CareerOpportunity #CompetitivePay

At Talentify, we prioritize candidate privacy and champion equal-opportunity employment. Central to our mission is our partnership with companies that share this commitment. We aim to foster a fair, transparent, and secure hiring environment for all. If you encounter any employer not adhering to these principles, please bring it to our attention immediately. Talentify is not the EOR (Employer of Record) for this position. Our role in this specific opportunity is to connect outstanding candidates with a top-tier employer.

Talentify helps candidates around the world to discover and stay focused on the jobs they want until they can complete a full application in the hiring company career page/ATS.","In this role, you’ll lead and consult on advanced data product initiatives, managing the full lifecycle from requirement analysis to implementation. Responsibilities include developing data cleansing routines, building standardized data flows, translating complex business needs into technical components, and establishing monitoring processes to ensure data integrity and quality. You’ll collaborate closely with cross-functional teams to create reliable data solutions that serve diverse client needs.","5–8 years of experience in data quality and management, 3–5 years in data warehousing, and strong expertise in SQL and Python. A degree in computer science, MIS, statistics, or a related field is required. Candidates with healthcare or finance industry experience, familiarity with Cybersecurity, Collibra, or AI/ML tools, and Google Cloud platforms such as Dataflow or Dataproc will stand out. This fully remote position offers a competitive salary (up to $100K), a collaborative culture, cutting-edge tech, and comprehensive benefits.","{' SQL': 'MISC', ' Python': 'MISC', ' Collibra': 'MISC'}"
148,Cogent Communications,Data Engineer,"Company:

Cogent Communications is a global, Tier 1 facilities-based ISP, consistently ranked as one of the top five networks in the world and is publicly traded on the NASDAQ Stock Market under the ticker symbol CCOI. Cogent specializes in providing businesses with high speed Internet access and Ethernet transport services. Cogent's facilities-based, all-optical IP network backbone provides IP services in over 216 markets globally. Since its inception, Cogent has unleashed the benefits of IP technology, building one of the largest and highest capacity IP networks in the world. This network enables Cogent to offer large bandwidth connections at highly competitive prices. Cogent also offers superior customer support by virtue of its end-to-end control of service delivery and network monitoring. A full benefits package takes effect within 30 days of employment. Matching 401k and stock options are also included.

Responsibilities:

Develop and update logical network diagrams ( Visio drawings) and maps of metro and long-haul optical fiber networksMaintain database of optical network physical parameters ( span distances, loss, fiber provider, provider ID, etc.)Drive the collection of metro and long haul network dataProvide coordination between field managers, fiber acquisition team, NOC and Network planning as it pertains to documenting and verifying as-built drawings/documentationProvide hands-on technical expertise visually translating textual/geographical network configuration data into network diagrams and GIS coded mapsMaintain proficiency in up-to-date technological developments in Internet/telecommunications infrastructure, DWDM/CWDM optical fiber transport systems, and GIS systems

Qualifications:

Strong proficiency in MS VisioStrong working knowledge of GIS systems, including familiarity with Google Earth ( .kmz), MS Streets & Trips, MapInfo, etc.Demonstrated ability to render optical fiber network drawings and mapsBasic understanding of DWDM/CWDM optical transport technologies and measurement parameters/techniquesStrong problem solving and troubleshooting skillsHigh-energy individual with good interpersonal skills who can work effectively with others, motivate peers, and drive projects to completionWell developed written and verbal communication skills3+ years of optical fiber network experience involving a geographically distributed network including 2+ years field experience is desiredFamiliarity with fiber OSP/telco/ISP operations is strongly desiredBachelor's degree in a technical field or equivalent experience, certifications or training is desiredStrong project management skillsThe ability to travel when necessary

Work Environment:

To best support your success, this is an in-office position five days a week, allowing for focused mentorship, training and personal coaching.

COVID-19 Policy:

Cogent has adopted a mandatory vaccination and booster policy which requires all U.S. employees to be fully vaccinated ( including booster shots when eligible) against COVID-19. Prior to beginning employment, new employees must provide proof of vaccination or apply for and receive an accommodation to be exempt from the policy.

By submitting an application or resume for this position, I understand that is an in-office position and agree to abide Cogent‚Äôs mandatory vaccination policy.

To apply for the Optical Network Documentation and Data Engineer position, please submit your resume and cover letter to careers@cogentco.com .

Cogent Communications is an Equal Opportunity Employer.","The successful candidate will be responsible for developing and updating logical network diagrams and GIS-coded maps, maintaining databases of physical network parameters, and coordinating across departments to ensure accurate as-built documentation. Key responsibilities include translating network configuration data into visual representations, staying current with optical fiber technologies such as DWDM/CWDM, and supporting data collection efforts for both metro and long-haul networks.","Candidates should have strong proficiency in MS Visio and GIS tools (such as Google Earth, MS Streets & Trips, and MapInfo), along with a solid understanding of optical transport technologies. Ideal applicants will bring 3+ years of experience in optical fiber network operations, including at least 2 years of field experience, and possess excellent problem-solving, communication, and project management skills. A technical degree or equivalent experience is preferred.","{' MS Visio': 'MISC', ' Google Earth': 'MISC'}"
152,UST,Data Analyst,"The Opportunity:Collaborate with clients to understand their data needs and provide insightful analysis.Research and resolve data discrepancies, ensuring data integrity and accuracy.Develop and maintain SQL queries for data extraction and analysis.Create and maintain data mappings for ETL in a star schema environment.Design and produce data reports, dashboards, and visualizations to support business decisions.Assist in the development and maintenance of the data warehouse.Work closely with cross-functional teams to support data-driven initiatives. This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required. What you need:Bachelor‚Äôs degree in computer science, Information Systems, or a related field.2-3 years of experience in data analysis, preferably in a data warehouse environment.Strong proficiency in SQL and experience with data modeling and mapping.Familiarity with star schema design and data warehousing concepts.Excellent analytical and problem-solving skills.Strong communication and interpersonal skills, with the ability to explain complex data concepts to non-technical stakeholders.Ability to manage multiple projects and meet deadlines in a fast-paced environment.Experience with data visualization tools (e.g., Tableau) is a plus. Required Soft Skills:Good analytical and problem-solving skillsExceptional communication skills (written and verbal)Good documentation skillsProficiency in English language (as a medium of communication)Frank and open communication with peers and higher-ups about realistic estimations and meeting timelines/expectations and proactive communication of issues and concerns thereof.Nice to have:Dimensional Modeling using Star SchemaKnowledge about ETL tools and how they work.Knowledge about healthcare data (claims processing, healthcare enrollments and providers)","This includes researching and resolving data discrepancies to ensure accuracy and data integrity, developing SQL queries for data extraction, and maintaining data mappings within a star schema environment. The position also involves designing and producing reports, dashboards, and visualizations to communicate data-driven insights. The analyst will assist in the development and upkeep of a data warehouse and will work closely with cross-functional teams to enable organization-wide data initiatives.","To qualify for this position, candidates should hold a bachelor’s degree in computer science, information systems, or a related field, and possess 2–3 years of experience in data analysis within a data warehouse setting. Proficiency in SQL, data modeling, and familiarity with star schema design and warehousing concepts are essential. Ideal candidates will exhibit strong analytical and problem-solving abilities, effective communication skills for engaging with both technical and non-technical audiences, and the ability to manage multiple projects in a fast-paced environment. Experience with Tableau or similar data visualization tools is a plus, along with familiarity in dimensional modeling, ETL tools, and healthcare data systems related to claims processing, enrollment, and provider data.","{' SQL': 'MISC', ' Tableau': 'MISC'}"
154,Techions,Data Scientist,"At Techions, we pride ourselves on being at the forefront of innovation, constantly pushing boundaries, and driving technological advancements. Our commitment to excellence has propelled us to the forefront of the industry, earning us a reputation as a pioneering force in the tech world.
Now, let's dive into the exciting opportunity we have for a Senior Data Scientist with expertise in Azure Databricks to join our dynamic team at Techions.
About Techions:
Techions is a trailblazing tech company known for its cutting-edge solutions and forward-thinking approach. We thrive on innovation and are committed to leveraging the latest technologies to solve complex challenges. Our team comprises passionate individuals who are driven by a shared vision of revolutionizing the tech landscape. At Techions, you'll have the opportunity to collaborate with some of the brightest minds in the industry, work on groundbreaking projects, and make a meaningful impact on the world.
Position Overview:We are seeking a highly skilled Senior Data Scientist with extensive experience in Azure Databricks to join our team. As a Senior Data Scientist at Techions, you will play a pivotal role in driving data-driven decision-making and developing advanced analytical solutions to address business challenges. You will work closely with cross-functional teams to extract insights from data, build predictive models, and deploy scalable solutions on the Azure Databricks platform.
Key Responsibilities:Lead the design, development, and implementation of machine learning models and algorithms to solve complex business problems.Collaborate with stakeholders to define project objectives, requirements, and success criteria.Utilize Azure Databricks for data preprocessing, feature engineering, model training, and deployment.Conduct exploratory data analysis to uncover hidden patterns and trends in large datasets.Develop data pipelines and workflows to automate repetitive tasks and streamline processes.Evaluate model performance and iterate on solutions to improve accuracy and efficiency.Stay current with emerging trends and technologies in data science and machine learning.
Requirements:Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or related field.Proven experience as a Data Scientist, preferably in a senior or lead role.Strong proficiency in Python, R, or other programming languages commonly used in data science.Hands-on experience with Data science libraries like pandas, scikit-learn and jupyter notebooks.Hands-on experience with Azure Databricks for data processing, model training, and deployment.Solid understanding of machine learning algorithms, statistical techniques, and data visualization.Excellent problem-solving skills and the ability to think creatively to tackle complex problems.Strong communication skills with the ability to effectively convey technical concepts to non-technical stakeholders.
Preferred Qualifications:Experience working in Agile development environments.Familiarity with cloud computing platforms such as Azure or AWS.Knowledge of big data technologies such as Hadoop, Spark, or Kafka.Join us at Techions and be part of a dynamic team that is shaping the future of technology. If you are passionate about data science and eager to make a meaningful impact, we want to hear from you!","Techions, a cutting-edge leader in technological innovation, is seeking a Senior Data Scientist with specialized expertise in Azure Databricks to join our forward-thinking team. Known for pioneering solutions and our commitment to leveraging the latest advancements, Techions offers a collaborative and intellectually stimulating environment where ideas become impactful products. This role presents an exciting opportunity to contribute to data-driven strategies and help solve complex business challenges using scalable, cloud-based solutions.","As a Senior Data Scientist, you will lead the design and deployment of machine learning models, work extensively on Azure Databricks for end-to-end data workflows, and collaborate across teams to derive insights and shape strategic initiatives. Ideal candidates will have strong experience in Python, data science libraries such as pandas and scikit-learn, and a solid grasp of machine learning algorithms. A Bachelor's or Master's in a relevant field is required, along with excellent communication and analytical skills. Prior experience in Agile environments, cloud platforms, and big data technologies like Spark or Kafka is a plus. If you're passionate about innovation and ready to drive real-world impact through data, we encourage you to join us at Techions.","{' Azure Databricks': 'MISC', ' Python': 'MISC', ' pandas': 'MISC', ' scikit-learn': 'MISC', ' Agile': 'MISC', ' Spark': 'MISC'}"
155,Data Glacier,Data Scientist,"The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with data Compile and analyze data related to business' issues Develop clear visualizations to convey complicated data in a straightforward fashion
QualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience 1 - 2 years' Data Analysis experience Proficient in SQL","The ideal candidate is a data enthusiast with a strong foundation in analytics and a passion for uncovering insights from large datasets. In this role, they will be responsible for conducting both recurring and ad hoc analyses, helping business users make informed decisions. By understanding the key challenges the business faces, the candidate will gather, compile, and interpret relevant data to address those issues effectively.","The successful candidate will possess a Bachelor's or Master's degree in Statistics, Applied Mathematics, or a related field, along with 1–2 years of experience in data analysis. Proficiency in SQL is essential, as well as the ability to develop clear, impactful visualizations that simplify complex data for stakeholders. A strong analytical mindset and excellent communication skills are key to thriving in this role.",{' SQL': 'MISC'}
162,Experity,Data Analyst,"Experity is the leading software and services company for on-demand healthcare in the U.S. We provide software solutions that remove complexities and simplify operations for 5700+ urgent care clinics across the country. We create, maintain, and support products to facilitate the complete on-demand healthcare experience: from patients finding clinics and making appointments, to checking in, to clinical documentation, and to the final bill paid by the patient. Our team is committed to changing healthcare for the better by innovating and revolutionizing on-demand healthcare for millions of patients across the country.

Experity offers the following:

Benefits ‚Äì Comprehensive coverage starts first day of employment and includes Medical, Dental/Orthodontia, and Vision.Ownership - All Team Members are eligible for synthetic ownership in Experity upon one year of employment with real financial rewards when the company is successful!Employee Assistance Program - This robust program includes counseling, legal resolution, financial education, pet adoption assistance, identity theft and fraud resolution, and so much more.Flexibility‚ÄØ‚Äì Experity is committed to helping team members face the demands of juggling work, family and life-related issues by offering flexible work scheduling to manage your work-life balance.Paid Time Off (PTO) - Experity offers a generous PTO plan and increases with milestones to ensure our Team Members have time to recharge, relax, and spend time with loved ones.Career Development‚ÄØ‚Äì Experity maintains a learning program foundation for the company that allows Team Members to explore their potential and achieve their career goals.Team Building ‚Äì‚ÄØWe bring our Team Members together when we can to strengthen the team, build relationships, and have fun! We even have a family company picnic and a holiday party.Total Compensation - Competitive pay, quarterly bonuses and a 401(k) retirement plan with an employer match to help you save for your future and ensure that you can retire with financial security.

Hybrid workforce:

Experity offers Team Members the opportunity to work remotely or in an office. While this position allows remote work, we require Team Members to live within a commutable distance from one of our locations to ensure you are available to come into the office as needed.

Job Summary: 

We are seeking a highly skilled and data-driven Go-to-Market (GTM) Data Analyst to join our team. The ideal candidate will be adept at aggregating and analyzing data from diverse sources, extracting valuable insights to inform strategic decisions, and proficient in building dynamic dashboards in Salesforce and other BI tools. Your expertise in SQL and data analytics will support our go-to-market strategy, optimize our sales funnel, and contribute to our overall success.

Responsibilities:

Aggregate data from multiple sources, including sales, marketing, customer service, and external databases to provide a comprehensive view of the market and our performance.Conduct in-depth analysis of our go-to-market strategy‚Äôs effectiveness, identifying trends, opportunities, and areas for improvement.Develop and maintain dynamic dashboards in Salesforce and other BI tools to provide real-time insights to the marketing and sales teams.Use SQL to query databases efficiently, ensuring data accuracy and accessibility.Collaborate with cross-functional teams to understand data needs and deliver actionable insights that drive strategic decision-making.Present complex analysis in an understandable manner to stakeholders at all levels of the organization, facilitating data-driven decision-making.Stay abreast of industry trends and advancements in data analytics and BI tools, recommending improvements to our processes and tools.Ensure data integrity and compliance with data protection regulations.

Education and Experience: 

Bachelor‚Äôs or Master‚Äôs degree in Data Science, Computer Science, Information Technology, or a related field.Proven experience as a Data Analyst or similar role, with a strong focus on go-to-market strategies.Expertise in SQL and experience with database management.Proficiency in Salesforce and other BI tools (e.g., Tableau, Power BI).Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent communication and presentation skills, capable of conveying complex data insights in a clear and persuasive manner.Adept at working in fast-paced environments and managing multiple projects simultaneously.Familiarity with sales and marketing metrics, and how they impact business decisions.

Budgeted salary range:

$66,900 to $91,000

Team Member Competencies:

Understands role on the team and works to achieve goals to the best of your ability.Working within a team means there will be varying opinions and ideas. Active listening and thoughtfully responding to what your team member says.Take responsibility for your mistakes and look for solutions. Understand how your actions impact team.Provides assistance, information, or other support to others to build or maintain relationships.Maintaining a positive attitude. Tackle challenges as they come, and don‚Äôt let setbacks get you down.Gives honest and constructive feedback to other team members.When recognizing a problem, take action to solve it.Demonstrates and supports the organization's core values.

Every team member exhibits our core values:

Team FirstLift Others UpShare OpenlySet and Crush GoalsDelight the Client

Our urgent care solutions include:

Electronic Medical Records (EMR): Software that healthcare providers use to input patient data, such as medical history, diagnoses, treatment plans, medications, and test results.Patient Engagement (PE): Software that shows patients the wait times at various clinics, allows patients to reserve a spot in line if there's a wait, and book the appointment.Practice Management (PM): Software that the clinic front desk staff uses to register the patient once they arrive for their appointment.Billing and Revenue Cycle Management (RCM): Software that manages coding, billing and payer contracts for clinics so they don‚Äôt have to.Teleradiology: Board certified radiologist providing accurate and timely reads of results from X-rays, CT scans, MRIs, and ultrasounds, for our urgent care clients.Consulting: Consulting services for urgent care clinics to assist with opening, expanding and enhancing client's businesses","As a Go-to-Market (GTM) Data Analyst at Experity, your primary responsibility will be to aggregate and analyze data from various departments including sales, marketing, and customer service to support strategic decision-making. You will be tasked with building and maintaining real-time dashboards in Salesforce and other BI tools like Tableau or Power BI to deliver insights that optimize the sales funnel and inform go-to-market strategies. Utilizing your SQL expertise, you will extract and manage large datasets to ensure data accuracy and accessibility, while also identifying trends, performance gaps, and actionable opportunities. Additionally, you will collaborate closely with cross-functional teams and present findings in a clear, digestible format to key stakeholders.","To qualify for this role, candidates should hold a Bachelor's or Master's degree in Data Science, Computer Science, Information Technology, or a related field, and have prior experience as a data analyst, ideally with a focus on GTM or sales/marketing analytics. Proficiency in SQL, Salesforce reporting, and BI platforms such as Tableau or Power BI is essential. A strong analytical mindset, attention to detail, and effective communication skills are critical, as is the ability to manage multiple projects in a dynamic, fast-paced environment. Familiarity with sales and marketing KPIs, along with a proactive, problem-solving attitude, will further contribute to success in this role.","{' SQL': 'MISC', ' Salesforce': 'MISC'}"
163,Lumen Technologies,Data Engineer,"About Lumen

Lumen connects the world. We are igniting business growth by connecting people, data and applications ‚Äì quickly, securely, and effortlessly. Together, we are building a culture and company from the people up ‚Äì committed to teamwork, trust and transparency. People power progress.

Lumen‚Äôs commitment to workplace inclusion and employee support shines bright. We‚Äôve made the Newsweek 2024 Greatest Workplaces for Diversity list and achieved a perfect score of 100 on the Human Rights Campaign Corporate Equality Index (CEI) for the fifth consecutive year. Plus, we‚Äôre the top employer in the communications and telecom industry, ranking 12th overall across all industries in The American Opportunity Index.

We‚Äôre looking for top-tier talent and offer the flexibility you need to thrive and deliver lasting impact. Join us as we digitally connect the world and shape the future.

The Role

We are looking for a big data developer who is passionate about working with large scale systems using cutting-edge technologies and tools to help identify and disrupt malicious threats on the Internet. You will be part of a dynamic and collaborative team that develops software to help identify and find within network like datasets.

The Main Responsibilities

Hadoop Developer

Design, develop, test, and deploy scalable and reliable data pipelines using technologies like Spark, Kafka, Hadoop, and other big data technologiesExtract, transform, and load data from various sources and formats, such as relational databases, APIs, JSON, XML, CSV, etc.Perform data quality checks and validations, and handle data anomalies and issuesCollaborate with other developers, data engineers, data analysts, and business stakeholders to understand data requirements and deliver data solutionsDevelop scalable systems that enable real-time validation of identified resources

What We Look For In a Candidate

Bachelor's degree in Computer Science, Engineering, Mathematics, or related field, or equivalent work experienceExperience in developing and working with big data technologies, such as Spark, Kafka, Hadoop, Hive, etcPrior experience in an internship applying big-data technologies toward identifying and finding threats within network datasets like IPFIX/netflowProficient in programming languages, such as Python, Java, Scala, or SQLStrong analytical and problem-solving skills, and attention to detailGood communication and teamwork skills, and ability to work independently and proactivelyEager to learn new skills and technologies, and willing to take on challenges

Compensation

The starting salary for this role differs based on the employee's primary work location. Employees typically do not start at the top of the range, though compensation depends on each individual's qualifications.

Location Based Pay Ranges

$63,980 - $106,630 in these states: AR ID KY LA ME MS NE SC SD

$67,340 - $112,230 in these states: AL AZ FL GA IA IN KS MO MT ND NM OH OK PA TN UT VT WI WV WY

$70,710 - $117,840 in these states: CO HI MI MN NC NH NV OR RI

$74,070 - $123,450 in these states: AK CA CT DC DE IL MA MD NJ NY TX VA WA

As with the pay range variety that's based on the region of a country, specific offers are determined by various factors such as experience, education, skills, certifications and other business needs.

Requisition #: 333099

Background Screening

If you are selected for a position, there will be a background screen, which may include checks for criminal records and/or motor vehicle reports and/or drug screening, depending on the position requirements. For more information on these checks, please refer to the Post Offer section of our FAQ page. Job-related concerns identified during the background screening may disqualify you from the new position or your current role. Background results will be evaluated on a case-by-case basis.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Equal Employment Opportunities

We are committed to providing equal employment opportunities to all persons regardless of race, color, ancestry, citizenship, national origin, religion, veteran status, disability, genetic characteristic or information, age, gender, sexual orientation, gender identity, gender expression, marital status, family status, pregnancy, or other legally protected status (collectively, ‚Äúprotected statuses‚Äù). We do not tolerate unlawful discrimination in any employment decisions, including recruiting, hiring, compensation, promotion, benefits, discipline, termination, job assignments or training.

Disclaimer

The job responsibilities described above indicate the general nature and level of work performed by employees within this classification. It is not intended to include a comprehensive inventory of all duties and responsibilities for this job. Job duties and responsibilities are subject to change based on evolving business needs and conditions.

Salary Range

Salary Min

63980

Salary Max

98760

This information reflects the anticipated base salary range for this position based on current national data. Minimums and maximums may vary based on location. Individual pay is based on skills, experience and other relevant factors.

This position is eligible for either short-term incentives or sales compensation. Director and VP positions also are eligible for long-term incentive. To learn more about our bonus structure, you can view additional information here. We're able to answer any additional questions you may have as you move through the selection process.

As part of our comprehensive benefits package, Lumen offers a broad range of Health, Life, Voluntary Lifestyle and other benefits and perks that enhance your physical, mental, emotional and financial wellbeing. You can learn more by clicking here.

Note: For union-represented postings, wage rates and ranges are governed by applicable collective bargaining agreement provisions.","As a Big Data Developer at Lumen, you will be responsible for designing, developing, testing, and deploying scalable data pipelines using advanced technologies such as Spark, Kafka, and Hadoop. You will extract, transform, and load data from various structured and unstructured sources, ensuring data quality through validations and anomaly handling. A key part of your role will involve collaborating with developers, data analysts, and business stakeholders to build solutions that identify and analyze threats within network datasets like IPFIX and Netflow. You will also contribute to real-time system development that supports the detection and mitigation of malicious threats on the internet.","To qualify for this role, candidates must have a bachelor's degree in Computer Science, Engineering, Mathematics, or a related field—or equivalent work experience—and be proficient in programming languages like Python, Java, Scala, or SQL. Prior experience working with big data technologies and datasets is essential, along with strong analytical and problem-solving skills. The role requires effective communication, teamwork, and a proactive attitude toward learning new technologies. Experience in internships applying big data to threat identification is highly desirable, as is familiarity with network security and scalable system development.","{' Python': 'MISC', ' Java': 'MISC', ' Scala': 'MISC', ' SQL': 'MISC'}"
164,"ERGOGUYS, LLC",Data Analyst,"Company Description
 ERGOGUYS, LLC is a consumer goods company based out of Chandler, Arizona, United States. As a leader in the industry, we are dedicated to creating ergonomic and user-friendly products that enhance productivity and promote a healthier and more comfortable work experience.
 Role Description
 This is a full-time remote role for a Data Specialist. The Data Specialist will be responsible for data analytics, data management, data analysis, data modeling, and utilizing their analytical skills to gather insights and support data-driven decision-making. They will also be responsible for managing and maintaining databases, ensuring data quality and integrity, and implementing efficient data processes.
 Qualifications
 Data Analytics, Data Analysis, and Analytical SkillsData Management and Data ModelingProficiency in SQL and database managementStrong problem-solving and critical thinking abilitiesExcellent attention to detail and organizational skillsExperience with data visualization tools and techniquesKnowledge of data privacy and security best practicesAbility to work independently and remotelyBachelor's degree in Data Science, Computer Science, or a related field","As a Data Specialist at ERGOGUYS, LLC, you will be responsible for managing and maintaining company databases to ensure data accuracy, quality, and integrity. You will perform data analytics and modeling to generate insights that support key business decisions and improve operational efficiency. Additionally, you will implement efficient data processes, apply data privacy and security best practices, and create visual reports to effectively communicate trends and findings across departments.","To succeed in this fully remote role, candidates must possess a bachelor’s degree in Data Science, Computer Science, or a related field, along with proven experience in data management, analysis, and modeling. Proficiency in SQL, database systems, and data visualization tools is essential. Strong analytical thinking, problem-solving abilities, attention to detail, and excellent organizational skills are also required. The ability to work independently in a remote setting is crucial for success in this position.",{' SQL': 'MISC'}
167,Equitable,Data Analyst,"At Equitable, our power is in our people.

We're individuals from different cultures and backgrounds. Those differences make us stronger as a team and a force for good in our communities. Here, you'll work with dynamic individuals, build your skills, and unleash new ways of working and thinking. Are you ready to join an organization that will help unlock your potential?

Responsibilities include:

Oversee the data aggregation and reporting platform, ensuring its smooth operation and adherence to compliance regulationsSupervise the platform based on the working supervisory procedures established by internal complianceAct as the subject matter expert (SME) for the platform, possessing comprehensive knowledge of data aggregation, performance reporting calculations, and problem resolutionCollaborate with vendors, internal departments, and the Equitable field force to ensure effective platform management.Build relationships with internal stakeholders and clients, fostering effective collaboration and communication.

The base salary range for this position is $68,000 - $85,000. Actual base salaries vary based on skills, experience, and geographical location. In addition to base pay, Equitable provides compensation to reward performance with base salary increases, spot bonuses, and short-term incentive compensation opportunities. Eligibility for these programs depends on level and functional area of responsibility.

For eligible employees, Equitable provides a full range of benefits. This includes medical, dental, vision, a 401(k) plan, and paid time off. For detailed descriptions of these benefits, please reference the link below.

Equitable Pay and Benefits: Equitable Total Rewards Program

Required Qualifications:

3+ years of experience in the Financial Services industry, preferably in a securities compliance roleFINRA Series 7 and 24 required and the ability to obtain the 63 and 65 or 66 registrations within 6 months of hireEstablished Excel and Project Management skillsProven knowledge of life, annuity, investment advisory products

Preferred Qualifications:

Knowledge of DST and DTCC feedsDetail-oriented with strong organization skillsExcellent critical and strategic thinking skills Must be able to quickly gather and analyze data.Excellent multi-tasking skillsAbility to build relationships, both internally and with clientsResults orientedSolution oriented and analytical mindsetPro-active and a quick learner

Skills:

Business Acumen: Knowledge of business concepts, tools, and processes that are needed for making sound decisions in the context of the company's business; ability to apply this knowledge appropriately to diverse situations.

Business Data Analysis: Knowledge of business data analysis; ability to collect, identify, analyze and interpret business data using various kinds of techniques to meet business needs and requirements.

Business Intelligence: Knowledge of business intelligence; ability to utilize business processes and technologies for gathering, storing, analyzing, and providing access to data that helps the organization make better business decisions.

Communicating Complex Concepts: Knowledge of effective presentation tools and techniques to ensure clear understanding; ability to use summarization and simplification techniques to explain complex technical concepts in simple, clear language appropriate to the audience

Data Analysis Tools: Knowledge of key uses and benefits of data analysis tools; ability to utilize data analysis tools to identify factors influencing business performance and to gain greater insight into trends within a business, industry and customer base.

Data Gathering and Analysis: Knowledge of data gathering and analysis tools, techniques and processes; ability to gather and analyze data on the learning needs of a target population.

Diversity, Equity and Inclusion: Demonstrates a commitment to Diversity, Equity and Inclusion by treating everyone with respect and dignity, ensuring all voices are heard and advocating for change.

About Equitable

At Equitable, we‚Äôre a team of over ten thousand strong; committed to helping our clients secure their financial well-being so that they can pursue long and fulfilling lives.

We turn challenges into opportunities by thinking, working, and leading differently ‚Äì where everyone is a leader. We encourage every employee to leverage their unique talents to become a force for good at Equitable and in their local communities.

We are continuously investing in our people by offering growth, internal mobility, comprehensive compensation and benefits to support overall well-being, flexibility, and a culture of collaboration and teamwork.

We are looking for talented, dedicated, purposeful people who want to make an impact. Join Equitable and pursue a career with purpose.

Equitable is committed to providing equal employment opportunities to our employees, applicants and candidates based on individual qualifications, without regard to race, color, religion, gender, gender identity and expression, age, national origin, mental or physical disabilities, sexual orientation, veteran status, genetic information or any other class protected by federal, state and local laws.

NOTE: Equitable participates in the E-Verify program.

If reasonable accommodation is needed to participate in the job application or interview process or to perform the essential job functions of this position, please contact Human Resources at (212) 314-2211 or email us at TalentAcquisition@equitable.com.

Primary Location

UNITED STATES-Remote

Organization

Equitable

Schedule

Full-time","The role at Equitable involves overseeing the data aggregation and reporting platform, ensuring smooth operations and compliance with regulations. The candidate will act as the subject matter expert (SME) on platform functionality, data aggregation processes, and performance reporting. Responsibilities include supervising platform activities per internal procedures, collaborating with vendors and internal teams, resolving issues, and building strong relationships with stakeholders and clients.","The position requires at least 3 years of experience in the financial services industry, preferably with a focus on securities compliance. A Series 7 and 24 license is required, with the expectation to obtain Series 63 and 65 or 66 within six months of hire. Strong Excel and project management skills are essential, along with a solid understanding of life, annuity, and investment advisory products. Preferred qualifications include familiarity with DST and DTCC feeds, strong analytical thinking, organizational skills, and a proactive mindset.",{' Excel': 'MISC'}
169,Lenovo,Data Analyst,"Why Work at Lenovo

We are Lenovo. We do what we say. We own what we do. We WOW our customers.

Lenovo is a US$62 billion revenue global technology powerhouse, ranked #217 in the Fortune Global 500, employing 77,000 people around the world, and serving millions of customers every day in 180 markets. Focused on a bold vision to deliver smarter technology for all, Lenovo has built on its success as the world‚Äôs largest PC company by further expanding into growth areas that fuel the advancement of ‚ÄòNew IT‚Äô technologies (client, edge, cloud, network, and intelligence) including server, storage, mobile, software, solutions, and services.

This transformation together with Lenovo‚Äôs world-changing innovation is building a more inclusive, trustworthy, and smarter future for everyone, everywhere. To find out more visit www.lenovo.com, and read about the latest news via our StoryHub.

Description And Requirements

The Lenovo Infrastructure Solutions Group Global Account Representative will be responsible for driving data center portfolio revenue, strategy, and customer satisfaction for Lenovo‚Äôs current and future Global accounts with special focus on the Manufacturing Industry.

The ideal candidate must have an acquisition mindset, result-driven sales individual who is self-motivated and not afraid to take risks to break down barriers. This individual will be establishing and managing account relationships through senior level engagements. With a focus on a holistic and comprehensive understanding of our customers Data Transformation needs, this individual will develop short and long-term strategies for market share growth and trusted advisor status within the accounts. They will also develop strategies for profit and pricing proposals, and account territory strategies utilizing the powerful network of interlocking teams and resources. The ISG Global Account Representative will be paired with Global Account Managers (responsible for overall performance to our global customers for all product lines in all regions), also be engaged with extended Global account teams. The ability to lead AND operate in a collaborative team are critical.

Key Responsibility Areas

Meet or exceed quarterly revenue & margin quotas.In charge of the full sales cycle, from quotation to closure. Advocate for client needs during sales cycle and in addressing any delivery issues.Build professional working relationships with the client, up to the C-level.Leverage executive sponsors and other Lenovo resources to strengthen relationship and credibility with client influencers and decision makers.Maintain high-level of customer loyalty and builds trust and integrity.Build and orchestrate sales pipeline activity, ensuring active nurturing of deals and movement of opportunities to close.Represent entire Lenovo portfolio of products and services.Engage partners effectively to improve win rates and delivery of selective deals.


Position Requirements: 

2+ years strategic selling to Large Enterprise Accounts in IT industry required.


Preferred Requirements: 

Successful track record selling to C level executivesExcellent interpersonal and communications skillsAbility to manage multiple complex sales engagementsEnterprise/Infrastructure industry experience required.Strong inter-personal and communications skills, able to manage multiple complex sales engagements concurrently.Possess an entrepreneurial approach that is imaginative, smart, passionate, and approachable.Strong team player and also a Self-motivator with a strong drive for success.Strong hunting and acquisition sales.Remote role, preferred location is Detroit, Michigan open to other locations throughout Midwest region.


The base salary range budgeted for this position is $127,500.00 - $156,500.00. Individuals may also be considered for bonus and/or commission. Lenovo's various benefits can be found at www.lenovobenefits.com

In compliance with Colorado's EPEWA, the expected Application Deadline for this position is 5/10/2024. This applies to both internal and external candidates.

We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, religion, sexual orientation, gender identity, national origin, status as a veteran, and basis of disability or any federal, state, or local protected class.

Additional Locations:

 United States of America - Michigan - Detroit United States of America United States of America - Michigan United States of America - Michigan - Detroit","The Lenovo Infrastructure Solutions Group Global Account Representative position focuses on driving revenue and customer satisfaction for Lenovo’s data center portfolio, with a particular emphasis on global accounts in the manufacturing industry. The role involves full-cycle strategic sales, from initiating customer relationships through to closure, while acting as a trusted advisor by deeply understanding customer needs around data transformation. The representative works collaboratively with Global Account Managers and extended teams, building senior-level relationships, managing pipelines, and leveraging internal and external resources to close complex sales engagements.","You could be the one who changes everything for our 28 million members. Centene is transforming the health of our communities, one person at a time. As a diversified, national organization, you‚Äôll have access to competitive benefits including a fresh perspective on workplace flexibility.

Position Purpose Perform day to day functions to maintain appropriate databases and create reports to monitor network compliance with State requirements.

Create and maintain appropriate databases, including contract network, authorization, third party liability, provider set up corrections, check requests, among othersDesign and generate reports to monitor department activity and State complianceUpdate the delegated F127entity Medicare and Medicaid Attachments on monthly basisProvide appropriate reports and statistical data to other department designees for the necessary follow up and resolutionGeneral administrative support of assigned department

Education/Experience High school diploma or equivalent. Associate‚Äôs degree in related field preferred. 1+ years of provider data or network administration experience, preferably in managed care. Proficient in Microsoft Office applications, preferably Access and Excel. Experience with data management in large databases, reporting and analysis preferred.Pay Range $18.66 - $31.73 per hour

Centene offers a comprehensive benefits package including competitive pay, health insurance, 401K and stock purchase plans, tuition reimbursement, paid time off plus holidays, and a flexible approach to work with remote, hybrid, field or office work schedules. Actual pay will be adjusted based on an individual's skills, experience, education, and other job-related factors permitted by law. Total compensation may also include additional forms of incentives.

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.","{' Microsoft Office': 'MISC', ' Access': 'MISC', ' Excel': 'MISC'}"
171,Centene Corporation,Data Analyst,"You could be the one who changes everything for our 28 million members. Centene is transforming the health of our communities, one person at a time. As a diversified, national organization, you‚Äôll have access to competitive benefits including a fresh perspective on workplace flexibility.

Position Purpose Perform day to day functions to maintain appropriate databases and create reports to monitor network compliance with State requirements.

Create and maintain appropriate databases, including contract network, authorization, third party liability, provider set up corrections, check requests, among othersDesign and generate reports to monitor department activity and State complianceUpdate the delegated entity Medicare and Medicaid Attachments on monthly basisProvide appropriate reports and statistical data to other department designees for the necessary follow up and resolutionGeneral administrative support of assigned department

Education/Experience High school diploma or equivalent. Associate‚Äôs degree in related field preferred. 1+ years of provider data or network administration experience, preferably in managed care. Proficient in Microsoft Office applications, preferably Access and Excel. Experience with data management in large databases, reporting and analysis preferred.Pay Range $18.66 - $31.73 per hour

Centene offers a comprehensive benefits package including competitive pay, health insurance, 401K and stock purchase plans, tuition reimbursement, paid time off plus holidays, and a flexible approach to work with remote, hybrid, field or office work schedules. Actual pay will be adjusted based on an individual's skills, experience, education, and other job-related factors permitted by law. Total compensation may also include additional forms of incentives.

Centene is an equal opportunity employer that is committed to diversity, and values the ways in which we are different. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other characteristic protected by applicable law.","Centene is seeking a detail-oriented individual to join their team in a role focused on maintaining and analyzing provider and network data to ensure compliance with state requirements. The responsibilities include creating and managing databases related to contract networks, authorizations, third-party liability, and provider setup corrections. The role also involves generating reports to track departmental activity and compliance, updating delegated Medicare and Medicaid attachments monthly, and supporting other departments by sharing relevant data and statistics. Additionally, general administrative duties for the assigned department are required.","To qualify, candidates should have at least a high school diploma or equivalent, with an associate degree in a related field preferred. A minimum of one year of experience in provider data or network administration, ideally within managed care, is also required. Proficiency in Microsoft Office, especially Excel and Access, is essential, as is experience working with large datasets and generating reports. The position offers a pay range of $18.66 to $31.73 per hour and comes with a comprehensive benefits package, including flexible work arrangements and various financial and health-related benefits.","{' Microsoft Office': 'MISC', ' Excel': 'MISC', ' Access': 'MISC'}"
172,JPMorgan Chase & Co.,Data Engineer,"Job Description

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.

As a Software Engineer II - AWS RDS Database Engineer at JPMorgan Chase within the Corporate and Investment Banking Division, you are part of an agile team that works to enhance, design, and deliver the software components of the firm‚Äôs state-of-the-art technology products in a secure, stable, and scalable way. As an emerging member of a software engineering team, you execute software solutions through the design, development, and technical troubleshooting of multiple components within a technical product, application, or system, while gaining the skills and experience needed to grow within your role. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm's business objectives.

Job Responsibilities

Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problemsCreates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systemsProduces architecture and design artifacts for complex applications while being accountable for ensuring design constraints are met by software code developmentGathers, analyzes, synthesizes, and develops visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systemsIdentifies hidden problems proactively and patterns in data and uses these insights to drive improvements to coding hygiene and system architectureContributes to software engineering communities of practice and events that explore new and emerging technologiesAdds to team culture of diversity, equity, inclusion, and respectMonitors customer facing databases and ensuring 24x7x365 uptime within our internal SLA of 99.99% with on call responsibilitySets up and configure Amazon RDS database instancesIdentifies optimization opportunities within customer facing databasesManages capacity and plan database resources

Required Qualifications, Capabilities And Skills

Formal training or certification on software engineering concepts and 2+ years applied experienceHands-on practical experience in system design, application development, testing, and operational stabilityProficient in coding in one or more languagesExperience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languagesOverall knowledge of the Software Development Life CycleSolid understanding of agile methodologies such as CI/CD, Applicant Resiliency, and SecurityDemonstrated knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.)

Preferred Qualifications, Capabilities, And Skills

Good to have proficiency in few modern technologies such as: Java version 8+, Spring Boot, Restful Microservices, AWS or Cloud Foundry, KubernetesPreferred minimum of 3 years of experience with Microsoft SQL Server, preferably in a highly transactional / OLTP environmentPreferred experience in performance Testing experience with Blazemeter / JMeter and automation experience with Cucumber / Automated Functional TestingPreferred experience with Datadog and Cloud watchPreferred experience with Microsoft SQL Server tools Experience with Always-On Availability groups preferred.Background in installation and configuration of SQL Server database technology in a development and DBA capacity, including but not limited to data back-up and restore, debugging, optimizing, software patch applications, defragmenting and replacing of databasesPreferred at least 2 years of experience with AWS databases services including RDS SQL

Please note this position is a Hybrid Office Work Position with our Offices in Newport Beach or Philadelphia, PA. This is Not a Remote Only Position. 

About Us

JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world‚Äôs most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, we offer discretionary incentive compensation which may be awarded in recognition of firm performance and individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. We also make reasonable accommodations for applicants‚Äô and employees‚Äô religious practices and beliefs, as well as mental health or physical disability needs. Visit our FAQs for more information about requesting an accommodation.

JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans

About The Team

The Corporate & Investment Bank is a global leader across investment banking, wholesale payments, markets and securities services. The world‚Äôs most important corporations, governments and institutions entrust us with their business in more than 100 countries. We provide strategic advice, raise capital, manage risk and extend liquidity in markets around the world.","The Software Engineer II - AWS RDS Database Engineer at JPMorgan Chase will be part of the Corporate and Investment Banking Division, contributing to the design, enhancement, and support of the firm's advanced technology products. Responsibilities include developing secure and high-quality software solutions, producing system architecture artifacts, and troubleshooting across multiple technical areas. The role also involves working with large data sets for reporting and visualization, ensuring 24/7 uptime for customer-facing databases, optimizing performance, configuring Amazon RDS instances, and managing database capacity.","Candidates are expected to have a minimum of 2+ years of applied experience with formal software engineering training. Proficiency in coding, strong system design skills, and hands-on experience with cloud technologies, especially AWS databases like RDS SQL, are required. Preferred qualifications include experience with Java 8+, Spring Boot, Kubernetes, performance testing tools like JMeter, and monitoring tools such as Datadog and CloudWatch. This hybrid role is based in either Newport Beach or Philadelphia, PA, and offers a competitive compensation and benefits package.","{' RDS SQL': 'MISC', ' Java 8+, Spring Boot': 'MISC', ' Kubernetes': 'MISC', ' Datadog': 'MISC', ' CloudWatch': 'MISC'}"
173,Mainz Brady Group,Data Engineer,"Mainz Brady Group has two18 months contract with for Data Platform Software Engineer with a large media company. This role is Hybrid and will require you to go into the office in either Santa Monica, CA, Austin, TX, San Francisco, CA or Seattle 2-3 days a week.

Requirement:

4+ years of professional programming and design experience in Scala, Java, Python etc.3+ years of big data development experience with technical stacks like Spark, Flink, Singlestore, Kafka, Nifi and AWS big data technologiesStrong knowledge of system / application design and architectureExperience of building industry level high available and scalable serviceExperience with processing large amount of data at petabyte level


Responsibilities:

Lead to build components of large-scale data platform for real-time and batch processing, and own features of big data applications to fit evolving business needsLead to build next-gen cloud based big data infrastructure for batch and streaming data applications, and continuously improve performance, scalability and availabilityBalance architectural and design considerations such as performance, scalability, reusability and flexibility issuesAdvocate the best engineering practices, including the use of design patterns, CI/CD, code review and automated test


Mainz Brady Group is a technology staffing firm with offices in California, Oregon and Washington. We specialize in Information Technology and Engineering placements on a Contract, Contract-to-hire and Direct Hire basis. Mainz Brady Group is the recipient of multiple annual Excellence Awards from the Techserve Alliance, the leading association for IT and engineering staffing firms in the U.S.

Mainz Brady Group is an Equal Opportunity Employer. We are committed to Diversity & Inclusion and incorporate non-discrimination best practices in all of our staffing processes. Mainz Brady Group does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, gender expression, age, disability or any other protected class.","The Data Platform Software Engineer will be responsible for leading the development of components within a large-scale data platform, handling both real-time and batch data processing. This includes designing and building next-generation, cloud-based big data infrastructure to support scalable and high-performing applications. The role requires balancing design considerations such as flexibility, reusability, and performance while also advocating best engineering practices like CI/CD, code reviews, design patterns, and automated testing. The engineer will play a crucial role in evolving the system to meet changing business needs, ensuring robust and efficient data operations at scale.","The ideal candidate should have a minimum of 4 years of professional programming experience using Scala, Java, or Python, and at least 3 years of hands-on experience with big data tools such as Spark, Flink, Singlestore, Kafka, Nifi, and AWS big data services. A strong understanding of application architecture, system design, and building highly available, scalable services is essential. Experience managing and processing petabyte-level data is also required. The position is hybrid and requires on-site presence 2–3 days a week in specified locations, including Santa Monica, Austin, San Francisco, or Seattle.","{' Scala': 'MISC', ' Java': 'MISC', ' Python': 'MISC'}"
174,Synechron,Data Engineer,"We are

At Synechron, we believe in the power of digital to transform businesses for the better. Our global consulting firm combines creativity and innovative technology to deliver industry-leading digital solutions. Synechron‚Äôs progressive technologies and optimization strategies span end-to-end Artificial Intelligence, Consulting, Digital, Cloud & DevOps, Data, and Software Engineering, servicing an array of noteworthy financial services and technology firms. Through research and development initiatives in our FinLabs we develop solutions for modernization, from Artificial Intelligence and Blockchain to Data Science models, Digital Underwriting, mobile-first applications and more. Over the last 20+ years, our company has been honored with multiple employer awards, recognizing our commitment to our talented teams. With top clients to boast about, Synechron has a global workforce of 14,700+, and has 48 offices in 19 countries within key global markets.

Our challenge

This position is for a Cloud Data engineer with a background in Python, Pyspark, SQL and data warehousing for enterprise level systems. The position calls for someone that is comfortable working with business users along with business analyst expertise.

The Role

Responsibilities:

Build and optimize data pipelines for efficient data ingestion, transformation and loading from various sources while ensuring data quality and integrity. Design, develop, and deploy Spark program in databricks environment to process and analyze large volumes of data. Experience of Delta Lake, DWH, Data Integration, Cloud, Design and Data Modelling. Proficient in developing programs in Python and SQLExperience with Data warehouse Dimensional data modeling. Working with event based/streaming technologies to ingest and process data. Working with structured, semi structured and unstructured data. Optimize Databricks jobs for performance and scalability to handle big data workloads. Monitor and troubleshoot Databricks jobs, identify and resolve issues or bottlenecks. Implement best practices for data management, security, and governance within the Databricks environment. Experience designing and developing Enterprise Data Warehouse solutions. Proficient writing SQL queries and programming including stored procedures and reverse engineering existing process. Perform code reviews to ensure fit to requirements, optimal execution patterns and adherence to established standards. 

Requirements: 

You are:

Minimum 9+ years of experience is required. 5+ years Python coding experience. 5+ years - SQL Server based development of large datasets5+ years with Experience with developing and deploying ETL pipelines using Databricks Pyspark. Experience in any cloud data warehouse like Synapse, Big Query, Redshift, Snowflake. Experience in Data warehousing - OLTP, OLAP, Dimensions, Facts, and Data modeling. Previous experience leading an enterprise-wide Cloud Data Platform migration with strong architectural and design skills. Experience with Cloud based data architectures, messaging, and analytics. Cloud certification(s). Minimally a BA degree within an engineering and/or computer science disciplineMaster‚Äôs degree strongly preferred

It would be great if you also had:

Any experience with Airflow is a Plus. 

We can offer you:

A highly competitive compensation and benefits packageA multinational organization with 48 offices in 19 countries and the possibility to work abroadLaptop and a mobile phone10 days of paid annual leave (plus sick leave and national holidays)Maternity & Paternity leave plansA comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region)Retirement savings plansA higher education certification policyCommuter benefits (varies by region)Extensive training opportunities, focused on skills, substantive knowledge, and personal developmentOn-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses‚ÄØCoaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groupsCutting edge projects at the world‚Äôs leading tier-one banks, financial institutions and insurance firmsA flat and approachable organizationA truly diverse, fun-loving and global work culture

S YNECHRON‚ÄôS DIVERSITY & INCLUSION STATEMENT

Diversity & Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‚ÄòSame Difference‚Äô is committed to fostering an inclusive culture ‚Äì promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more.

All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant‚Äôs gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.

Candidate Application Notice","The Cloud Data Engineer at Synechron will be responsible for building, optimizing, and maintaining large-scale data pipelines and ETL workflows using Databricks, Python, PySpark, and SQL in a cloud environment. The role involves designing efficient data ingestion and transformation pipelines, optimizing Databricks jobs for scalability and performance, and implementing best practices in data quality, security, and governance. Key tasks include working with structured and unstructured data, integrating event-based/streaming technologies, supporting enterprise data warehousing efforts, performing code reviews, and collaborating with stakeholders to ensure business and technical requirements are met.","Ideal candidates should have at least 9 years of relevant experience, including 5+ years of Python and SQL programming and hands-on expertise in Databricks and cloud-based data warehousing platforms like Synapse, BigQuery, Redshift, or Snowflake. A strong foundation in data modeling (OLTP, OLAP), ETL development, and cloud data architecture is required, along with prior experience leading enterprise-wide cloud migration projects. Preferred qualifications include cloud certifications, experience with Airflow, and a master’s degree in computer science or a related field. Candidates must also possess strong architectural skills and a passion for innovative data solutions in a fast-paced financial technology environment.","{' Python': 'MISC', ' SQL': 'MISC'}"
175,Havicma Logistics,Data Scientist,"About Us:
At Havicma Logisitics, we're revolutionizing the delivery industry by leveraging data-driven insights to provide fast, efficient, and reliable delivery services to our customers. Join our innovative team from anywhere in the world and be part of shaping the future of delivery!

Job Description:
Are you passionate about using data to drive business decisions and enhance user experiences? Join us as a Remote Data Scientist and play a key role in optimizing our delivery operations. We're seeking a talented individual with expertise in SQL, MongoDB, and cloud computing services to help us analyze data, uncover insights, and improve our delivery processes.

Responsibilities:
- Utilize SQL and MongoDB to query, manipulate, and analyze large datasets effectively.
- Design and implement advanced machine learning models and algorithms to optimize delivery routes, predict demand, and enhance overall efficiency.
- Collaborate closely with cross-functional teams to develop data-driven strategies and solutions that improve delivery performance and customer satisfaction.
- Explore and implement cloud computing services such as AWS, Azure, or Google Cloud Platform to optimize data storage, processing, and analytics workflows.
- Communicate findings and recommendations to stakeholders in a clear and compelling manner, driving actionable insights and business decisions.

Requirements:
- Advanced degree in Computer Science, Statistics, Mathematics, or a related field.
- Proven experience in applying machine learning techniques to real-world problems.
- Proficiency in programming languages such as Python, R, or Julia.
- Strong understanding of SQL and experience with relational databases.
- Familiarity with MongoDB and NoSQL database concepts.
- Basic knowledge of cloud computing services, with experience in AWS, Azure, or Google Cloud Platform preferred.
- Excellent analytical and problem-solving skills, with a keen eye for detail.
- Outstanding communication skills and the ability to convey complex ideas effectively.

Perks:
- Exciting opportunities to work on cutting-edge projects with global impact.
- Remote-friendly environment with flexible work hours.
- Competitive salary and comprehensive benefits package.
- Access to top-of-the-line tools and resources to fuel your creativity and innovation.
- Supportive team culture that values collaboration, diversity, and personal growth.

Join Us:
If you're ready to make a difference in the delivery industry and be part of a dynamic team that's shaping the future of delivery services, we want to hear from you! OPT and H1B candidates are welcome to apply.","As a Remote Data Scientist at Havicma Logistics, your primary responsibility will be to use data analytics and machine learning to drive strategic decisions and optimize the company's delivery operations. You’ll work with large datasets using SQL and MongoDB, develop advanced models for route optimization and demand forecasting, and collaborate with cross-functional teams to implement data-driven solutions. Additionally, you’ll explore and integrate cloud services such as AWS, Azure, or Google Cloud to improve data workflows and analytics capabilities. Communicating insights clearly to stakeholders and turning data into actionable strategies will be key to your success.","Candidates should possess an advanced degree in a quantitative field such as Computer Science, Statistics, or Mathematics and have hands-on experience in machine learning and data analysis. Proficiency in Python, R, or Julia is required, along with strong skills in SQL and familiarity with MongoDB. Experience working with cloud platforms is a plus. The role demands strong analytical thinking, excellent communication skills, and a detail-oriented mindset. In return, Havicma offers a remote-friendly, flexible work environment, competitive compensation, and opportunities to contribute to high-impact global projects in the logistics industry.","{' Python': 'MISC', ' R': 'MISC', ' Julia': 'MISC', ' SQL': 'MISC', ' MongoDB': 'MISC'}"
176,USAA,Data Scientist,"Why USAA?

At USAA, we have an important mission: facilitating the financial security of millions of U.S. military members and their families. Not all of our employees served in our nation‚Äôs military, but we all share in the mission to give back to those who did. We‚Äôre working as one to build a great experience and make a real impact for our members.

We believe in our core values of honesty, integrity, loyalty and service. They‚Äôre what guides everything we do ‚Äì from how we treat our members to how we treat each other. Come be a part of what makes us so special!

The Opportunity

We offer a flexible work environment that requires an individual to be in the office 4 days per week. This position can be based in one of the following locations: San Antonio, TX; Phoenix, AZ; Colorado Springs, CO; Plano, TX or Tampa, FL.

Relocation assistance is not available for this position.

This candidate selected for this position will be working on the D&S Data Science team applying artificial intelligence and machine learning solutions to support a variety of business applications from automating key business processes, to improved routing of phone calls, to better understanding our members needs and the service we deliver. This position will work with a broad range of business partners from product lines to contact center and everything in between.

Translates business problems into applied statistical, machine learning, simulation, and optimization solutions to advise actionable business insights and drive business value through automation, revenue generation, and expense and risk reduction. In collaboration with engineering partners, delivers solutions at scale, and enables customer-facing applications. Leverages database, cloud, and programming knowledge to build analytical modeling solutions using statistical and machine learning techniques. Collaborates with other data scientists to improve USAA‚Äôs tooling, growing the company‚Äôs library of internal packages and applications. Works with model risk management to validate the results and stability of models before being pushed to production at scale.

What You‚Äôll Do

Captures, interprets, and manipulates structured and unstructured data to enable analytical solutions for the business.Selects the appropriate modeling technique and/or technology with consideration to data limitations, application, and business needs.Develops and deploys models within the Model Development Control (MDC) and Model Risk Management (MRM) framework.Composes technical documents for knowledge persistence, risk management, and technical review audiences. Consults with peers for mentorship, as needed.Translates business request(s) into specific analytical questions, executing on the analysis and/or modeling, and communicating outcomes to non-technical business colleagues.Consults with Data Engineering, IT, the business, and other internal stakeholders to deploy analytical solutions that are aligned with the customer‚Äôs vision and specifications and consistent with modeling best practices and model risk management standards.Seeks opportunities and materials to learn new techniques, technologies, and methodologies.Ensures risks associated with business activities are optimally identified, measured, monitored, and controlled in accordance with risk and compliance policies and procedures.

What You Have

Bachelor‚Äôs degree in mathematics, computer science, statistics, economics, finance, actuarial sciences, science and engineering, or other similar quantitative discipline; OR 4 years of experience in statistics, mathematics, quantitative analytics, or related experience (in addition to the minimum years of experience required) may be substituted in lieu of degree.2 years of experience in predictive analytics or data analysis OR advanced degree (e.g., Master‚Äôs, PhD) in mathematics, computer science, statistics, economics, finance, actuarial sciences, science and engineering, or other similar quantitative discipline.Experience in training and validating statistical, physical, machine learning, and other advanced analytics models.Experience in one or more dynamic scripted language (such as Python, R, etc.) for performing statistical analyses and/or building and scoring AI/ML models.Ability to write code that is easy to follow, well detailed, and commented where necessary to explain logic (high code transparency).Experience in querying and preprocessing data from structured and/or unstructured databases using query languages such as SQL, HQL, NoSQL, etc.Experience in working with structured, semi-structured, and unstructured data files such as delimited numeric data files, JSON/XML files, and/or text documents, images, etc.Familiarity with performing ad-hoc analytics using descriptive, diagnostic, and inferential statistics.Experience with the concepts and technologies associated with classical supervised modeling for prediction such as linear/logistic regression, discriminant analysis, support vector machines, decision trees, forest models, etc.Experience with the concepts and technologies associated with unsupervised modeling such as k-means clustering, hierarchical/agglomerative clustering, neighbors algorithms, DBSCAN, etc.Ability to communicate analytical and modeling results to non-technical business partners.

What Sets You Apart

Knowledge or experience with Natural Language Processing (NLP).Intermediate experience using Python.

The above description reflects the details considered necessary to describe the principal functions of the job and should not be construed as a detailed description of all the work requirements that may be performed in the job.

What We Offer

Compensation: USAA has an effective process for assessing market data and establishing ranges to ensure we remain competitive. You are paid within the salary range based on your experience and market data of the position. The actual salary for this role may vary by location. The salary range for this position is: $89,990 - $161,990.

Employees may be eligible for pay incentives based on overall corporate and individual performance and at the discretion of the USAA Board of Directors.

Benefits: At USAA our employees enjoy best-in-class benefits to support their physical, financial, and emotional wellness. These benefits include comprehensive medical, dental and vision plans, 401(k), pension, life insurance, parental benefits, adoption assistance, paid time off program with paid holidays plus 16 paid volunteer hours, and various wellness programs. Additionally, our career path planning and continuing education assists employees with their professional goals.

For more details on our outstanding benefits, please visit our benefits page on USAAjobs.com.

Applications for this position are accepted on an ongoing basis, this posting will remain open until the position is filled. Thus, interested candidates are encouraged to apply the same day they view this posting. 

USAA is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.","As a Data Scientist at USAA, you'll work within the D&S Data Science team, applying AI and machine learning solutions to enhance business performance across departments such as customer service and product lines. Your responsibilities will include developing, validating, and deploying predictive models, translating business needs into actionable data solutions, and working closely with engineering partners to implement scalable, efficient models. You’ll manage data across structured and unstructured formats, use tools such as Python, SQL, and cloud platforms, and contribute to knowledge-sharing by documenting methodologies and mentoring where needed. Additionally, your role will require you to align with USAA’s Model Risk Management standards and ensure that data science solutions support informed, risk-aware business decisions.","To qualify, candidates should have at least a bachelor’s degree in a quantitative field or equivalent experience, and a minimum of two years in predictive analytics or data analysis. Required skills include experience with scripting languages like Python or R, SQL or NoSQL databases, and supervised and unsupervised machine learning techniques. Ideal candidates will also have intermediate-level Python expertise and knowledge of Natural Language Processing (NLP). The position requires strong communication skills, the ability to simplify technical results for non-technical stakeholders, and a commitment to continuous learning. This hybrid role requires on-site presence four days a week in one of USAA's designated office locations.","{' Python': 'MISC', ' R': 'MISC', ' SQL': 'MISC', ' NoSQL': 'MISC'}"
177,"Navitas Partners, LLC",Data Engineer,"Title: Application Development AnalystLocation: Tallahassee, FL 32399Project Duration: 12 Months Position Summary:Collaborate with a team to integrate in-house applications with a new statewide system (PALM).Focus on a specific division's applications but may be assigned others as needed. Key Responsibilities:Maintain, enhance, and support various agency business applications.Assist in documenting program requirements and user needs.Analyze existing databases and write scripts to migrate data.Manage Oracle database objects (schemas, tables, etc.) using SQL.Update scripts and scheduled tasks using tools like CRON jobs.Develop and maintain user manuals and guides.Troubleshoot software issues and collaborate with IT professionals.Participate in all project phases (testing, meetings, etc.).Modify Oracle Forms applications to reflect database changes.Develop or revise PHP reports as needed. Required Skills and Experience:7+ years of experience with Oracle databases (complex queries, PL/SQL objects).3+ years of experience with Oracle Forms and database performance tuning.3+ years of experience with financial data and internal controls.Experience with relational databases, continuous integration tools (Jenkins), and SQL query tools.Strong communication, interpersonal, and problem-solving skills.Ability to work independently, manage priorities, and meet deadlines. Preferred Skills and Experience:Oracle certifications, accounting principles (GAAP), and web development experience (XML, CSS, Javascript frameworks).Experience with code repositories (Git), continuous integration tools (Jenkins), and Agile development methodologies (Scrum, XP, Kanban).Familiarity with DEP's technical environment and environmental regulations.","The Application Development Analyst will work in Tallahassee, FL, supporting a 12-month project focused on integrating in-house business applications with Florida’s new statewide system (PALM). The analyst will be responsible for maintaining, enhancing, and troubleshooting agency applications—particularly those related to financial data. Key tasks include documenting requirements, migrating data between databases, managing Oracle objects, updating scripts and reports, and participating in all project phases. Experience with Oracle Forms, CRON jobs, and PHP is also essential, along with the ability to collaborate with cross-functional IT teams.","Qualified candidates must have at least 7 years of experience working with Oracle databases (including PL/SQL), 3 years of experience in Oracle Forms, and a strong background in financial data and internal controls. Ideal candidates will also be skilled in relational databases, Jenkins, and SQL query tools, and possess strong communication and problem-solving abilities. Preferred qualifications include Oracle certifications, familiarity with GAAP, web development skills (XML, CSS, JavaScript), experience with Git and Agile methodologies, and knowledge of environmental regulations and DEP’s technical systems.","{' Oracle': 'ORG', ' Oracle Forms': 'MISC', ' SQL': 'MISC', ' Git': 'MISC'}"
182,Scale AI,Data Scientist,"Scale is looking for a data scientist to join our team to help advance the development of AI. As a member of the data science team, you will lead the charge of building our data science infrastructure for marketplace products and driving insights that lead to step-function improvements in how we operate. The ideal candidate is detail-oriented, rigorous about validating results, talented at distilling down complexity, and loves tackling and solving hard problems.

You will:

Build evaluation frameworks to measure marketplace efficacy and behavioral economicsAdapt statistical models to solve specific hard problems in fields of marketplace experimentation, econometrics, and incentivesBe a proactive partner to your business stakeholders and provide insights and conclusions rather than just data outputs/modelsTackle business-critical questions by developing and testing hypotheses, and aiding evidence-based decision makingPartner with Product Managers, Data Engineers, Data Scientists, and Business Stakeholders to drive business decisions and product roadmaps

Ideally, You'd Have:

2+ years of industry experience in a highly analytical roleDegree in a quantitative field (e.g., Maths, Engineering)Expert-level proficiency in writing complex SQL queries across large datasetsExpertise in designing metrics and diagnosing data inconsistenciesExperience working with marketplace experiments (causal inference)Proficiency in Python

Compensation packages at Scale include base salary, equity, and benefits. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position, determined by work location and additional factors, including job-related skills, experience, interview performance, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Scale employees are also granted Stock Options that are awarded upon board of director approval. You‚Äôll also receive benefits including, but not limited to: Comprehensive health, dental and vision coverage, retirement benefits, a learning and development stipend, and generous PTO. Additionally, this role may be eligible for additional benefits such as a commuter stipend.

The base salary range for this full-time position in the locations of San Francisco, New York, Seattle is:

$148,000 ‚Äî $177,600 USD

About Us:

At Scale, we believe that the transition from traditional software to AI is one of the most important shifts of our time. Our mission is to make that happen faster across every industry, and our team is transforming how organizations build and deploy AI. Our products power the world's most advanced LLMs, generative models, and computer vision models. We are trusted by generative AI companies such as OpenAI, Meta, and Microsoft, government agencies like the U.S. Army and U.S. Air Force, and enterprises including GM and Accenture. We are expanding our team to accelerate the development of AI applications.

We believe that everyone should be able to bring their whole selves to work, which is why we are proud to be an affirmative action employer and inclusive and equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability status, gender identity or Veteran status.

We are committed to working with and providing reasonable accommodations to applicants with physical and mental disabilities. If you need assistance and/or a reasonable accommodation in the application or recruiting process due to a disability, please contact us at accommodations@scale.com. Please see the United States Department of Labor's Know Your Rights poster for additional information.

We comply with the United States Department of Labor's Pay Transparency provision .

PLEASE NOTE: We collect, retain and use personal data for our professional business purposes, including notifying you of job opportunities that may be of interest and sharing with our affiliates. We limit the personal data we collect to that which we believe is appropriate and necessary to manage applicants‚Äô needs, provide our services, and comply with applicable laws. Any information we collect in connection with your application will be treated in accordance with our internal policies and programs designed to protect personal data.","As a Data Scientist at Scale, your core responsibilities include developing robust evaluation frameworks for marketplace efficacy, building statistical models tailored to experimentation and incentive systems, and deriving actionable insights for business-critical decisions. You will collaborate closely with product managers, engineers, and stakeholders to influence product roadmaps and strategy. Your focus will be on applying rigorous analytical techniques—such as causal inference and econometrics—to large datasets in order to optimize marketplace behavior and operational efficiency.","Ideal candidates will bring at least 2 years of experience in a highly analytical role, a degree in a quantitative discipline, and expert proficiency in SQL and Python. Experience with marketplace data, metric design, and diagnosing data inconsistencies is essential, especially in environments requiring experimentation and behavioral analysis. Compensation for this San Francisco, New York, or Seattle-based role ranges from $148,000 to $177,600 in base salary, in addition to equity and comprehensive benefits.","{' SQL': 'MISC', ' Python': 'MISC', ' San Francisco': 'MISC', ' New York': 'MISC', ' Seattle-based': 'MISC'}"
183,iO Associates - US,Data Engineer,"Are you passionate about database development and data warehousing? Our partner is seeking for a talented SQL Server Database Engineer to join their dynamic team. In this role, you'll play a pivotal part in building, managing, and optimizing their enterprise data architecture. Responsibilities:Collaborate with software and analytics teams to design and implement robust database architectures and applications.Enhance database performance and automate processes for efficiency.Set and maintain high standards for database development practices.Modernize our data warehouse to ensure reliable, consistent data access.Develop custom data pipelines for ETL processes.Ensure the stability and performance of SQL Server environments (including SSIS/SSRS/MDS).Document configurations, test scripts, and functional specifications for integrations and reporting.
Qualifications:Bachelor's degree in Information Technology, Computer Science, or equivalent professional experience.4-5 years of experience in SQL Server database development and data warehouse design.Proficiency in Azure data services (Azure SQL Database, Azure Data Factory).Experience with Red Gate tools (SQL Source Control, SQL Compare).A strong foundation in data warehousing principles and data analytics.Excellent problem-solving skills to address data issues and logical discrepancies.Familiarity with SQL Server, cloud technologies, microservice architecture, and Azure DevOps.
COMPENSATIONCompetitive salary commensurate with experience plus yearly bonusHealth InsuranceDental InsuranceVision InsuranceLife InsuranceDisability Insurance401K planPTOPaid Holidays","This opportunity is ideal for a skilled SQL Server Database Engineer who is enthusiastic about database development and data warehousing. In this role, you’ll collaborate closely with software and analytics teams to design robust database architectures and enhance database performance through process automation and best practices. A core part of the role includes modernizing the organization’s data warehouse for consistent and reliable data access, building custom ETL pipelines, and ensuring the stability of SQL Server environments including tools like SSIS, SSRS, and MDS. Clear documentation for system configurations, test scripts, and reporting requirements is also a key responsibility.","a Bachelor’s degree in Information Technology, Computer Science, or equivalent experience, along with 4–5 years of experience in SQL Server development and data warehouse architecture. Proficiency in Azure data services such as Azure SQL Database and Azure Data Factory is essential, as is experience with Red Gate tools. Candidates should bring a solid understanding of data warehousing principles and analytics, problem-solving skills to handle data anomalies, and familiarity with cloud technologies, microservices, and Azure DevOps. This full-time role offers a competitive salary, bonus, and a robust benefits package including health, dental, vision, 401(k), PTO, and more.","{' SQL Server': 'MISC', ' Red Gate': 'MISC', ' Azure DevOps': 'MISC'}"
186,FedEx Logistics,Data Analyst,"100% onsite role located in LaVergne, TN

Please note that visa sponsorship is not available for this position.

General Summary

The Analyst, Data II is part of a team that shares the responsibility for success and profitability by providing services to our customers which may include: data warehousing, post audits, reporting, carrier bids management, dashboard creation, project management, transportation analysis, application mastery, consulting support, and data analysis. The Data Analyst works with customers, carriers, and internal employees to analyze and identify cost saving opportunities for customers.

Primary Responsibilities

Manage data gathering for customers‚Äô benchmark key performance metrics.Create a strategic approach to carrier bids through lane, mode, and service balancing (Bid team) by performing the following tasks: Scorecard and performance tracking, transportation dashboard, on-going analysis of data. Determine the best mode, carrier, and service for the customer, resulting in customer savings by providing the analysis and metrics for transportation bids.Use professional judgment to assess the impact of decisions/actions on the customer and the Company which would be approved by both the customer and the person‚Äôs leader.Act as an internal technical resource for role specific applications.Analyze large amounts of data and then recommend broad based innovative improvement initiatives for customer(s).Reporting and analyzing on an ad hoc basis for the customer. Develop customer presentations showing data trends and possible solutions to the customer. Collaborate with the objective of agreeing to the most effective and profitable solution for the customer, carrier, and the Company.Developing standard operating procedures based on the direction from manager.

Education/Experience

Bachelor‚Äôs Degree in Statistics, Engineering, Accounting/Finance or related field preferred and 5+ years of relevant experience.In lieu of degree, high school diploma or GED and 4-6 years of relevant experience.Proficient with technology, specifically Microsoft applications such as Access and Excel.Experience with SQL is preferred.Ability to work in a fast paced environment with multiple deadlines.Strong organizational skills and the ability to handle multiple tasks simultaneously.Strong interpersonal skills with the ability to work with internal and external customers.Experience or knowledge in transportation, logistics, parcel shipping or freight pay is preferred.Excellent written and verbal communication skills.

Physical/Cognitive Requirements

With or without accommodation:

Ability to follow policies and procedures.Ability to read, write and interpret information.Ability to add, subtract, multiply and divide. Ability to use hands to manipulate, handle, or feel.Ability to sit/walk/stand for up to 8 hours per day. Must possess visual acuity, i.e., close, distance, and color vision, depth perception and the ability to adjust focus.

Working Conditions

General office environment that is generally favorable. Lighting and temperature are adequate, and there are no hazardous or unpleasant conditions caused by noise, dust, etc. Work is generally performed within an office environment with standard office equipment available.

ADA

The Company is committed to making reasonable accommodations for qualified individuals with disabilities in accordance with the ADA and any other applicable federal, state, or local laws. If you require an accommodation to perform the job, now or in the future, please contact your Human Resources Representative. Upon request, Human Resources will engage in an interactive process with you to determine whether or not a reasonable accommodation is available.

Disclaimer

The above information is only an illustration of the general nature and level of work performed by the employee within this classification. The omission of specific statements of duties does not exclude them from the position if the work is similar, related or a logical assignment to the position.

The job description does not constitute an employment agreement between the Company and employee and is subject to change by the Company as the needs of the Company and requirements of the job change.

Job ID: 52079

Schedule: Full-time","In this position, you’ll play a key role in optimizing transportation and logistics operations by managing data for benchmarking, carrier bid analysis, scorecard development, and dashboard reporting. You'll work closely with internal teams, customers, and carriers to uncover cost-saving opportunities and implement impactful solutions.","Ideal candidates will have a bachelor’s degree in a related field and 5+ years of relevant experience (or equivalent experience in lieu of a degree). Strong skills in Microsoft Access and Excel are essential, with SQL proficiency preferred. A background in transportation, logistics, parcel shipping, or freight pay is highly valued. This role requires excellent analytical, organizational, and communication skills, along with the ability to work efficiently in a fast-paced environment. Please note that visa sponsorship is not available for this position.","{' Microsoft Access': 'MISC', ' Excel': 'MISC', ' SQL': 'MISC'}"
187,Wipro,Data Engineer,"About Wipro:

Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients‚Äô most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.

A PROUD HISTORY OF OVER 75 YEARSFY22 REVENUE 10.4 BN USDWE‚ÄôRE PRESENT IN 66 COUNTRIESOVER 1,400 ACTIVE GLOBAL CLIENTS

Title - Azure Synapse Data Engineer

Location - Remote (Anywhere in USA) Should be willing to work in CST time zone.

Primary Skills - Apache Spark, Hadoop, Scala, Azure Synapse, Azure Databricks

Secondary Skills - SSIS

Job Description -

Overall IT experience: 10+ yearsNeed a Sr Data Engineer who has 5+ years of experience in Azure native services with good exposure to ADF, Synapse, ADLS Gen2, Strong SQL skills, spark.Experience in analyzing/reverse engineering SSIS packages to re-platform solution on AzureDesigning Synapse tables and implementing data solutions within the Azure ecosystem.Design , develop and implement Synapse tables to support data ingestion, transformation and storage processes.Utilize Spark Scala / SQL to build scalable and efficient data pipelines within Azure Synapse.Optimize data storage, ensuring high performance and reliability in Synapse environment.Provide expertise in troubleshooting and resolving data related issues within Azure Synapse.Collaborate with cross-functional teams to understand data requirements and translate them into technical solutions.Proven experience working with Azure Synapse Analytics.Proficiency in Spark Scala/SQL for data processing and transformation.Strong understanding of data modelling concepts and database design principles within Synapse.Ability to optimize and tune Synapse tables for performance and scalability.Excellent communication skills and the ability to work collaboratively in a team environment.

Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.

Azure Data Factory","Wipro is seeking a Senior Azure Synapse Data Engineer with over 10 years of overall IT experience and at least 5 years in Azure data services. This role is fully remote but requires the flexibility to work in Central Standard Time (CST). The ideal candidate will bring expertise in Azure Synapse, ADF, Databricks, ADLS Gen2, Spark (Scala/SQL), and strong SQL skills, along with experience analyzing and migrating SSIS packages.","Responsibilities include designing and developing Synapse tables, building scalable data pipelines with Spark in the Azure environment, optimizing data storage, resolving data issues, and collaborating with cross-functional teams to deliver robust data solutions. A solid understanding of data modeling, database performance tuning, and Azure analytics tools is essential for this role. Strong communication and collaboration skills are also key.","{' Synapse': 'MISC', ' Azure': 'MISC'}"
188,University of Virginia,Data Scientist,"The School of Data Science (SDS) at the University of Virginia (UVA) seeks an Intermediate Data Scientist to work in collaboration with Don Brown, PhD and Sana Syed, MD, MS, focusing on understanding gut structure and function in common gastrointestinal (GI) diseases using cutting-edge machine learning and AI methods. The overarching goal of this work is to personalize care for pediatric patients suffering from chronic GI disease by improving diagnostics, predicting future disease complications, and identifying better disease biomarkers and novel drug targets. Details about the Gastro Science Lab and the Syed lab can be found at https://gastrodatasciencelab.org/ and https://med.virginia.edu/sana-syed-lab/.

This is a one year restricted position continuation is based on the availability of funding and satisfactory performance.

Data Scientists provide sophisticated data management and analysis to support University projects or programs. They focus primarily on high-level data projections and statistical analysis. They manage the design and programming of all data entry forms and the training and supervision of project research coders, student workers, and volunteers. They oversee regular assessments of reliability, submit data on a monthly basis, and assist with literature searches pertinent to various research project topics.

The Successful Candidate Will

Work in a professional manner and have a strong willingness to learn and improve.Promote a culture of excellence by supporting others and generating new ideas to drive the lab forward.Act as a champion for the lab‚Äôs research at local, regional, and national conferences.Drive the collection of new data and the refinement of existing data for new purposes.Independently and creatively analyze data to test or refine hypotheses.Explore and examine data from multiple disparate sources in order to identify, analyze, and report trends in the data.Develop and execute of statistical mathematical and predictive models.Visualize and report data findings creatively in a variety of visual formats to support research presentations, manuscripts, and media write-ups.Establish links across existing data sources and find new interesting data correlations.Lead projects in concept formulation, determination of appropriate statistical methodology, data analysis, research evaluation, and final research reporting.Collaborate across faculty and staff to provide actionable data-driven insights.Formulate and define analytic scope and objectives through research and fact-finding as a self-starter.Be a leader of a lab data science team and provide guidance to less experienced data analysts/scientists.

Qualifications

Master's Degree and at least 3 years of relevant experience.Strong Organization and time line management skills .Experience in AI/ML modeling approaches such as: metabolic modeling, convolutional neural networks, and Gradient-weighted Class Activation Mapping.Understand all phases of the analytic process including data collection, preparation, modeling, evaluation, and deployment.

Anticipated hiring range: $100,000 - $120,000 / annual

To Apply

Please visit UVA job board: https://jobs.virginia.edu and search for ‚ÄúR0056431‚Äù

Complete An Application And Attach

Cover LetterCurriculum Vitae 

Please note that multiple documents can be uploaded in the box.

INTERNAL APPLICANTS: Please search for ""find jobs"" on your workday home page and apply using the internal job board.

Review of applications will begin January 22, 2024 and continue until the position is filled.

For questions about the position, please contact: Adam Greene, Research Program Officer (arg7ef@virginia.edu) For questions about the application process, please contact: Rhiannon O'Coin (mo2r@virginia.edu)

For more information about the School of Data Science, please see www.datascience.virginia.edu

For more information about the University of Virginia and the Charlottesville community, please see www.virginia.edu/life/charlottesville and www.embarkuva.com

The selected candidate will be required to complete a background check at the time of the offer per University policy.

PHYSICAL DEMANDS This is primarily a sedentary job involving extensive use of desktop computers. The job does occasionally require traveling some distance to attend meetings, and programs.

The University of Virginia, including the UVA Health System which represents the UVA Medical Center, Schools of Medicine and Nursing, UVA Physician‚Äôs Group and the Claude Moore Health Sciences Library, are fundamentally committed to the diversity of our faculty and staff. We believe diversity is excellence expressing itself through every person's perspectives and lived experiences. We are equal opportunity and affirmative action employers. All qualified applicants will receive consideration for employment without regard to age, color, disability, gender identity or expression, marital status, national or ethnic origin, political affiliation, race, religion, sex (including pregnancy), sexual orientation, veteran status, and family medical or genetic information.","The Intermediate Data Scientist position at the University of Virginia’s School of Data Science offers a unique opportunity to contribute to high-impact research at the intersection of artificial intelligence and pediatric gastrointestinal (GI) health. Working in collaboration with Dr. Don Brown and Dr. Sana Syed, the successful candidate will be instrumental in developing machine learning models and data-driven strategies to enhance diagnostics and treatment personalization for children with chronic GI diseases. The role is central to the Gastro Data Science Lab, blending clinical insight with computational innovation to unlock new biomarkers, refine predictive tools, and support targeted therapeutics.","Applicants should hold a Master’s degree and have a minimum of 3 years of experience in relevant data science roles, particularly those involving AI/ML methods like convolutional neural networks, metabolic modeling, and Grad-CAM. Key responsibilities include leading analytics projects, synthesizing and visualizing complex datasets, publishing research findings, and mentoring junior data team members. This is a one-year, full-time position with a salary range of $100,000–$120,000, renewable based on funding and performance. To apply, visit the UVA job board and search for “R0056431.” Applications require a cover letter and curriculum vitae.",{' AI/ML': 'MISC'}
193,Honeywell,Data Engineer,"Driving Infinite Possibilities Within A Diversified, Global Organization

The Future Is What You Make It.

When you join Honeywell, you become a member of our global team of thinkers, innovators, dreamers and doers who make the things that make the future.

That means changing the way we fly, fueling jets in an eco-friendly way, keeping buildings intelligent and safe and even making it possible to breathe on Mars

Working at Honeywell isn‚Äôt just about developing cool things. That‚Äôs why all of our employees enjoy access to dynamic career opportunities across different fields and industries.

Are you ready to help us make the future?

Join a team that is elevating our strategy to drive advanced analytics and visualization tools across the Commercial enterprise. In this role, Data Engineer ‚Äì Commercial, you will design, implement, and manage the data architecture, systems, and processes to effectively collect, store, process and analyze high volume, high dimensional data to provide strategic insight into complex business problems. This will involve creating and maintaining scalable, efficient, and secure data pipelines, data warehouses, and data lakes. You need to ensure consistency in data quality and availability for analysis and reporting including compliance with data governance and security standards

Responsibilities

Work in complex data science and analytics projects in support of the Commercial organization.Work with product owner to identify the data requirements and design/ maintain/ optimize data pipeline to ingest, transform, and load structured and unstructured data from various sources into the data warehouse or data lake.Design and implement data models and schemas to support analytical and reporting requirements.Collaborate with data scientists and analysts to define and structure data for effective analysis and reporting.Develop and maintain ETL (Extract, Transform, Load) processes.Administer, optimize, and manage databases, data warehouses, and data lakes to ensure performance, reliability, and scalability.Enforce data governance policies, standards, and best practices to maintain data quality, privacy, and security.Create and maintain comprehensive documentation for data architecture, processes, and systems.Troubleshoot and resolve data-related problems and optimize system performance.Partner with IT support team on production processes, continuous improvement, and production deployments.

YOU MUST HAVE

Bachelor‚Äôs degree from an accredited institution in a technical discipline such as the sciences, technology, engineering or mathematicsTwo or more years of relevant experience in Data Engineering, ETL Development, Database Administration.Experience in Azure Databricks, CI/CD & Dev Ops ProcessExpert in scripting and querying languages, such as Python, SQL, PySparkExperience with both Structured and Unstructured dataSFDC business/ technical knowledgeKnowledge of Agile development methodology

WE VALUE

Working with at least one NoSQL system (HBase, Cassandra, MongoDB)Knowledge of databases, data warehouse platforms (Snowflake) and Cloud based tools.Experience in using data integration tools for ETL processes.Knowledge of Data Modelling techniques including schema design for both rational and NoSQL databasesUnderstanding of Hadoop's ecosystem (including HDFS) and Spark for processing and analyzing large-scale datasets.Demonstrated experience in cutting-edge packages such as SciKit, TensorFlow, Pytorch, GPT, PySpark, Bit bucket etc.Ability to develop and communicate technical vision for projects and initiatives that can be understood by customers and management.Proven mentoring ability to drive results and technical growth in peers.Effective communication skills (verbal, written, and presentation) for interacting with customers and peers.Demonstrated application of statistics, statistical modeling, and statistical process control.

Additional Information

JOB ID: HRD228162Category: EngineeringLocation: 855 S Mint St,Charlotte,North Carolina,28202,United StatesExempt

Engineering (EMEA)

Honeywell is an equal opportunity employer. Qualified applicants will be considered without regard to age, race, creed, color, national origin, ancestry, marital status, affectional or sexual orientation, gender identity or expression, disability, nationality, sex, religion, or veteran status.","As part of a dynamic global team, you’ll be responsible for designing and maintaining scalable data architectures, pipelines, and models to enable insight-driven decision-making. Your work will involve building ETL processes, collaborating with data scientists and business stakeholders, and ensuring high data quality and security in accordance with governance standards.","The ideal candidate will have at least a bachelor’s degree in a technical field and 2+ years of experience in data engineering or database administration. Proficiency in Azure Databricks, Python, SQL, PySpark, and CI/CD processes is essential. Experience with tools like Snowflake, MongoDB, Hadoop, and data modeling techniques is highly valued, as is familiarity with SFDC and agile development methodologies. This role offers the chance to work in a fast-paced, innovation-driven environment and contribute to impactful business outcomes across Honeywell’s commercial operations.","{' Azure Databricks': 'MISC', ' Python': 'MISC', ' SQL': 'MISC', ' PySpark': 'MISC', ' Snowflake': 'MISC', ' MongoDB': 'MISC', ' Hadoop': 'MISC'}"
195,Tata Consultancy Services,Data Analyst,"Relevant Experience

10+ Years

Technical/Functional Skills

Data

Experience Required

10

Roles & Responsibilities

Coordinate with business team to understand the gaps and enable the process to make QMS data is one source of truth.

Generic Managerial Skills 

Digital : Python for Data Science","As a Data Manager/Lead, your primary role will be to coordinate closely with business teams to identify gaps in data processes and ensure that the Quality Management System (QMS) becomes a single, reliable source of truth. You will be responsible for enabling efficient data workflows, integrating data from various systems, and enhancing the consistency and integrity of business-critical information. Leveraging Python for data science tasks, you will support initiatives related to data analysis, transformation, and automation. Additionally, you will oversee the implementation of standardized data procedures, participate in digital transformation projects, and collaborate with cross-functional stakeholders to drive data strategy and process improvement.","The ideal candidate will have a minimum of 10 years of experience in data management, data governance, or a similar role, with a strong technical background in Python for data science. Proven expertise in working with QMS data, understanding complex data ecosystems, and leading efforts to standardize and centralize enterprise data is essential. Strong communication, analytical, and problem-solving skills are required, along with the ability to manage multiple projects and align stakeholders on data objectives. A background in digital or technical project leadership and familiarity with quality management frameworks are preferred.",{' Python': 'MISC'}
196,StoneX Group Inc.,Data Engineer,"Overview

 The Company 

Innovative, future-focused and collaborative, StoneX Group Inc. (NASDAQ: SNEX) is a global financial services firm with an entrepreneurial culture and a passion for providing world-class services to our clients. A Fortune-100 company with a nearly 100-year track record , with 3, 9 00 employees and over 400,00 retail and institutional clients from more than 80 offices spread across five continents, we connect clients to the global markets ‚Äì focusing on innovation, human connection, and providing world-class products and services to all types of investors.

Today's global financial markets offer a world of opportunities. To trade. To invest. To manage risk. And to grow. We believe in connecting every company, every organization, every trader, and every investor to every advantage they need to succeed in today‚Äôs global markets ecosystem.

But that belief doesn‚Äôt stop at our clients. We also believe in connecting every single one of our employees to every opportunity they need to succeed in their own careers, too. From an entrepreneurial culture to a collaborative environment working alongside highly skilled specialists, a career at StoneX also offers a world of opportunities. To invest in yourself. To achieve. And to grow.

 We Connect Clients to Markets . 

 StoneX Graduate Program 

Are you looking to gain real world experience in an entrepreneurial culture? Consider joining a thriving global financial services firm and  launch your career with StoneX  ! Our Graduate Program connects recent graduates with the opportunit ies that match their skill level within StoneX and provides additional new employee trainings tailored to individuals beginning their career .

 StoneX New Grad Perks: 

In addition to the real-world experience, you‚Äôll gain at StoneX, we‚Äôre excited to offer interns several perks which include the following:

 Compensation : All New Grads are paid at a competitive rate .  Hybrid Model : StoneX works on a hybrid model with the flexibility to work from home and in one of our fully equipped offices around the globe. In office days are made better with free snacks and drinks.  Socials : Networking and acclimation to the company , office, and city are important aspects of the graduate program.  Access to Senior Leaders: Senior leaders are involved in the graduate program delivering trainings , presenting on firm business, and even attending socials.  Training: Virtual and in-person trainings to l earn about the firm and how we do business . As well as getting new grads onboarded and connect ed with the company globally. 


 Position Purpose:  A Graduate Database Administrator is a highly motivated individual that is responsible for managing and maintaining our open source database platforms, ensuring their performance, security and reliability . Working closely with the rest of the DBA team and development team to ensure our databases are optimized for performance and scalability.

Responsibilities

 On call cover as a part of a rotation with other members of the team  Take proactive measures to monitor , trend, and tune databases, such as running maintenance jobs (backups, DBCCs, apply indexes/re-indexing, etc.), to meet or exceed baseline stability and performance SLAs on large databases (1 TB+) and large volumes of databases (100+).  Create, implement, and maintain DB Health Checks/Monitoring, and have a n ability to automate SQL health reporting/event notification, and corrective actions.  Developing ‚Äòbest practice‚Äô standards within the DBA team and working with local and remote development teams to ensure these standards are adhered to  When performance issues arise, determine the most effective way to increase performance including scaling up or out, server configuration changes, index/query changes, etc.  Identify code defects and enhancements and develop a detailed root cause analysis that can be leveraged by the product management and development teams to improve application availability and decrease the total cost of ownership.  Manage and maintain our open-source databases, including installation, configuration, and maintenance.  Develop and maintain scripts to automate database administration tasks.  Stay up-to-date with the latest trends and technologies in database administration.  Adhere to and proactively enhan ce the firm‚Äôs compliance with applicable laws, regulations and codes of conduct in all jurisdictions in which the Firm conducts business and which have an impact on its business  Maintain a high level of conduct, ethical standards and values  Work to identify risks and enhance control across the business  Report control weaknesses, illegal, suspicious or unusual activity  Maintain an appropriate level of competence through ongoing training, making requests for updates or development as required  Ensuring the clients are treated fairly by knowing the customer and giving suitable advice where appropriate , providing an appropriate level of service, communicating clearly and fairly and ensuring complaints are reported 


Qualifications

Desired but not mandatory skills 

Coding skills (PowerShell, C#, Python) to automate tasks and interact with APIs

Automation and Orchestration tools ( Jenkines , Ansible, GIT, TeamCity, Azure Devops )

StoneX Essential Qualifications

Ability to maintain confidentiality and appropriately handle sensitive information with tact and discretion

Sound verbal/written communication abilities

Effective interpersonal skills

Sense of urgency

Honesty, curiosity, and tenacity

Strong work ethic and emphasis on attention to detail

The confidence to fail

Early Careers Requirements

Pursuing a bachelor‚Äôs degree from an accredited university in a relevant program and graduating between December 2023 and August 2024

Proficiency with Microsoft Office suite (preferably Excel)

Must be authorized to work in the US for any employer","As a Graduate Database Administrator at StoneX, your core responsibilities will include managing and maintaining open-source database platforms to ensure peak performance, scalability, and security. You will work closely with DBA and development teams to implement health checks, optimize queries, automate tasks, and troubleshoot performance issues for large-scale databases. Additional duties include supporting on-call rotation, scripting for maintenance and monitoring, adhering to best practices and compliance standards, and proactively identifying areas for performance improvement. Your work will contribute directly to application availability, client service quality, and operational efficiency.","To be eligible, candidates must be pursuing a bachelor’s degree in a relevant field, with graduation expected between December 2023 and August 2024. Strong communication skills, discretion, attention to detail, and a passion for continuous learning are essential. Experience or interest in coding languages such as PowerShell, Python, or C#, and familiarity with automation tools like Jenkins, Ansible, or Azure DevOps is desired but not mandatory. Proficiency in Microsoft Office, particularly Excel, and U.S. work authorization are required. The ideal candidate is curious, adaptable, and eager to contribute in a dynamic, global financial services environment.","{' PowerShell': 'MISC', ' Python': 'MISC', ' C#': 'MISC', ' Microsoft Office': 'MISC', ' Excel': 'MISC'}"
197,University of Wisconsin-Madison,Data Analyst,"Job Summary:

On-farm and applied agricultural field trials are critical to engaging innovative farmers and better understanding the implications for agricultural management and adoption of innovative practices. The Data Specialist will work with UW faculty and Extension educators to strengthen field trial design and provide data analysis support for applied field research projects. This work is intended to assist farmers and industry partners in research-based decision making to improve the economic, environmental and social sustainability of Wisconsin farms. This position will also work closely with faculty to develop and analyze data to support agronomic and nutrient management recommendations.

About Extension:

UW-Madison's Division of Extension serves the people and communities of Wisconsin by addressing local, statewide and national issues, improving lives through research-based education, fostering partnerships and action, and facilitating positive impacts. The Agriculture Institute is one of six Institutes in the Division.

About the Agriculture Institute's Crops and Soils Program:

The Agriculture Institute's Crops and Soils Program works hand-in-hand with row crop, forage, fruit and vegetable producers to implement best practices for every aspect of the growing phase. The Crops and Soils program provides timely resources and information to help Wisconsin crop producers and their agricultural consultants manage crops efficiently and profitably.

About this Position:

The Data Specialist position is designed to work with crop producers and agribusiness professionals statewide to solve production challenges and incorporate new research findings into outreach and educational materials that improve the efficiency and profitability of crop production.

Specific roles of the position will include:

 Consult with colleagues on aspects of project design and data analysis in agricultural field research. Develop systems for efficient data analysis and communication of results to farm and industry partners. Compile and analyze existing datasets in collaboration with UW faculty to communicate findings and make management recommendations. The ideal candidate will have experience with developing and evaluating educational programming and a track record of building positive relationships.

The preferred location for this position is Madison, WI, but is flexible based on programmatic needs, successful candidate's preferences, and availability of suitable space.

The Division of Extension has a deep and profound commitment to diversity, inclusion, and equity, believing that these values are foundational elements to eliminate disparities and expanding access for all. As Extension, we acknowledge the need for strategic and coordinated actions that help us form a more equitable, anti-racist, non-biased, and inclusive organization. (https://blogs.extension.wisc.edu/oaic/call-to-action/) As such, all Extension employees are expected to foster and promote the values of diversity and inclusion.

Responsibilities: Contributes to a research agenda set by a lead researcher by preparing data sets, analyzing them using data science techniques, and presenting the results. May work independently or as part of a team.

30% Prepares data sets for analysis including cleaning/quality assurance, transformations, restructuring, and integration of multiple data sources30% Independently identifies and implements appropriate data science techniques to find data patterns and answer research questions chosen by the lead researcher including data visualization, statistical analysis, machine learning, and data mining10% Organizes and automates project steps for data preparation and analysis10% Composes and assembles reproducible workflows and reports to clearly articulate patterns to researchers and/or administrators10% Documents approaches to address research questions and contributes to the establishment of reproducible research methodologies and analysis workflows10% Communicate plans, activities, and achievements to Program Managers, partners, and relevant stakeholders

Institutional Statement on Diversity:

Diversity is a source of strength, creativity, and innovation for UW-Madison. We value the contributions of each person and respect the profound ways their identity, culture, background, experience, status, abilities, and opinion enrich the university community. We commit ourselves to the pursuit of excellence in teaching, research, outreach, and diversity as inextricably linked goals.

The University of Wisconsin-Madison fulfills its public mission by creating a welcoming and inclusive community for people from every background - people who as students, faculty, and staff serve Wisconsin and the world.

For more information on diversity and inclusion on campus, please visit: Diversity and Inclusion

Education:

Required

Master's Degree in a field related to this position's focus

Preferred

PhD in a field related to this position's focus

Qualifications:

Required:

 Three or more years relevant professional experience; Demonstrated skill with R or comparable statistical software Demonstrated skill in data analysis and interpretation. Demonstrated skills in interpreting, utilizing, and applying evidence-based information and research findings; Demonstrated ability to communicate effectively, both written and verbal, through a variety of technologies; Demonstrated ability to effectively work with people from different cultural backgrounds, including those associated with race, ethnicity, national origin, religion, socioeconomic status, age, gender, disability, sexual orientation, and other aspects of human diversity.

Preferred:

 Ability to conduct linear and non-linear regression analysis Strong interpersonal relationship and problem-solving skills in a team setting Demonstrated experience with building diverse, collaborative partnerships Demonstrated ability to communicate scientific or technical materials in written and verbal forms for a variety of lay and other audiences

Work Type:

Full Time: 100%

This position may require some work to be performed in-person, onsite, at a designated campus work location. Some work may be performed remotely, at an offsite, non-campus work location.

Appointment Type, Duration:

Ongoing/Renewable

Salary:

Minimum $65,000 ANNUAL (12 months)

Depending On Qualifications

Employees in this position can expect to receive benefits such as generous vacation, holidays, and paid time off; competitive insurances and savings accounts; retirement benefits. Benefits information can be found at (https://hr.wisc.edu/benefits/).

Additional Information:

Division of Extension headquarters are located within Madison, WI but the position location is flexible and will be determined based on programmatic needs and successful candidate's preferences and availability of suitable space.

The University of Wisconsin-Madison has a remote work policy that offers the potential for remote or hybrid work. More about that policy within the Division of Extension can be found here: https://kb.wisc.edu/extension/113536.

Please note that successful applicants are responsible for ensuring their eligibility to work in the United States (i.e. a citizen or national of the United States, a lawful permanent resident, a foreign national authorized to work in the United States without need of employer sponsorship) on or before the effective date of appointment.

How to Apply:

We are eager to learn more about how your experience and passion may align with this position. Please submit a cover letter referring to your related work experience and a resume detailing your educational and professional background.

Your cover letter should communicate your interest in the position and how your skillset aligns with the role. The application reviewers will be relying on written application materials to determine who may advance to preliminary interviews.

Contact:

Anne Pfeiffer

anne.pfeiffer@wisc.edu

608-263-1095

Relay Access (WTRS): 7-1-1. See RELAY_SERVICE for further information.

Official Title:

Data Scientist II(RE021)

Department(s):

A47-EXTENSION/ANRCD/AGR/CROPS/CROPS&SOIL

Employment Class:

Academic Staff-Renewable

Job Number:

296309-AS

The University of Wisconsin-Madison is an Equal Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to, including but not limited to, race, color, religion, sex, sexual orientation, gender identity, national origin, age, pregnancy, disability, or status as a protected veteran and other bases as defined by federal regulations and UW System policies. We promote excellence through diversity and encourage all qualified individuals to apply.

If you need to request an accommodation because of a disability, you can find information about how to make a request at the following website: https://employeedisabilities.wisc.edu/disability-accommodation-information-for-applicants/

Employment will require a criminal background check. It will also require you and your references to answer questions regarding sexual violence and sexual harassment.

The University of Wisconsin System will not reveal the identities of applicants who request confidentiality in writing, except that the identity of the successful candidate will be released. See Wis. Stat. sec. 19.36(7).

The Annual Security and Fire Safety Report contains current campus safety and disciplinary policies, crime statistics for the previous 3 calendar years, and on-campus student housing fire safety policies and fire statistics for the previous 3 calendar years. UW-Madison will provide a paper copy upon request; please contact the University of Wisconsin Police Department .","The Data Specialist will collaborate with UW faculty and Extension educators to strengthen the design and implementation of on-farm field trials, ensuring high-quality data analysis and communication of findings to farmers and industry partners. Core duties include preparing and analyzing agricultural datasets using statistical software (such as R), developing efficient workflows, and translating research outcomes into actionable insights that enhance decision-making on Wisconsin farms. The role will involve building systems to compile, clean, and visualize data, performing statistical analyses, and automating key data processes, as well as contributing to reproducible research documentation. The position also requires organizing and sharing results with stakeholders through effective communication, including technical reporting and outreach materials.","Candidates must have a Master’s degree in a relevant field and at least three years of professional experience related to data science or agricultural research. Required skills include proficiency in statistical software (R preferred), data cleaning and transformation, and experience working with diverse communities. Strong verbal and written communication skills, experience with regression analysis, and the ability to communicate scientific information to various audiences are highly valued. A PhD is preferred, as is experience in educational programming, relationship building with stakeholders, and familiarity with agronomic research. The role may be based in Madison, WI or another Wisconsin location, with hybrid or remote flexibility depending on program needs and candidate preferences.",{'R': 'MISC'}
198,Cushman & Wakefield,Data Analyst,"Job Title

Enterprise Data Intern

Job Description Summary

Job Description

Cushman & Wakefield also provides eligible employees with an opportunity to enroll in a variety of benefit programs, generally including health, vision, and dental insurance, flexible spending accounts, health savings accounts, retirement savings plans, life, and disability insurance programs, and paid and unpaid time away from work. In addition to a comprehensive benefits package, Cushman and Wakefield provide eligible employees with competitive pay, which may vary depending on eligibility factors such as geographic location, date of hire, total hours worked, job type, business line, and applicability of collective bargaining agreements.

The compensation that will be offered to the successful candidate will depend on factors such as whether the position is covered by a collective bargaining agreement, the geographic area in which the work will be performed, market pay rates in that area, and the candidate‚Äôs experience and qualifications.

The company will not pay less than minimum wage for this role.

The compensation for the position is: $16.00 - $30.00

Cushman & Wakefield provides equal employment opportunity. Discrimination of any type will not be tolerated. Cushman & Wakefield is an Equal Opportunity / Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability, protected veteran status or any other characteristic protected by state, federal, or local law.

In compliance with the Americans with Disabilities Act Amendments Act (ADAAA), if you have a disability and would like to request an accommodation in order to apply for a position at Cushman & Wakefield, please call the ADA line at 1-888-365-5406 or email HRServices@cushwake.com. Please refer to the job title and job location when you contact us.","As an Enterprise Data Intern at Cushman & Wakefield, you will support the Enterprise Data team in handling, analyzing, and organizing business data across the organization. Your role may include assisting with data quality checks, contributing to data governance and management initiatives, preparing reports and dashboards, and collaborating with cross-functional teams to ensure data consistency and usability. This internship offers hands-on experience with enterprise-scale data systems and the opportunity to contribute to impactful business decisions.","Ideal candidates are currently pursuing a degree in data science, computer science, business analytics, or a related field, and demonstrate strong analytical and organizational skills. Proficiency in Microsoft Excel and familiarity with data visualization or analytics tools (e.g., SQL, Power BI, Tableau) are preferred. Applicants should have a keen attention to detail, good communication abilities, and a strong interest in enterprise data systems and real estate operations. Compensation for this role ranges from $16.00 to $30.00 per hour depending on qualifications and geographic location.","{' Microsoft Excel': 'MISC', ' SQL': 'MISC', ' Power BI': 'MISC', ' Tableau': 'MISC'}"
199,TEKsystems,Data Engineer,"Description 

Candidate Requirements

 Years of Experience Required: 3+ overall years of experience in the field. Degrees or certifications required: No degree is required to be eligible for this role, but it is preferred to have a relevant degree. Disqualifiers: Candidates with a majority of their experience in developer work, has poor communication skills, has not worked in a customer facing support role, or are missing any of the required technologies will not be eligible for the role. Best vs. Average: The ideal resume would contain multiple years of experience with support engineering, troubleshooting, and is well articulated both on paper and in person. Performance Indicators: Performance will be assessed based on quality of work and ticketing metrics. Required Skills‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ With increasingly vast seas of digital information, smart organizations can today do things that were up to now impossible; spot unseen business trends, prevent diseases, make our roads safer and so on. At Version 1 our Mission is to prove IT can make a real difference. We prove this every day and due to continued expansion, we‚Äôre searching for like-minded individuals to help us ‚Äòtake it to the next level‚Äô‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ This is an exciting opportunity for an experienced developer of large scale data solutions. You will join a team delivering a transformative cloud hosted data platform for a key Version 1 customer‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ The ideal candidate will have a proven track record in implementing data ingestion and transformation pipelines for large scale organizations. We are seeking someone with deep technical skills in a variety of technologies to play an important role in developing and delivering early proofs of concept and production implementation.‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ You will gain good experience in building solutions using a variety of open source tools a Microsoft Azure services and a proven track record in delivering high quality work to tight deadlines. Your main responsibilities will be:‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Designing and implementing highly performant data ingestion pipelines from multiple sources using Apache Spark and/or Azure Databricks and/or HDInsights‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Delivering and presenting proofs of concept to of key technology components to project stakeholders.‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Developing scalable and re-usable frameworks for ingesting of geospatial data sets‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Integrating the end to end data piple-line to take data from source systems to target data repositories ensuring the quality and consistency of data is maintained at all times‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Working with event based / streaming technologies to ingest and process data‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Working with other members of the project team to support delivery of additional project components (API interfaces, Search)‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Evaluating the performance and applicability of multiple tools against customer requirements‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Working within an Agile delivery / DevOps methodology to deliver proof of concept and production implementation in iterative sprints.


 Skills 

databricks, azure, spark, designing engineering, data management

 Top Skills Details 

databricks,azure,spark,designing engineering,data management

 Additional Skills & Qualifications 

‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Qualifications‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Strong knowledge of Data Management principles‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience in building ETL / data warehouse transformation processes‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Direct experience of building data pipelines using HDInsights and Apache Spark (preferably Databricks).‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience using geospatial frameworks on Apache Spark and associated design and development patterns‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Microsoft Azure Big Data Architecture certification.‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Hands on experience designing and delivering solutions using the Azure Data Analytics platform (Cortana Intelligence Platform) including Azure Storage, Azure SQL Data Warehouse, Azure Data Lake, Azure Cosmos DB, Azure Stream Analytics‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience with Apache Kafka / Nifi for use with streaming data / event-based data‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience with other Open Source big data products Hadoop (incl. Hive, Pig, Impala)‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience with Open Source non-relational / NoSQL data repositories (incl. MongoDB, Cassandra, Neo4J)‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience working with structured and unstructured data including imaging & geospatial data.‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Experience working in a Dev/Ops environment with tools such as Microsoft Visual Studio Team Services, Chef, Puppet or Terraform


 Experience Level 

Intermediate Level

 About TEKsystems 

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.","The role centers on designing and implementing high-performance data ingestion pipelines using technologies such as Apache Spark, Azure Databricks, and HDInsights. The candidate will deliver proofs of concept and develop scalable frameworks for ingesting both traditional and geospatial datasets. Responsibilities also include end-to-end pipeline integration from source systems to target repositories, performance tuning, and supporting additional project components such as API interfaces. Working in an Agile/DevOps environment, the candidate will be expected to collaborate across teams, develop automation, and maintain data integrity and consistency.","To be considered for this role, candidates should have at least 3+ years of experience in the field, with preference given to those who possess a relevant degree. The ideal candidate will have a proven track record in implementing large-scale data ingestion and transformation pipelines, particularly using tools such as Apache Spark, Databricks, and HDInsights. Hands-on experience with the Azure Data Analytics platform (including Azure Storage, Azure SQL Data Warehouse, Azure Data Lake, Azure Cosmos DB, and Azure Stream Analytics), as well as building ETL/data warehouse transformation processes, is required. Candidates should also have a strong knowledge of data management principles, experience with geospatial frameworks on Apache Spark, and familiarity with both structured and unstructured data, including imaging and geospatial data.",{' Apache Spark': 'MISC'}
200,TEKsystems,Data Engineer,"Description 

Role and Responsibilities:

 Minimum 3+ of experience is required in Technical Support Roles Administration support for SQL databases and/or Azure Cloud-based Must have knowledge of basics of Azure and SQL, Hand-on experience in production support with Database experience Experience supporting or maintaining complex mission critical database solutions, RDMS technologies, and/or SQL language. Excellent understanding of Database concepts and deployments Participate in case triage meetings to share knowledge with other engineers and develop efficient customer solutions. Consistently share best practices with team members and help create a knowledge base article to solve/workaround that issue Manage all customer communication with the appropriate level of etiquette, timeliness, and professionalism, whilst working towards achieving the KPI targets. Experience working in a team environment, managing a diverse workload Ability to work independently, be adaptable to change and varied working hours Ability to take quick decisions, like when to escalate a ticket to next level Strong problem solving and troubleshooting skills, an ability to use various data collection tools and methodologies to analyze problems, determine root cause and develop solutions. Excellent Communication Skills - verbal, listening, and written (including technical writing). Passion for technology, lifelong learning and professional development. Experience in one or more of these areas desirable: - Experience supporting Azure or other cloud-based solutions. - Microsoft certifications in data platform or Azure technologies - Experience troubleshooting Open-Source Databases like MySQL, Postgre SQL, etc., - Basic Networking, Storage and Platform troubleshooting skills.


 Skills 

azure, database administrator, mysql, postgresql, mariadb, technical support, troubleshooting

 Top Skills Details 

azure,database administrator,mysql,postgresql,mariadb,technical support,troubleshooting

 Additional Skills & Qualifications 

Candidate Requirements

 Years of Experience Required: 3+ overall years of experience in the field. Degrees or certifications required: No degree is required to be eligible for this role, but it is preferred to have a relevant degree. Disqualifiers: Candidates with a majority of their experience in developer work, has poor communication skills, has not worked in a customer facing support role, or are missing any of the required technologies will not be eligible for the role. Best vs. Average: The ideal resume would contain multiple years of experience with support engineering, troubleshooting, and is well articulated both on paper and in person. Performance Indicators: Performance will be assessed based on quality of work and ticketing metrics.


 Experience Level 

Intermediate Level

 About TEKsystems 

We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.

The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.","The ideal candidate will have at least 3 years of experience, with strong knowledge in data management principles and hands-on expertise in building ETL and data warehouse transformation processes. Required technical skills include Databricks, Azure Data Services, Apache Spark, HDInsights, and geospatial data frameworks. Preferred qualifications include Azure Big Data Architecture certification, experience with streaming technologies like Apache Kafka or NiFi, and familiarity with NoSQL and open-source big data tools (e.g., Hadoop, MongoDB, Cassandra). Strong communication skills and prior experience in a customer-facing support role are essential.","To be considered for this role, candidates should have at least 3+ years of experience in the field, with preference given to those who possess a relevant degree. The ideal candidate will have a proven track record in implementing large-scale data ingestion and transformation pipelines, particularly using tools such as Apache Spark, Databricks, and HDInsights. Hands-on experience with the Azure Data Analytics platform (including Azure Storage, Azure SQL Data Warehouse, Azure Data Lake, Azure Cosmos DB, and Azure Stream Analytics), as well as building ETL/data warehouse transformation processes, is required. Candidates should also have a strong knowledge of data management principles, experience with geospatial frameworks on Apache Spark, and familiarity with both structured and unstructured data, including imaging and geospatial data.",{' Apache Spark': 'MISC'}
204,Humana,Data Engineer,"Become a part of our caring community and help us put health first

Humana is seeking a HEDIS Data and Reporting Lead to join the National Medicaid Quality team. The HEDIS Data and Reporting Lead reports to the National Medicaid Quality Director and oversees and coordinates all aspects of HEDIS data collection strategy, analytics, and reporting for the Humana Healthy Horizons Medicaid business, and leads the National Medicaid Quality Analytics team.

The HEDIS Data And Reporting Lead‚Äôs Responsibilities Include

Managing a team of Data and Reporting Professionals, BI Engineers, and Data Scientists, all dedicated to Humana‚Äôs Medicaid business at the national level.Overseeing the development and maintenance of BI reporting solutions for topics including but not limited to: HEDIS/Quality measure rate trending and forecasting, pay-for-performance (withhold) program monitoring, Provider HEDIS/Quality measure performance, CAHPS and survey analytics, Health Equity, and other needed Quality reporting.Overseeing the coordination of HEDIS data ingestion activities and driving strategy to optimize HEDIS data ingestion, EHR/HIE interoperability, supplemental data, and record review for the Medicaid line of business.Supporting market level Quality Analysts and Quality teams to ensure all state and NCQA deliverables are met in a timely fashion.Coordinating study designs for pilots and innovations by managing data science personnel within the National Medicaid Quality Analytics team.Supporting Medicaid Business Development efforts by assisting in data parade preparation and response development for all Medicaid RFP activities.

Required Qualifications

Use your skills to make an impact 

Five (5) or more years of technical experience in data reporting.Two (2) or more years of project leadership experience.Experience with HEDIS and Quality data and process, with strong understanding of industry standard reporting requirements, measures, and specifications.Advanced Microsoft Excel skills including ability to link pivots to external data sources, creating pivot tables and summarizing data into reports and dashboards.Advanced Power BI skills including ability to link to external data sources, pass-through queries, data structure and relationship design.Experience working with big and complex data sets within large organizations and/or the analysis of healthcare data.

Preferred Qualifications

Bachelor's degree.Prior people leader experience.Medicaid Quality Experience, preferably in the managed care setting.Advanced Degree in a quantitative discipline, such as Mathematics, Economics, Finance, Statistics, Computer Science, Engineering or related field.Advanced in SQL, SAS and other data systems.Experience with tools such as Tableau and Qlik for creating data visualizations.Prior experience working in a system analytics and/or data warehousing environment.

Additional Information

Workstyle: Home. Home workstyle is defined as remote but will use Humana office space on an as needed basis for collaboration and other face-to-face needs. Travel: up to 10%Typical Work Days/Hours: Monday ‚Äì Friday, 8:00 am ‚Äì 5:00 pm, preferably EST.Direct Reports: 2 direct reports with potential for growth.

Nationwide Remote - This is a remote nationwide position.

WAH Internet Requirements

To ensure Home or Hybrid Home/Office employees‚Äô ability to work effectively, the self-provided internet service of Home or Hybrid Home/Office employees must meet the following criteria:

At minimum, a download speed of 25 Mbps and an upload speed of 10 Mbps is recommended; wireless, wired cable or DSL connection is suggested.Satellite, cellular and microwave connection can be used only if approved by leadership.Employees who live and work from Home in the state of California, Illinois, Montana, or South Dakota will be provided a bi-weekly payment for their internet expense.Humana will provide Home or Hybrid Home/Office employees with telephone equipment appropriate to meet the business requirements for their position/job.Work from a dedicated space lacking ongoing interruptions to protect member PHI / HIPAA information.

Benefits

Humana offers a variety of benefits to promote the best health and well-being of our employees and their families. We design competitive and flexible packages to give our employees a sense of financial security‚Äîboth today and in the future, including:

Health benefits effective day 1Paid time off, holidays, volunteer time and jury duty payRecognition pay401(k) retirement savings plan with employer matchTuition assistanceScholarships for eligible dependentsParental and caregiver leaveEmployee charity matching programNetwork Resource Groups (NRGs)Career development opportunities

HireVue

As part of our hiring process for this opportunity, we will be using an interviewing technology called HireVue to enhance our hiring and decision-making ability. HireVue allows us to quickly connect and gain valuable information from you pertaining to your relevant skills and experience at a time that is best for your schedule.

Scheduled Weekly Hours

40

Pay Range

The compensation range below reflects a good faith estimate of starting base pay for full time (40 hours per week) employment at the time of posting. The pay range may be higher or lower based on geographic location and individual pay will vary based on demonstrated job related skills, knowledge, experience, education, certifications, etc.

$95,300 - $131,200 per year

This job is eligible for a bonus incentive plan. This incentive opportunity is based upon company and/or individual performance.

Description Of Benefits

Humana, Inc. and its affiliated subsidiaries (collectively, ‚ÄúHumana‚Äù) offers competitive benefits that support whole-person well-being. Associate benefits are designed to encourage personal wellness and smart healthcare decisions for you and your family while also knowing your life extends outside of work. Among our benefits, Humana provides medical, dental and vision benefits, 401(k) retirement savings plan, time off (including paid time off, company and personal holidays, volunteer time off, paid parental and caregiver leave), short-term and long-term disability, life insurance and many other opportunities.

About Us

Humana Inc. (NYSE: HUM) is committed to putting health first ‚Äì for our teammates, our customers and our company. Through our Humana insurance services and CenterWell healthcare services, we make it easier for the millions of people we serve to achieve their best health ‚Äì delivering the care and service they need, when they need it. These efforts are leading to a better quality of life for people with Medicare, Medicaid, families, individuals, military service personnel, and communities at large.

Equal Opportunity Employer

It is the policy of ‚ÄØHumana not to discriminate against any employee or applicant for employment because of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or because he or she is a protected veteran. It is also the policy of ‚ÄØHumana‚ÄØto take affirmative action to employ and to advance in employment, all persons regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, genetic information, disability or protected veteran status, and to base all employment decisions only on valid job requirements. This policy shall apply to all employment actions, including but not limited to recruitment, hiring, upgrading, promotion, transfer, demotion, layoff, recall, termination, rates of pay or other forms of compensation and selection for training, including apprenticeship, at all levels of employment.","The HEDIS Data and Reporting Lead at Humana will guide the strategic development and execution of all HEDIS-related data processes and reporting initiatives within the Medicaid business line. This role includes leading a team of data professionals, BI engineers, and data scientists, while managing data ingestion strategy, interoperability with EHR/HIE systems, and enhancing supplemental data collection. Additionally, the position is responsible for creating and maintaining BI solutions for performance metrics such as HEDIS measures, CAHPS, health equity analytics, and pay-for-performance programs. The role involves cross-functional collaboration with state markets, supporting business development through RFP analytics, and ensuring timely delivery of all required reports and quality deliverables.","Candidates should have at least five years of experience in technical data reporting, with two or more years in a leadership role. Strong knowledge of HEDIS measures, quality reporting, and industry standard specifications is essential. Proficiency in Microsoft Excel and Power BI is required, along with experience working with large datasets in healthcare. Preferred qualifications include a bachelor’s degree, prior Medicaid experience, advanced SQL or SAS capabilities, and familiarity with tools such as Tableau or Qlik. Candidates with a demonstrated ability to manage cross-functional teams and drive strategy in data environments will be best suited for this remote position.","{' HEDIS': 'MISC', ' Microsoft Excel': 'MISC', ' Power BI': 'MISC', ' SQL': 'MISC', ' SAS': 'MISC'}"
206,Nippon Life Benefits,Data Analyst,"Company DescriptionWe have been focused on delivering innovative group benefits for over 30 years. Fully-customizable programs give companies the peace of mind that comes from top quality protection at prices that help protect the bottom line. Our full product line includes Medical, RX, Wellness, Dental, Life, Disability, and Vision.
Nippon Life Benefits is the U.S. subsidiary of Japan-based Nippon Life Insurance Company, one of the world‚Äôs largest mutual life insurance companies with over $520 billion in assets.
We are proud of our A- (Excellent) rating from AM Best.
Role DescriptionThis is a full-time role for a Medical Data Analyst / Programmer with a hybrid work schedule. As a Medical Data Analyst / Programmer, you will contribute to the success of the Underwriting Department through the implementation of new technology for Underwriting. Responsibilities include maintaining and improving the Proposal System (Stepwise/Gateway) used to illustrate our proposals and generate renewals. You will also be responsible for maintaining database warehouse. Serve as a technical resource to the department in matters related to Underwriting, risk selection, etc.
Nature and Scope of ResponsibilitiesDevelop, maintain, and support existing Microsoft VBA, MS Word Document customization, OptumStepwise rating system, and analyze and convert business requirements as needed.Create SQL stored procedures/queries, enhance existing data objects and actively mitigate potential data credibility issues. Responsible for working with outside vendor (OPTUM) on new business rating system and any issues related to the system.Translate algorithms from filed rate manuals into Underwriting tools and Optum StepWise rating system to meet business, end user, and regulatory requirements.Load monthly claims and premium data for Underwriting to complete monthly renewals.Address any system related issues that are brought to attention.Ensure compliance with State Laws with regard to rating and update our benefit summaries and SBCs.Provide reports on status of new business activity, renewals, sales and other ad hoc reports as deemed necessary.Work with Trustmark on data transfers, special projects, reporting, etc.Perform other tasks as requested.
QualificationsBachelor's degree in Computer Science, Data Science, Information Systems, or a related field5+ years experience with data analysis, programming, and/or statistical modelingProficiency in SQL, VBA and programming languages such as Python or RStrong analytical and problem-solving skillsKnowledge of Group insurance with an emphasis on Underwriting preferredAbility to work independently and collaboratively in a team environment Excellent communication and presentation skillsThis position may be remote or hybrid (reliably commute to office in Midtown Manhattan 2 to 3 days a week preferred)
Pay: $70,000.00 - $95,000.00 per year(inclusive of a merit-based bonus, dependent on years of experience, level of education obtained, location as well as applicable skillset) and an excellent benefits package, including a comprehensive benefit plan, generous employer match for 401k and employer paid Money Purchase retirement plan.
This position outline reflects the general responsibilities and level of work being performed by employees in this position. It is not intended to be an exhaustive list of all duties, responsibilities and qualifications of employees assigned to this position. Nothing in this position outline restricts management's rights to assign or reassign duties and responsibilities to this job at any time.","As a Medical Data Analyst / Programmer at Nippon Life Benefits, you will play a vital role within the Underwriting Department, focusing on the development, maintenance, and enhancement of underwriting systems and tools. Your primary responsibilities include maintaining the Proposal System (Optum StepWise/Gateway), customizing MS Word documents via VBA, and managing the data warehouse. You will design SQL queries, troubleshoot system issues, and translate insurance rate manuals into tools that ensure compliance with regulatory standards. Additional tasks include monthly claims and premium data processing, collaborating with vendors like Optum and Trustmark, and delivering performance reports and ad hoc analyses.","Candidates should hold a Bachelor's degree in Computer Science, Data Science, Information Systems, or a related field, with at least 5 years of relevant experience in data analysis, programming, or statistical modeling. Proficiency in SQL and VBA is required, and experience with Python or R is highly desirable. Familiarity with group insurance and underwriting processes is preferred. Strong analytical thinking, effective communication skills, and the ability to work both independently and within a team environment are essential. The position offers flexibility for remote work but prefers candidates able to commute to Midtown Manhattan 2–3 days a week.","{' SQL': 'MISC', ' VBA': 'MISC', ' Python': 'MISC', ' R': 'MISC'}"
207,Cogent Communications,Data Engineer,"Company: 

Cogent Communications is a global, Tier 1 facilities-based ISP, consistently ranked as one of the top five networks in the world and is publicly traded on the NASDAQ Stock Market under the ticker symbol CCOI. Cogent specializes in providing businesses with high speed Internet access and Ethernet transport services. Cogent's facilities-based, all-optical IP network backbone provides IP services globally. Since its inception, Cogent has unleashed the benefits of IP technology, building one of the largest and highest capacity IP networks in the world. This network enables Cogent to offer large bandwidth connections at highly competitive prices. Cogent also offers superior customer support by virtue of its end-to-end control of service delivery and network monitoring. A competitive base salary and a full benefits package including; Health, Dental, Vision, Paid Time Off ( PTO), Short- and Long-Term Disability, Life Insurance, Holidays, Parental Leave, 401 ( k) plan with employer match, stock options, and an Employee Assistance Program. Most benefits take effect within 30 days of employment, and some require a waiting period.

 Job Summary: 

The SQL Server DBA will be responsible for the implementation, configuration, maintenance, performance and support of critical SQL Server DB systems, to ensure the availability and consistent performance of our corporate and business applications. This is a ‚Äúhands-on‚Äù position requiring solid technical skills, as well as excellent interpersonal and communication skills.

The successful candidate will be responsible for the development and support of different versions of SQL server and other database technologies like MySQL, Oracle, etc., ensuring their optimal functioning ( security, health, performance, etc.).

The successful candidate must be capable of working independently or collaboratively with other team members.

 Essential Duties and Responsibilities: 

Manage SQL Server databases and other RDBMS through different product lifecycle from development to mission-critical production systemsInstall, Configure and maintain database servers and processes, including monitoring of system health and performance, to ensure high levels of performance, availability, and securitySupport 24x7 operational database support including periodic on-call rotationConduct diagnostic tests and evaluate performance metrics on the databasesMonitor the databases to ensure system health, functionality and remediate problems/issues in a timely mannerMigrate/convert databases from Oracle 11g, 12c and 19c to MS SQL serverExecute & maintain SQL scripts and utility jobs for MS SQL database maintenanceImplement & manage MS SQL database backups and restore, clustering, always on, failover and load balancing technologiesPerform DB refreshes from Prod to lower environmentsMonitor database status, logs, space utilization, extents, locks, blockings and deadlocks and clearing them accordinglyImplement and support MS SQL ( Active/Passive & Active/Active), Multi Node Clustering for four node clustersApply data modeling techniques to ensure that development and implementation support efforts meet integration and performance expectationsIndependently analyze, solve, and correct issues in real time, providing end-to-end problem resolutionRefine and automate regular processes, track issues, and document changesAssist developers and application owners with complex query tuning and optimizationPerform scheduled maintenance and support release deployment activities after hoursShare domain and technical expertise, providing technical mentorship and cross-training to other peers and team membersPerform all other DB related tasks and activities as assigned
 Qualifications: 

3+ years of experience supporting MS SQL Server DatabasesExperience with Performance Tuning and Optimization ( PTO), using native monitoring and troubleshooting toolsExperience with backups, restores and recovery modelsKnowledge of High Availability ( HA) and Disaster Recovery ( DR) options for SQL ServerExperience working with Windows server, including Active DirectoryExperience creating and deploying SSRS, SSIS and SSAS packagesAbility to organize and plan work independentlyAbility to multi-task and context-switch effectively between different activities and teamsExperience with MySQL, Oracle and MariaDB running on LinuxExperience with VMware, NetApp and SSRS a plusAbility to write, keep and maintain SOP, documentation, etc

 Other qualification that would be nice to have include: 

Oracle DB knowledge in a Unix environmentKnowledge with Rubrik MS SQL backup technologyKnowledge with SQL Monitor MS SQL performance monitoring toolKnowledge with Power Script/DBAToolsExcellent written and verbal communicationFlexible, team player, ‚Äúget-it-done‚Äù personality

 Physical Requirements: 

Remains in a sitting/stationary position continually or almost continually during the work dayOperates a computer and performs desk-based computer tasks continually; frequently viewing a computer screenPrefer the ability to lift, carry, push, pull objects and/or equipment that weighs up to 50 pounds on rare occasions

 COVID-19 Policy: 

Cogent has adopted a mandatory vaccination and booster policy which requires all U.S. employees to be fully vaccinated with one booster against COVID-19. Prior to beginning employment, new employees must provide proof of vaccination or apply for and receive an accommodation to be exempt from the policy.

By submitting an application or resume for this position, I understand that is an in-office position and agree to abide Cogent‚Äôs mandatory vaccination policy.

To apply for the MS SQL, Database Administrator position, please submit your resume and cover letter to careers@cogentco.com .

 Cogent Communications is an Equal Opportunity Employer.","As a SQL Server Database Administrator at Cogent Communications, you will be responsible for implementing, configuring, maintaining, and supporting mission-critical database systems to ensure high performance, availability, and security. Your duties include managing SQL Server databases through all lifecycle stages, performing routine health checks, optimizing performance, ensuring data backups and recovery, and managing high availability and disaster recovery strategies. You will assist in database migrations, support SSRS/SSIS/SSAS deployments, monitor system logs, perform production refreshes, and provide after-hours support as needed. Collaboration with developers, cross-functional teams, and mentorship to peers is also a key part of this role.","The ideal candidate should have at least 3 years of experience with Microsoft SQL Server database administration, including hands-on experience in performance tuning, optimization, backup and recovery models, and high availability solutions. Familiarity with Active Directory, SSRS, SSIS, SSAS, and experience working with Windows Server is required. Experience with additional database platforms such as Oracle, MySQL, and MariaDB in Linux environments, as well as tools like VMware, NetApp, Rubrik, SQL Monitor, and PowerShell scripting, is highly desirable. Strong communication skills, a detail-oriented approach, and the ability to multitask in a team-oriented environment are essential. Candidates must comply with Cogent’s in-office and COVID-19 vaccination policies.",{' Microsoft SQL Server': 'MISC'}
208,Advantage Technical,Data Analyst,"We are the movers of the world and the makers of the future. We get up every day, roll up our sleeves and build a better world -- together. At OEM, we‚Äôre all a part of something bigger than ourselves. What will you make today? In our plants around the world, we‚Äôre constantly developing new technologies and processes to further increase our efficiency. You'll get the satisfaction of making great products people use and love.

Location: Onsite. Corktown, Detroit

Position: Data Coordinator

Primary Responsibilities: 

Day to day administrative support of commercial and government fleet field salespeople. Provide administrative support to the Operation's Manager in the management of the organization's central meetings & events to include, but not limited to meeting notice and materials generation; event planning support in areas such as lodging, transportation, food/ beverage; and meeting facilitation. Assist in the completion of the monthly performance metric analysis and reporting cycle. Lead the planning, creation, and facilitation of the monthly business review meeting. Administrative support of the operation's internal control program, completion of the annual MCRP, publication of EDMS materials, and creation of work instructions/ processes. Administrative support and coordination of the organization's vehicle demo program to include inventory tracking, CVMS information management, vehicle order administration, and assistance in Fleetio transfer. Support the operation‚Äôs budget process to include Ariba PO & Invoice reconciliation. Serve as the central point of contact for the communication and distribution of materials. Maintenance of organization chart, distribution lists, & other personnel tracking documents. 


Skills Required:

System InterfacesAccess & user knowledge in the following systems: Salesforce, Ariba, FMS, CVMS, CONCEPS SharePoint site development, administration & permissions management. EDMS book administration and document publication and retention. Excel Spreadsheet (to include: Power Query, Pivot Analysis/ Charting/ Macros) Power Point, Word, PDF Edit, Outlook, Webex Salesforce report configuration and export


Experience Required:

Meeting & Event Planning from an external hospitality perspective. System Interfaces Access & user knowledge in the following systems: Salesforce, Ariba, FMS, CVMS, CONCEPS SharePoint site development, administration & permissions management. EDMS book administration and document publication and retention. Excel Spreadsheet (to include: Power Query, Pivot Analysis/ Charting/ Macros) Power Point, Word, PDF Edit, Outlook, Webex Salesforce report configuration and export


Education Required:

Bachelors


Would you be a good fit for this exciting career advancement opportunity? Click 'Apply Now' to submit your application and a recruiter will be connecting with you soon!

After you have applied, download our Staffmark Group WorkNOW App to receive real-time job offers and apply for additional opportunities. You can download it from the App Store or get it on Google Play. 

About Advantage Technical

With company roots going back over 30 years, Advantage Technical is an engineering and information technology services company and a national leader in the provision of technical resources today. These services include Staff Augmentation, Direct Placement, Project Resourcing and Outsourcing ‚Äì delivered from 40 key market locations, by over 3500 specialized contractors, to over 500 clients across North America. Advantage Technical is a Best of Staffing Diamond Award winner for both Clients and Talent. For more information about the industries and services offered by Advantage Technical, please visit AdvantageTechnical.com.

Advantage Technical is committed to providing equal employment opportunity for all persons regardless of race, color, religion (including religious dress and grooming practices), sex, sexual orientation, gender, gender identity, gender expression, age, marital status, national origin, ancestry, citizenship status, pregnancy, medical condition, genetic information, mental and physical disability, political affiliation, union membership, status as a parent, military or veteran status or other non-merit based factors. We will provide reasonable accommodations throughout the application, interviewing and employment process. If you require a reasonable accommodation, contact us. Advantage Technical is an E-Verify employer. This policy is applicable to all phases of the employment relationship, including hiring, transfers, promotions, training, terminations, working conditions, compensation, benefits, and other terms and conditions of employment.

All employees are directed to familiarize themselves with this policy and to act in accordance with it. All decisions with respect to employment matters and other phases of employer-temporary employee relationships will be in keeping with this policy and in accordance with all applicable laws and regulations.","As a Data Coordinator at OEM's Corktown, Detroit location, you will play a vital role in supporting commercial and government fleet field sales operations. Your primary duties will include day-to-day administrative assistance to the field sales team and Operations Manager, coordination of key internal meetings and events, and planning and facilitating the monthly business review meetings. You'll manage central data and documents through platforms like SharePoint and EDMS, maintain organizational charts, support vehicle demo programs, assist with budget tracking and invoice reconciliation via Ariba, and handle the publication and distribution of materials across the organization.","To qualify for this role, you must hold a bachelor's degree and have a strong background in system interface and administrative coordination. You should have hands-on experience using systems such as Salesforce, Ariba, FMS, CVMS, CONCEPS, and be proficient with SharePoint site development and EDMS document management. Proficiency in Microsoft Excel (Power Query, PivotTables, macros), PowerPoint, Word, and tools like Webex is essential. Experience in external meeting and event planning is also required, along with strong communication and organizational skills to serve as the central contact point for internal operations.","{' SharePoint': 'MISC', ' EDMS': 'MISC', ' Microsoft Excel': 'MISC', 'Power Query': 'MISC', ' PowerPoint': 'MISC', ' Word': 'MISC', ' Webex': 'MISC'}"
209,Frost,Data Analyst,"Job Description

It‚Äôs about insights that are out of sight.

Does diving into a 1,000-piece puzzle and placing all the pieces excite you? Do you want the autonomy to improve processes and find solutions? Would you consider excel to be your second language? If so, being a Data Analyst ‚Äì Financial with Frost could be for you.

At Frost, it‚Äôs about more than a job. It‚Äôs about having a flourishing career where you can thrive, both in and out of work. At Frost, we‚Äôre committed to fostering an environment that reflects our values and encourages team members to be the best they can be. In joining our adaptable, integrity-driven team, you‚Äôll become part of Frost‚Äôs over 150-year legacy of providing unparalleled banking services.

Who You Are

As a Data Analyst ‚Äì Financial with Frost, you are our researcher, always searching for new data to analyze. In this role, you will analyze complex financial data to support key business initiatives. You will use your effective communication skills and analytical mindset to present your findings and make recommendations to upper management. More than that, this role is about constant improvement and doing so with our signature all-win approach in mind.

What You‚Äôll Do

Interpret data using sound statistical methods while considering how the data can tell a story for an audience with a different area of expertiseExtract relevant data from enterprise data storage systems by using Structured Query Language (SQL) and other available tools and techniquesProvide expertise to create reporting and analysis that improves and automates the financial data collection processWork closely with end users to determine business rules and requirements that must be followed during report creation and validate that extracted information is accurateProvide guidance to less experienced Data Analysts Always act using Integrity, Caring, and Excellence to achieve all-win outcomes

What You‚Äôll Need

Bachelor's degree in Business, Data Analytics, Statistics or MIS disciplineAdvanced knowledge and skill in SQL tools and techniquesAdvanced experience with report writing systems and the ability to create programs from scratchStrong analytical thinking and problem-solving skillsExcellent written and verbal communication skillsStrong knowledge and understanding of financial and accounting conceptsExperience working in cross-functional teamsProficiency in Microsoft computer applications

Additional Preferred Skills

2+ years of data analyst experienceExperience in the banking industryExperience with workflow process management or process improvementCompetency with advanced analytics or data science

Frost Benefits

At Frost, we care about your health, your family, and your future and strive to have our benefits reflect that. This includes:

Medical, dental, vision, long-term, and life insurance401(k) matchingGenerous holiday and paid time off scheduleTuition reimbursementExtensive health and wellness programs, including our Employee Assistance ProgramReferral bonus program + more!

Since 1868, Frost has dedicated their expertise to provide exceptional banking, investment, and insurance services to businesses and individuals throughout Texas. Frost is one of the 50 largest U.S. banks by asset size and is a leader is banking customer satisfaction. At Frost, it‚Äôs about being part of something bigger. If this sounds like you, we encourage you to apply and see what‚Äôs possible at Frost.","As a Data Analyst – Financial at Frost, you will play a crucial role in uncovering insights through data interpretation and storytelling. You’ll be responsible for analyzing complex financial data and extracting meaningful insights using SQL and other tools. You’ll collaborate with cross-functional teams to improve financial data processes, develop automated reporting solutions, and ensure data accuracy. Your findings and recommendations will support strategic decision-making and drive key business initiatives. You'll also work closely with end users to define reporting requirements and may provide mentorship to junior analysts, always guided by Frost’s core values of Integrity, Caring, and Excellence.","To be successful in this role, a Bachelor’s degree in Business, Data Analytics, Statistics, or MIS is required, along with advanced SQL skills and experience creating custom reports from scratch. You should have strong analytical, problem-solving, and communication skills, with a solid understanding of financial and accounting concepts. Proficiency in Microsoft Office applications and the ability to work effectively in cross-functional teams are essential. Preferred qualifications include 2+ years of data analyst experience, especially within the banking industry, as well as familiarity with workflow process management, process improvement, and data science or advanced analytics.","{' SQL': 'MISC', ' Microsoft Office': 'MISC'}"
210,Complete Staffing Solutions,Data Analyst,"The Data Analyst will be responsible for the creation and delivery of analytics, insights, and reporting in support of our internal teams as well as our financial advisors and institutions.The ideal employee in this role will assist in recommendations by synthesizing data from multiple sources and developing reports needed to drive business insights and processes.The primary focus for this role will be to strategize with the team to identify solutions with a focus on process efficiency, operational automation, and improvement of the advisor experience.The ideal candidate will have experience with data analysis, finding patterns, insights, and anomalies, and be able to communicate those findings in concise, clear and easy to understand formats that our teams can use to formulate action plans.

The post Data Analyst appeared first on Complete Staffing Solutions.","The Data Analyst will play a critical role in generating actionable insights and reports that support internal teams, financial advisors, and partner institutions. Key duties include synthesizing data from multiple sources, identifying trends, anomalies, and key performance indicators, and presenting findings in a clear and actionable format. This role will also focus on enhancing business processes through strategic data analysis, recommending improvements that streamline operations, and driving automation efforts to improve the advisor and customer experience.","The ideal candidate will have a proven background in data analysis, strong experience in interpreting large datasets, and an ability to deliver insights that lead to operational improvements. Proficiency in data visualization tools, SQL, and Microsoft Excel is essential, with additional experience in automation or process improvement initiatives being a strong advantage. Excellent communication skills are critical, as findings must be shared clearly with both technical and non-technical stakeholders to influence data-driven decisions.","{' SQL': 'MISC', ' Microsoft Excel': 'MISC'}"
211,McKesson,Data Engineer,"McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve ‚Äì we care. What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow‚Äôs health today, we want to hear from you.

Every single McKesson employee contributes to our mission‚Äîby joining McKesson you act as a catalyst in a chain of events that helps millions of people all over the globe. Talented, compassionate people are the future of our company‚Äîand of healthcare. At McKesson, you‚Äôll collaborate on the products and solutions that help us carry out our mission to improve lives and advance healthcare. Working here is your opportunity to shape an industry that‚Äôs vital to us all.

Wherever you contribute here at McKesson, you will have the ability to make a real impact in the lives of others.

Position Description

As a Data Engineer at McKesson, you will play a crucial role in designing, constructing, and maintaining data architectures, databases, and large-scale processing systems. You will collaborate closely with cross-functional teams to develop efficient data pipelines and contribute to our organization's data modernization efforts. This position requires a deep understanding of data engineering principles, cloud technologies, and a commitment to delivering high-quality solutions.

Key Accountabilities:

Design and implement scalable and efficient data pipelines to support various data-driven initiatives.Collaborate with cross-functional teams to understand data requirements and contribute to the development of data architectures.Work on data integration projects, ensuring seamless and optimized data flow between systems.Implement best practices for data engineering, ensuring data quality, reliability, and performance.Contribute to data modernization efforts by leveraging cloud solutions and optimizing data processing workflows.Demonstrate technical leadership by staying abreast of emerging data engineering technologies and implementing industry best practices.Effectively communicate technical concepts to both technical and non-technical stakeholders.Collaborate with the team to address unique challenges in talent attraction, development, and retention.


Minimum Requirements:

4+ years of experience of relevant experience

Critical Skills:

4+ years of experience of professional experience in IT data and analytics fieldProven experience as a Data Engineer or in a similar role.Deep technical expertise in building and optimizing data pipelines and large-scale processing systems.Experience working with cloud solutions and contributing to data modernization efforts.Experience working with Databricks, Snowflake, Azure SQL, Azure ADF, Big Query, GCP, Power BI/Tableau, Azure ADFStrong programming skills (e.g., Python, Java, Scala) for data manipulation and transformation.Excellent understanding of data engineering principles, data architecture, and database management.


Additional Experience:

Strong problem-solving skills and attention to detail.Excellent communication skills, with the ability to convey technical concepts to both technical and non-technical stakeholders.Knowledge of the healthcare, distribution, or software industries is a plus.Strong technical aptitude and experience with a wide variety of technologiesAbility to rapidly learn and if required evaluate a new tool or technology.Strong verbal & written communication skillsDemonstrated technical experience.Be an innovative thinker.Must have a strong customer and quality focus.


Education:

Bachelor's degree in a related field (e.g., Computer Science, Information Technology, Data Science) or equivalent experience


Work Environment/Physical Demands:

General Office Requirements

At McKesson, we care about the well-being of the patients and communities we serve, and that starts with caring for our people. That‚Äôs why we have a Total Rewards package that includes comprehensive benefits to support physical, mental, and financial well-being. Our Total Rewards offerings serve the different needs of our diverse employee population and ensure they are the healthiest versions of themselves. For more information regarding benefits at McKesson, please click here.

As part of Total Rewards, we are proud to offer a competitive compensation package at McKesson. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered.

Our Base Pay Range for this position

$112,200 - $187,000

McKesson is an Equal Opportunity/Affirmative Action employer. 

All qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.Qualified applicants will not be disqualified from consideration for employment based upon criminal history.

McKesson is committed to being an Equal Employment Opportunity Employer and offers opportunities to all job seekers including job seekers with disabilities. If you need a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to Disability_Accommodation@McKesson.com. Resumes or CVs submitted to this email box will not be accepted.

Current employees must apply through the internal career site.

Join us at McKesson!","As a Data Engineer at McKesson, your core responsibility is to design, build, and optimize scalable data pipelines and data architectures to support analytics and business insights across the organization. You will collaborate closely with cross-functional teams to define data requirements and implement cloud-based data solutions using tools such as Azure Data Factory, Databricks, Snowflake, and BigQuery. You’ll also be involved in data modernization efforts, ensuring best practices for data integrity, reliability, and performance. This position also demands technical leadership through the adoption of emerging technologies and effective communication of complex data engineering concepts to diverse stakeholders.","The ideal candidate will have a minimum of 4 years of experience in the IT data and analytics field, with proven expertise in building and maintaining data pipelines, working with large-scale processing systems, and cloud technologies like Azure and GCP. Proficiency in programming languages such as Python, Java, or Scala, along with knowledge of modern data warehousing and BI tools (e.g., Power BI, Tableau), is essential. A bachelor’s degree in Computer Science, IT, or a related field is required. Strong problem-solving skills, attention to detail, and the ability to communicate technical ideas clearly to both technical and non-technical audiences are critical to success in this role. Healthcare or distribution industry experience is a plus.","{' Azure': 'MISC', ' GCP': 'MISC', ' Python': 'MISC', ' Java': 'MISC', ' Scala': 'MISC', ' Power BI': 'MISC'}"
212,Kavaliro,Data Engineer,"Kavaliro is seeking a Database Developer to support a client in Chantilly, VA. 
 
 The Database Developer will Design, develop, implement and maintain NoSQL databases; utilize expert knowledge of SQL Language to perform database tasks. Translate business requirements into databases, data warehouses, and data streams; create procedures and procedures to ensure data accuracy and accessibility and process, clean, integrate the data. 
 
 Required Experience:

Demonstrated experience with designing cloud-native architecturesusing cloud services such as AWS, Google, IBM, and OracleDemonstrated experience designing and operating big data systemsDemonstrated experience building and optimizing performance of large scale graph databases (tens of billions of edges) usingDynamoDB or new enhanced capabilitiesDemonstrated experience developing and operating graph traversal capabilities using data graphing tool traversal capabilities built uponApache Gremlin or new enhanced capabilitiesDemonstrated experience developing and operating NoSQL solutions to complex big data applicationsDemonstrated experience in data modeling for performance, partition sharding, record/event aggregation workflows, streamprocessing, and metrics gatheringDemonstrated experience designing and operating large-scale serverless geospatial indexes built with GeoMESADemonstrated experience with partition and sort key design and implementation to ensure consistent performanceDemonstrated experience with aggregation operations to de-duplicate records on continuous data feedsDemonstrated subject matter expertise experience with relational databases to noSQLDemonstrated experience building and operating high performance data processing pipelines using Lambda, Step Functions and PySparkDemonstrated experience building high quality User Interface/User experiences with the React framework and webGLDemonstrated experience designing and operating large scale graph databases using Apache CassandraDemonstrated experience performing in-depth technical analysis of large-scale graph databases to develop implementation strategies for search optimizationsDemonstrated experience developing technical capabilities for processing, persistence and search of datasets that are collected or maintained using standards common in the Sponsor's communityDemonstrated experience facilitating engineering discussions across teams representing multiple stakeholders to develop and execute implementation strategies that meet mission needsDemonstrated experience developing Machine LearningOperations (MLOps) pipelines for large scale applicationDemonstrated experience maintaining configuration of software using configuration management resources such as GitHubDemonstrated experience designing, building and operating big data systems, such as persistence, partitioning, indexing, at scale of trillions of records/eventsDemonstrated experience with Niagara Files (NiFi) applications or new enhanced capabilitiesDemonstrated experience developing and operating Kubernetes infrastructureDemonstrated experience supporting engineering efforts that will contribute to delivery of capabilities such as datasets and functionality such as communications, geospatial workflowsDemonstrated experience implementing DevSecOps and agile development in production environmentsDemonstrated experience with agile software development and testingDemonstrated experience with federal security, regulatory and compliance requirements and security accreditation package developmentDemonstrated experience with data security and governance using centralized security controls like LDAP, encrypting the data, and auditing access to the dataDemonstrated experience with specialized technologies that are optimized for the particular use of the data, such as relational databases, a NoSQL database (Cassandra), or object storageDemonstrated experience with Apache, TINKERPOP, GREMLIN and/or JANUSGRAPH to design, develop, implement and maintain systemDemonstrated knowledge of Graph Database to design, develop, implement and maintain systemDemonstrated experience with C or C++ to write interfacesDemonstrated experience using centralized security controls likeLDAP, encrypting data, and auditing access to dataDemonstrated experience with: Postgres, MariaDB, ELK, Minio, AWS S3, Neo4j, MongoDB, noSQLDemonstrated experience with: Languages: Python (pypi libraries)Demonstrated experience with: Operating Systems: Centos7, RockyLinux8Demonstrated experience with: Orchestration: Kubernetes, Docker, Docker-Compose, Docker- SwarmDemonstrated experience with: Development Tools: vscode, gitlab, jupyterhub/notebooks, MATLABDemonstrated experience with Environments: large collaboration and development environmentsDemonstrated experience with Data types: Unstructured, structured, or semi-structured data, including: CSV, JSON, JSONL, AVRO, Protocol Buffers, Parquet, etc
 Desired Experience: 

Demonstrated experience with designing cloud-nativearchitectures using Sponsors cloud servicesDemonstrated experience designing and operating bigdata systems within the Sponsors policy and regulatory environmentDemonstrated experience developing and operatinggraph traversal capabilities using the Sponsors data graphing tooltraversal capabilities built upon Apache GremlinDemonstrated experience building and operating highperformance data processing pipelines using Lambda, Step Functionsand PySpark on the Sponsors infrastructure with EMRDemonstrated experience working with the Sponsor'senterprise services used for Data Management, including the enterprisecatalog service (and associated APIs), and Policy Decision Points(PDPs).Demonstrated experience developing MachineLearning Operations (MLOps) pipelines for large scale application inthe Sponsor's environmentDemonstrated experience and understanding of IT Service Management and common SLA measurementsDemonstrated experience presenting solutions,requirements, and presentations to diverse audiences.Demonstrated experience working with containerorchestration technologies such as AWS ECS, AWS Fargate, andKubernetes or other enhanced capabilities availableDemonstrated experience in managing largeoperational cloud environments spanning multiple tenants using Multi-Account management, AWS Well Architected Best Practices, andAWS Organization Units/Service Control Policies (OU/SCP)
 Location:Chantilly, VAThis position is onsite and there is no remote availability
 Clearance Requirement: Candidates must have an active TS/SCI security clearance with a Full Scope Polygraph 
 Kavaliro provides Equal Employment Opportunities to all employees and applicants. All qualified applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws. Kavaliro is committed to the full inclusion of all qualified individuals. In keeping with our commitment, Kavaliro will take the steps to assure that people with disabilities are provided reasonable accommodations. Accordingly, if reasonable accommodation is required to fully participate in the job application or interview process, to perform the essential functions of the position, and/or to receive all other benefits and privileges of employment, please respond to this posting to connect with a company representative.","The Database Developer will be responsible for designing, developing, and maintaining NoSQL databases and translating complex business requirements into scalable database solutions. The role involves managing data accuracy, accessibility, integration, and performance of large-scale systems including graph databases using tools like Apache Gremlin, DynamoDB, Cassandra, and NiFi. Key duties also include developing data pipelines, stream processing, geospatial indexing, and MLOps pipelines. The candidate will be expected to support engineering initiatives across diverse platforms and technologies while ensuring adherence to DevSecOps and federal compliance standards.","The ideal candidate will possess 3+ years of experience in database development with demonstrated expertise in cloud-native architecture using platforms like AWS, Google Cloud, and Oracle. Strong hands-on experience with NoSQL technologies, graph database traversal (Apache Gremlin), container orchestration (Kubernetes, Docker), and various scripting/programming languages including Python and C/C++ is required. Proficiency in data security, configuration management (GitHub), and agile development is also essential. A Top Secret/SCI clearance with Full Scope Polygraph is required for this onsite position in Chantilly, VA.","{' Oracle': 'ORG', ' NoSQL': 'MISC', 'Apache Gremlin': 'MISC', ' Python': 'MISC', ' C/C++': 'MISC'}"
213,"FinQuery, Formerly LeaseQuery",Data Engineer,"We are actively seeking a Financial Data Engineer (Python/C#) for a full-time, direct-hire opportunity with our client. Our client is an investment management company based in New York with 50-100 employees, known for its innovative approach to investment management and strong commitment to technological advancement within the financial sector.
Job Description- Develop and maintain software applications using Python and/ C#, focusing on data modeling, analysis, and reporting within the financial domain.- Collaborate with business users and technical teams to design and implement solutions that enhance data-driven decision-making processes.- Utilize SQL for database management, data manipulation, and complex query development, ensuring data integrity and efficiency.- Engage in the full software development lifecycle, from requirements analysis through to testing and deployment, within an Agile framework.
Minimum Qualifications- 2+ years of experience in financial industry.
Preferred Qualifications- B.S. or B.A degree or relevant degree.- Experience in data modeling, SQL, and experience with Bloomberg or similar financial data platforms.- Knowledge of fixed income, accounting principles, and exposure to financial market data.
Note- The position is on-site in the Financial District, Manhattan, NYC.- Must be authorized to work in the United States.- Compensation is based on experience and includes a comprehensive benefits package. - If you have less experience than specified or have higher salary requirements, we still would love to chat with you.","The Financial Data Engineer will develop and maintain robust software applications using Python and/or C# with a strong emphasis on data modeling, analysis, and financial reporting. The role involves close collaboration with both business stakeholders and technical teams to create data-driven solutions that optimize investment decision-making. This includes extensive use of SQL for database management and complex query development, maintaining data integrity, and performance. The engineer will participate in the full software development lifecycle within an Agile environment, ensuring that solutions meet both functional and performance standards.","The ideal candidate will have at least 2 years of experience within the financial industry, a strong command of Python and/or C#, and a solid understanding of SQL. A bachelor’s degree in Computer Science, Finance, or a related field is preferred. Additional assets include familiarity with data modeling, Bloomberg or similar financial data platforms, knowledge of fixed income, and an understanding of accounting principles and financial market data. Candidates must be authorized to work in the United States and willing to work onsite in Manhattan’s Financial District. Compensation is commensurate with experience and includes a competitive benefits package.","{' Python': 'MISC', ' C#': 'MISC', ' SQL': 'MISC'}"
215,AdTheorent,Data Analyst,"The AdTheorent Data and Analytics (D&A) team is responsible for organizing, analyzing, and deriving insights and actionable recommendations from digital campaign data. The team then communicates these findings to internal and external stakeholders via concise, impactful deliverables. The ideal candidate for a role with the team thoroughly understands the digital landscape, has a strong eye for detail, can tell a clear story with data, and thrives in a collaborative, team-oriented environment.Responsibilities:Self-sufficiently manage reporting responsibilities and analytical projects with guidance from senior team membersProvide proactive analytics support to other departments, including working with other teams to execute against analytics and reporting frameworks tailored to meet the needs of each campaignWork with complex data structures and produce easy-to-understand, error-free, and timely deliverables that analyze user behavior online to provide actionable insights that address client business objectivesDeliver campaign performance results and presentations to internal stakeholders 

Requirements

Bachelor's degree in quantitative studies preferred. The equivalent combination of education, training, and work experience may be suitableUp to 1 year of relevant experience working in a quantitative business environmentBasic understanding of digital advertising landscapeStrong project management skills: ability to concurrently manage multiple deliverables and meet deadlinesExcellent written and verbal communication skills: ability to tell a compelling story with dataStrong attention to detailIntermediate Excel and PowerPoint skills (required)Experience with Relational Databases (e.g. - SQL Server) and Business Intelligence tools (e.g. - Tableau) (preferred) 

Benefits

We offer full health coverage, generous PTO, an award-winning office culture! We are an Equal Opportunity Employer and seek to foster community, inclusion and diversity within the organization. We encourage all qualified candidates, regardless of racial, religious, sexual or gender identity, to apply.","The Data and Analytics team member at AdTheorent will independently manage reporting responsibilities and analytical projects, while collaborating with senior team members for guidance. This role requires partnering with cross-functional teams to implement analytics and reporting frameworks tailored to specific campaign goals. The analyst will handle complex data structures and transform them into clear, error-free, and actionable insights that inform user behavior analysis and address client business objectives. Additionally, the role involves delivering campaign performance reports and presentations to internal stakeholders in a compelling, data-driven format.","The ideal candidate will hold a bachelor’s degree in a quantitative field or possess equivalent education and experience, with up to one year of relevant experience in a data-centric business environment. A basic understanding of the digital advertising ecosystem is essential, along with strong project management and multitasking skills. Proficiency in Excel and PowerPoint is required, and familiarity with SQL Server and business intelligence tools such as Tableau is preferred. Excellent verbal and written communication skills, along with the ability to interpret data to tell a compelling story, are critical to success in this role.","{' Excel': 'MISC', ' PowerPoint': 'MISC', ' SQL Server': 'MISC'}"
216,Coders Data,Data Analyst,"The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.  ResponsibilitiesUnderstand the day-to-day issues that our business faces, which can be better understood with data Compile and analyze data related to business' issues Develop clear visualizations to convey complicated data in a straightforward fashion
QualificationsBachelor's or Master's degree in Statistics or Applied Mathematics or equivalent experience 1 - 2 years' Data Analysis experience Proficient in SQL","The ideal candidate will leverage their passion for big data and analytics to deliver actionable insights across a variety of business functions. This includes performing both recurring and ad hoc analyses to support decision-making. Key responsibilities involve understanding business challenges that can be addressed with data, compiling and analyzing relevant datasets, and developing clear and effective visualizations to present complex information in an easily digestible manner.","Candidates should hold a Bachelor's or Master's degree in Statistics, Applied Mathematics, or a related field, with 1–2 years of hands-on experience in data analysis. Proficiency in SQL is required, as it will be used extensively for data querying and manipulation. Strong analytical thinking and the ability to translate data into meaningful business insights are essential for success in this role.",{' SQL': 'MISC'}
217,Community Foundation for a greater Richmond,Data Analyst,"VISION: A thriving region where all individuals and families have the opportunity to succeed.The mission of the Community Foundation is to make the Richmond region a better place through bold solutions and inspired philanthropy. Today, we manage more than 1,400 charitable funds with assets exceeding several billion dollars and growing. In 2022, we deployed more than 6,000 grants totaling over $85 million. The Foundation also supports the activities of 9 other charitable foundations and organizations that have chosen to fulfill their charitable legacy in partnership with us. Together we do more good! As a part of the Community Foundation, you have a chance to use your skills and experience to create positive, long-lasting change for our region; while maintaining a healthy balance between personal and professional endeavors. We offer competitive benefits, flexibility in schedule and partial telework, half-days on Fridays, a collaborative culture, and mission-centered work. To learn more about our vision and mission, please visit cfrichmond.org/About/Our-Story. TITLE: Data Analyst REPORTS TO: Chief Information OfficerCLASSIFICATION: Full-time, exempt; salaried-benefits eligible; 37.5 hours per week POSITION DESCRIPTION: At the Community Foundation for a greater Richmond, data is key to everything we do. As a Data Analyst, you will leverage analytic and technical skills to help us innovate, build and maintain well-managed solutions and capabilities for our customer focused businesses. On any given day you will be challenged with regional data, customer data and operational data. Creating indicators, metrics and reports that provided data and information to our business leaders is a critical part of this role. 
Our Data Analyst will be responsible for designing, developing and managing the data architecture, infrastructure and tools necessary for collecting, storing, processing and analyzing data. The primary focus is to create data sets and reporting that enable the organization to derive valuable insights from their data. PRIMARY DUTIES AND RESPONSIBILITIES:Design and implement scalable and robust data solutions to support the organization's data processing needs.Manage and optimize databases for performance and reliability, ensuring data integrity and security.Create and maintain data models to facilitate efficient data storage, retrieval, and analysis.Evaluate and recommend appropriate tools and technologies for data processing and analysis, keeping up to date with industry trends.Fully participate in the Agile Scrum process.Other duties as assigned.
ESSENTIAL SKILLS AND EXPERIENCE:  Collecting, managing, and analyzing dataMining data and conducting basic analyses, using business intelligence and visualization tools like MS Power BI, MS Excel, and TableauManaging data (organizing, cleaning, and storing them in relational databases)Interpreting data, analyzing results using basic statistical techniquesDeveloping and implementing data analyses, data collection systems and other strategies that optimize efficiency and quality.Acquiring data from primary or secondary data sources and maintaining databasesAcquiring, analyzing, and presenting data to support decision makingInspecting, cleaning, transforming, and modeling data to support decision-makingData entry, governance, and validationProblem-solving skills: Strong analytical and problem-solving skills, ability to troubleshoot and debug complex software issues.Communication skills: Strong verbal and written communication skills, ability to explain technical concepts to non-technical stakeholders.Technical curiosity: A desire to stay up to date with new technologies and industry trends, ability to quickly learn new tools and technologies as needed.Collaborating with other team members to design and develop new capabilities to support business needs.

PREFERRED QUALIFICATIONS:Education: A bachelor's or master's degree in computer science, software engineering, technology, engineering, mathematics, or a related fieldExperience in data analyticsExperience coding in Salesforce, Python, Microsoft SQLExperience working within process management and improvement methodologies ‚Äì Agile, Lean etc.Experience working with Microsoft Azure data environments.Experience delivering Data Governance and Data Quality Management concepts and practices within the financial services industry. If you are interested, please visit https://www.cfrichmond.org/discover/cf/join-us and submit your cover letter including salary requirements and resume to https://www.cfengage.org/jobapplication. No phone calls or agencies, please. Don‚Äôt meet every single requirement? We are dedicated to building a diverse, inclusive, and authentic workplace, so if you‚Äôre excited about this role, but your experience doesn‚Äôt align perfectly with every qualification, we encourage you to apply anyway. You may be the right candidate for this or other roles.","Reporting to the Chief Information Officer, this full-time, exempt role blends technical expertise with a commitment to positive community impact. The Data Analyst will lead the design, development, and management of data systems and analytics solutions that support data-informed decision-making across the organization.","The Data Analyst will be responsible for designing and implementing scalable, secure, and efficient data solutions to meet the organization’s growing information needs. Key duties include managing relational databases, creating data models, optimizing performance, and delivering accurate and actionable business intelligence reports. The role also involves evaluating and recommending new technologies, participating in Agile development processes, and collaborating with cross-functional teams to support strategic initiatives. Additional responsibilities may be assigned as needed to support the organization's goals.",{' Agile': 'MISC'}
218,Randstad Digital Americas,Data Engineer,"Job Summary

We are currently looking for a talented, experienced Software Quality Engineering Manager with leadership/communication skills and a passion for testing software for our growing organization. The Manager of Test Engineering Data is responsible for working with leadership and staff to build up a core software QA practice, including resources, infrastructure, and processes (automated and manual) that align with organizational goals around the quality of technology delivery and meeting defined metrics and outcomes. The Manager Test Engineering - Data works collaboratively with all levels of leadership and departments to develop, build, and maintain testing strategy, activities, processes, and infrastructure for their assigned vertical. They will work closely with teams to engage and manage test deliverables, allocate resources, and ensure the quality of testing for the client platform they are aligned with.

location: CHICAGO, Illinois

job type: Permanent

salary: $80,000 - 100,000 per year

work hours: 8am to 4pm

education: Bachelors

Responsibilities

 Lead multiple applications and multiple testing teams  Participate in scope definition, requirements analysis, functional and technical design, application build, product configuration, unit testing, and production deployment  Provide technical expertise and ownership in the diagnosis and resolution of issues, including the determination and provision of workaround solution or escalation to service owners  Work with the Development team, QA and DevOps engineers and Product owners in both agile and waterfall methodologies  Document and interact with business and technology stakeholders / team members as necessary  Provide testing strategy and leadership including the implementation of automated testing frameworks in Data and Analytics vertical on Azure DevOps  Execution of Test Plans across Microsoft SQL Server, Tableau, SSRS, SSIS along with API QA testing to verify functionality and find defects  Supervise growing QA team on testing practices to ensure rapid and accurate completion of assigned tasks  Define & Execute the Integration/E2E strategy required at the Product Teams  Write and refine new and existing test cases  Review and thoroughly understand functional and technical requirements for BI products  Define and implement metrics and reporting at all phases of SDLC to track quality of software product delivery  Drive bug prioritization and work cross-functionally with Product Owner, Director of Business Intelligence and business owners  Partner with technical team to bring releases to life and ensure they meet our standards  Collaborate closely with key stakeholders to explain and verify defects  Support the recruitment activities to hire right Test Engineers for various Product Teams  Coach and develop the Test Engineers on the Product Teams  Other duties as assigned 

Qualifications

Experience level: ManagerMinimum 3 years of experienceEducation: Bachelors (required)

Skills

Manager

Equal Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.

At Randstad Digital, we welcome people of all abilities and want to ensure that our hiring and interview process meets the needs of all applicants. If you require a reasonable accommodation to make your application or interview experience a great one, please contact HRsupport@randstadusa.com.

Pay offered to a successful candidate will be based on several factors including the candidate's education, work experience, work location, specific job duties, certifications, etc. In addition, Randstad Digital offers a comprehensive benefits package, including health, an incentive and recognition program, and 401K contribution (all benefits are based on eligibility).

Applications accepted on ongoing basis until filled.","The Manager of Test Engineering – Data will lead testing initiatives across various BI technologies including Microsoft SQL Server, SSIS, SSRS, Tableau, and APIs. This includes designing and executing test strategies, leading and mentoring test engineers, implementing automation frameworks, and driving QA best practices. The role involves close collaboration with development, DevOps, and product stakeholders using both Agile and Waterfall methodologies, and includes the definition of quality metrics, test case documentation, and bug management.","Candidates must have a Bachelor’s degree and a minimum of 3 years of experience in a QA management role. Strong expertise in QA strategy, test automation (especially within Microsoft technologies and Azure DevOps), and managing QA resources is essential. Ideal candidates will demonstrate proficiency in BI tools and data testing, possess excellent leadership and communication skills, and have experience recruiting and mentoring QA teams. A background in full SDLC testing and cross-functional collaboration is critical for success in this role.",{' Azure DevOps': 'MISC'}
219,CGI,Data Engineer,"Position Description

CGI is one of the top 5 largest global IT companies spread across 40 countries with endless opportunities to expand and grow. As a CGI Federal Member, you have the opportunity to be a shareholder at CGI and join a family of 90,000 members strong.

CGI Federal is hiring a Data Engineer SME (Data Collection Engines) to work with a skilled and motivated team of professionals on a high-visibility Department of Homeland Security (DHS) Cybersecurity and Infrastructure Security Agency (CISA) cyber security program. You will support a dynamic, fast-paced project focused on improving the cyber security posture of civilian government agencies through the implementation and enhancement of a cybersecurity platform, providing integration services, and developing, securing and maintaining cybersecurity dashboards. You will work closely with a variety of agency stakeholders, supporting their mission, priorities, organization and unique challenges. You will also support the development of additional cyber security offerings focused on next generation security solutions and technologies.

The successful candidate for this position is a motivated individual, a self-starter who works effectively in a dynamic environment. This is a great opportunity with room to grow both on the program and within CGI Federal!

This position is located in our Fairfax, VA office; however, a hybrid working model is acceptable.

You will be required to be in our Fairfax, VA office two days per week.

Your future duties and responsibilities

 Develop scripts using Python, Java or Scala to extract data from published vendor APIs to be consumed from upstream processes Understand data lakehouse technologies like Iceberg, Databricks, Redshift Spectrum, Athena and Snowflake Build secure containerized images that can run extraction code as a microservice Integrate solutions using an event driven architecture leveraging AWS GovCloud technologies Provide detailed specifications for proposed solutions including materials, effort, and time necessary Perform performance analysis to identify bottle necks in processes and recommend improvements Assist Solution Architects to refine and improve extraction processes Perform root cause analysis and remediation of production errors Other duties as assigned based on competencies and personal goals

Required Qualifications To Be Successful In This Role

 Due to the nature of the contract requirements, US citizenship and successful passing of CGI background check is required prior to beginning work. In addition, candidates must have the ability to obtain and maintain a DHS CISA EOD/Public Trust clearance Bachelor's degree in Computer Science or data related field required and 8+ years experience Experience developing applications/utilities using Python, Java, or Scala leveraging tools like Presto, AWS Athena, Spark or AWS Glue Design and develop utilities to transform, enhance, and clean-up data in preparation for loading to target data-lake such a Redshift, Iceberg or Elasticsearch Design and develop stored procedures for data validation Parse disparate data sources including XLS, XML, JSON and CSV files and load/output to similar formats Build logic to clean-up data, ensure compliance to defined data-dictionary Research on published APIs for identified tools with an intent to extract the data using right APIs and access points Test and debug custom data extraction utilities and validate the data-feed requirements that are part of the data-pipe line Update and maintain the data extraction utilities to comply with the changes in data sources Prior experience in information technology, contracting or other related fields Experience with Agile development concepts or an interest to learn Experience in cybersecurity Experience with testing/or requirements development An aspiration to be a perpetual learner is highly desirable Experience with project coordination and administration Experience with Jira and/or Confluence Experience on complex work assignments in matrixed organizations Exposure to or general knowledge of CISA‚Äôs Continuous Diagnostics and Mitigation Program (CDM)

CGI is required by law in some jurisdictions to include a reasonable estimate of the compensation range for this role. The determination of this range includes various factors not limited to skill set, level, experience, relevant training, and license and certifications. To support the ability to reward for merit-based performance, CGI typically does not hire individuals at or near the top of the range for their role. Compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range for this role in the U.S. is $108,600.00 - $235,200.00.

#CGIFederalJob

#DHSCareers

Together, as owners, let‚Äôs turn meaningful insights into action.

Life at CGI is rooted in ownership, teamwork, respect and belonging. Here, you‚Äôll reach your full potential because‚Ä¶

You are invited to be an owner from day 1 as we work together to bring our Dream to life. That‚Äôs why we call ourselves CGI Partners rather than employees. We benefit from our collective success and actively shape our company‚Äôs strategy and direction.

Your work creates value. You‚Äôll develop innovative solutions and build relationships with teammates and clients while accessing global capabilities to scale your ideas, embrace new opportunities, and benefit from expansive industry and technology expertise.

You‚Äôll shape your career by joining a company built to grow and last. You‚Äôll be supported by leaders who care about your health and well-being and provide you with opportunities to deepen your skills and broaden your horizons.

Come join our team‚Äîone of the largest IT and business consulting services firms in the world.

Qualified applicants will receive consideration for employment without regard to their race, ethnicity, ancestry, color, sex, religion, creed, age, national origin, citizenship status, disability, medical condition, military and veteran status, marital status, sexual orientation or perceived sexual orientation, gender, gender identity, and gender expression, familial status, political affiliation, genetic information, or any other legally protected status or characteristics.

CGI provides reasonable accommodations to qualified individuals with disabilities. If you need an accommodation to apply for a job in the U.S., please email the CGI U.S. Employment Compliance mailbox at US_Employment_Compliance@cgi.com. You will need to reference the requisition number of the position in which you are interested. Your message will be routed to the appropriate recruiter who will assist you. Please note, this email address is only to be used for those individuals who need an accommodation to apply for a job. Emails for any other reason or those that do not include a requisition number will not be returned.

We make it easy to translate military experience and skills! Click here to be directed to our site that is dedicated to veterans and transitioning service members.

All CGI offers of employment in the U.S. are contingent upon the ability to successfully complete a background investigation. Background investigation components can vary dependent upon specific assignment and/or level of US government security clearance held.

CGI will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with CGI‚Äôs legal duty to furnish information.","The selected candidate will build and maintain scalable, secure, and efficient data extraction and processing solutions using languages like Python, Java, or Scala. Responsibilities include developing microservices for data collection, working with AWS GovCloud, containerizing applications, and implementing data pipelines for lakehouse solutions like Databricks, Redshift Spectrum, and Iceberg. This role also involves analyzing performance, debugging production issues, and contributing to innovative cybersecurity offerings.","To be considered for the Data Engineer SME position at CGI Federal, candidates must possess a minimum of eight years of experience in software or data engineering, complemented by a bachelor’s degree in Computer Science, Data Science, or a related field. A strong foundation in programming languages such as Python, Java, or Scala is essential, along with hands-on experience using tools like Presto, AWS Athena, Spark, and AWS Glue. Candidates should be well-versed in designing and developing data pipelines, working with large-scale data lake and lakehouse architectures including Redshift, Elasticsearch, and Iceberg. Familiarity with parsing various data formats such as JSON, CSV, XML, and XLS, as well as integrating APIs, is required. Experience with Agile development methodologies, cloud-native architectures, containerization technologies (such as Docker or Kubernetes), and cloud platforms (especially AWS GovCloud) is highly desirable. Additionally, applicants must be U.S. citizens and able to obtain and maintain a DHS CISA EOD/Public Trust clearance. Strong communication, analytical, and problem-solving skills are also critical for success in this role.","{' Python': 'MISC', ' Java': 'MISC', ' Scala': 'MISC', ' AWS Glue': 'MISC', ' Agile': 'MISC', ' Docker': 'MISC', ' Kubernetes': 'MISC', ' AWS GovCloud': 'MISC'}"
220,CareSource,Data Engineer,"This is Data Engineering with Purpose! Bring your strong ETL and architecture skills to our state-of-the-art Databricks platform and join us as we change lives- together! This role focuses upon clinical subjects within the health insurance industry: member conditions, social determinants of health, clinical programming, and population health. You will be hands-on in transforming and delivering datasets that impact the lives of millions of members within a dynamic, growing organization!

Job Summary

The Data Solutions Engineer II is responsible for bringing strong knowledge of Data Warehousing (including ETL, development, testing, ad-hoc reporting, and business analysis) to the Finance function and participating in the full life cycle of data and analytic solutions, broadly from requirements through ETL/ELT, production, consumption and ad-hoc reporting.

Essential Functions

Develop end-to-end data warehouse / data mart solutions, utilizing Databricks and Microsoft technologies. Patterns include traditional dimensional modeling (Kimball), and schema-less (big data) models.Develop data modeling expertise on one or more insurance-specific data / workflows, such as claims, care management (CM), utilization management (UM), eligibility, and population healthPartner with Data Solutions Analysts, and line-of-business stakeholders in product ideation, requirements gathering, data reviews, ongoing data quality, and troubleshootingDevelop or support reports, dashboards, and ad-hoc analysis supporting business consumersTest, debug, and performance tune data pipelines and end-user queriesMaintain the highest level of data security and confidentiality, conforming to all HIPAA and contract requirementsPerform any other job duties as requested

Education And Experience

Bachelor's degree in computer science, engineering, mathematics, a related field, or equivalent combination of education and experience is requiredA minimum of four (4) years‚Äô data engineering-level SQL experience (including data modeling, profiling and cleansing, and building complex data sets) is requiredA minimum of two (2) years‚Äô experience building enterprise data solutions (data warehouses and data marts) is requiredA minimum of two (2) years‚Äô experience building customer facing data solutions (PowerBI, Tableau, Oracle, advanced Excel, etc.) is requiredA minimum of two (2) years‚Äô experience in healthcare data is preferred

Competencies, Knowledge And Skills

Advanced SQL skills, including the ability to develop upon and maintain systems utilizing contemporary data warehousing patterns including ETL / ELT, fact and dimension modeling, and deploying analytic resources via staging tiers and consumption layersProficient working with and warehousing data from multiple sources, such as operational data stores (ODS), flat file, EDI/HL7, API, etc.Proficiency with the Microsoft data ecosystem (SSRS, SSIS, PowerBI)Experience with Azure Databricks and SparkSQL, or similar data lake platforms (Azure Data Lake, Snowflake, Hadoop, etc.)Working knowledge of Python, including Python-specific data modeling skill supporting data transformation and data scienceKnowledge of common healthcare data domains and processes (patient registry, billing, diagnosis, procedure codes)Preferred knowledge of healthcare insurance-specific domains, such as claims (medical and pharmacy), health information exchange (HIE), utilization management (UM), demographicsProficient with the Microsoft 365 suite, including extensive use of Teams, SharePoint, and ExcelGood written and verbal communication skills

Licensure And Certification

Relevant Microsoft certifications (SQL, PowerBI, Azure) is preferredDatabricks certification and/or badging is preferred

Working Conditions

General office environment; may be required to sit or stand for extended periods of time

Compensation Range

$69,400.00 - $111,000.00 CareSource takes into consideration a combination of a candidate‚Äôs education, training, and experience as well as the position‚Äôs scope and complexity, the discretion and latitude required for the role, and other external and internal data when establishing a salary level. We are highly invested in every employee‚Äôs total well-being and offer a substantial and comprehensive total rewards package.

Compensation Type

Salary","As a Data Solutions Engineer II, you will be instrumental in delivering impactful data solutions within the healthcare insurance sector. This role emphasizes hands-on development with modern platforms like Databricks and Microsoft technologies, creating end-to-end data warehouse and data mart solutions. You will be responsible for transforming complex data into meaningful insights by developing ETL/ELT pipelines, data models (Kimball and schema-less), and robust analytic assets such as dashboards and reports. This position demands strong collaboration with business analysts and stakeholders to support clinical and financial data workflows, ensuring the highest standards of data quality, security, and compliance with HIPAA guidelines.","The ideal candidate holds a bachelor’s degree in computer science or a related field, with at least 4 years of experience in SQL-based data engineering, and a minimum of 2 years building both enterprise and customer-facing data solutions. Proficiency in SQL, data warehousing patterns, Microsoft data stack (SSIS, SSRS, Power BI), Databricks, and Python is essential. Experience with healthcare datasets—such as claims, care management, and population health—is highly valued. Familiarity with data integration from APIs, flat files, and EDI/HL7 formats, along with strong communication skills, is expected. Certifications in Microsoft technologies and Databricks are preferred.","{' SQL': 'MISC', 'SSIS': 'MISC', ' SSRS': 'MISC', ' Power BI': 'MISC', ' Databricks': 'MISC', ' Python': 'MISC', ' EDI/HL7': 'MISC'}"
221,Silicon Valley Bank,Data Analyst,"Overview

Together, Silicon Valley Bank and First Citizens offer you the strength and stability of a diversified financial institution with a 125-year tradition of service and the personalized approach of a nimble financial partner.

First Citizens Bank helps personal, business, commercial and wealth clients build financial strength that lasts. Headquartered in Raleigh, N.C., First Citizens has built a unique legacy of strength, stability and long-term thinking that has spanned generations. First Citizens offers an array of general banking services including a network of more than 550 branches in 23 states and commercial banking expertise delivering best-in-class lending, leasing, and other financial services coast to coast. Parent company First Citizens BancShares, Inc. (NASDAQ: FCNCA) is a top 20 U.S. financial institution with more than $200 billion in assets.

Silicon Valley Bank is focused on building deep and authentic relationships with founders, investors, and ecosystem partners to improve their probability of success. This specific role would help entrepreneurs of early and mid-stage startups with a mix of banking services, advice and valuable introductions.

SVB a Division of First Citizens Marketing Technology Team is looking to hire, an enthusiastic person who is excited about technology and data. We‚Äôre looking for you to join our growth marketing organization to enable world class customer journeys, ensure MarTech Stack data integrity and enable marketing ROI insights. In this role, you will be a critical member of the Marketing Technology Team and support the analytics team.

As a Marketing Technology Analyst focused on data, you will be primarily working on:

Data Evaluation and Cataloging - Investigation, exploration, interrogation and ensuring the integrity of system data flow, coupled with the describing, and cataloging of those findings.Data Facilitation - Consultatively assisting our internal business and technical peers by contributing to evaluation and feasibility of initiatives with a focus on the data and governance perspectives.Data Assets Management ‚Äì Understanding, supporting the MarTech/ Data Teams by curating the data and information currently and potentially available to SVB, as well as sharing your understanding on the strengths, restrictions, and limitations of each.

Responsibilities

Support the improvement of availability and trustworthiness of dataServe as a binding and bridging agent between business innovators, data producers, data engineers, data scientists, and other knowledge workers across various parts of the organizationAssist in conceptualizing and ongoing administration of an enterprise data governance frameworkMonitoring data quality process, identifying data quality issue patterns, applying remediation plans, implementation of data controls, and manage data quality remediation strategies.Support data sourcing by interviewing to prepare specifications, gathering information to facilitate negotiations, preparing technical documents, and ensuring universal understanding of the needEngage with stakeholders across the organization to understand processes that generate, transform, and distribute dataLearning the process of our internal constituents, to facilitate anticipating value-add and innovation opportunities.Create standards, policies, and processes regarding data quality assurance and managementRecommend and implement data process improvements for Marketing and Business partnersEnforce the data privacy and regulatory requirements as governed by SVB‚Äôs Privacy Team

The base pay for this position is relative to your experience but the range is generally $113,455 ‚Äì $196,655 per year. This position is eligible for variable compensation, which may be in the form of incentive, bonus, or commission pay. First Citizens offers a competitive, comprehensive benefits program which you can review here: https://jobs.firstcitizens.com/benefits.

Qualifications

3-5 years' experience in data storage, data extraction, data governance. Alternatively, High School or GED with 7-9 years of experience in data storage, data extraction, data governance.

Background & Experience Preferred

Effective communicator, stakeholder management, great collaborator, technical writing skillsSystems experience: CRM, Marketing automation, Customer data platforms (CDP)Experience or familiarity with Agile Scrum MethodologyRoll up your sleeves and can-do attitude is a must

Education

Bachelor‚Äôs degree in business, computer science or related experience","The Data Solutions Engineer II is responsible for bringing strong knowledge of Data Warehousing (including ETL, development, testing, ad-hoc reporting, and business analysis) to the Finance function and participating in the full life cycle of data and analytic solutions, broadly from requirements through ETL/ELT, production, consumption and ad-hoc reporting.","A minimum of four years of experience in SQL for data engineering purposes—such as modeling, profiling, cleansing, and building complex datasets—is required, along with at least two years of experience developing enterprise data solutions like data warehouses and data marts. Candidates must also have a minimum of two years of experience creating customer-facing data solutions using tools like Power BI, Tableau, or Oracle. Experience working with healthcare data is preferred. Proficiency in advanced SQL, data warehousing practices (ETL/ELT), and tools within the Microsoft data ecosystem (SSRS, SSIS, Power BI) is essential. Additional expertise in Azure Databricks, SparkSQL, and Python for data transformation or data science workflows is highly valued. Familiarity with healthcare domains—such as claims, utilization management, and health information exchanges—as well as Microsoft 365 productivity tools, is beneficial. Preferred certifications include Microsoft credentials in SQL, Power BI, or Azure, and Databricks certification or badging.","{' SQL': 'MISC', ' Azure Databricks': 'MISC', ' SparkSQL': 'MISC', ' Python': 'MISC', ' Microsoft 365': 'MISC', ' Power BI': 'MISC', ' Azure': 'MISC'}"
222,Qumulo,Data Engineer,"About The Company

Qumulo is the unstructured data platform to store and manage exabyte-scale data anywhere ‚Äì at the edge, in the core data center and in the cloud. With unstructured data growing in more locations faster than ever before, enterprises today need a way to store, manage, and curate data simply and efficiently in any location, on any platform. This is precisely what Qumulo was founded to accomplish.

At Qumulo, we are building an open and collaborative culture where people can do their best work with customers as our magnetic field. We act as owners, we share by default, we are data driven and experimental and as an inclusive workplace, we encourage and celebrate multiple points of view. As part of our culture we believe diversity drives innovation.

About The Position

Engineers working on core services build the modern distributed storage engine that powers our on-premises and cloud products along with the various services that help customers store, access, and protect their data. The software stack includes a distributed and fault-tolerant block storage layer, a transactional file system, and multiple access protocols and replication/backup features. If you're excited about working on industry-leading data storage software that scales to multiple petabytes with sub-millisecond access latencies, and allows customers to run all their unstructured data workflows on one platform, we want to talk to you!

Software Engineers at Qumulo work alongside people who crave collaborative coding environments. It's a community where individual engineers have a voice, and teams have the autonomy to drive their own progress.

Responsibilities

Contribute to feature development and testing using languages like C and RustParticipate in team SDLC processes like stand-ups/reviews/pair programming/etc. and improve them as appropriateOwn, define and implement customer-facing features and internal improvementsHelp debug and fix test failures and product issues

Qualifications

Experience programming in a compiled language like C/C++, Rust, C#, Java or GoFirm grasp of computer science fundamentals (algorithms, data structures, concurrent programming, operating systems concepts)Work collaboratively with a team on shared work using strong written and oral communication skillsPrevious experience with public cloud storage APIs, block or file storage systems, Linux tooling, kernel interfaces, performance tuning, and/or GDB debugging would be a plus2+ years of proven ability providing production software level design, coding and testingBS in Computer Science or equivalent experience

Key Benefits

The annual pay range for the role is USD $140,000.00 - $190,000.00. Individual pay depends on various factors, such as role level, relevant experience and skills, and location. Pay ranges are reviewed and typically updated each year. Offers are made within the pay range applicable at the time. U.S. based employees have access to healthcare benefits, short-term and long-term disability coverage, basic life insurance, wellbeing benefits, flexible time off, and paid holidays, among others.

Excellent healthcare coverageParental leave401K investment planUnlimited paid time off, strongly encouraged to take at least 3 weeks per year

Other Details

Qumulo is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, gender, religion, sex, sexual orientation, age, disability, military status, or national origin or any other characteristic protected under federal, state, or applicable local law.

Please note that employment at Qumulo is contingent upon completion of a satisfactory background check.

For more information on our Applicant and Employee Privacy Notice please click on the link below:

https://qumulo.com/applicant-employee-privacy-notice","In this role, the Marketing Technology Analyst will be responsible for evaluating and cataloging data, ensuring data integrity, and supporting data-driven initiatives across the organization. The analyst will serve as a liaison between business units, data engineers, and knowledge workers to facilitate smooth data flow and usage. Key duties include managing data assets, supporting enterprise data governance frameworks, monitoring and resolving data quality issues, and enforcing data privacy policies. The analyst will engage with stakeholders to understand data generation processes, recommend improvements, and document technical specifications. Additionally, the role involves creating and maintaining data standards and processes to enhance marketing performance, improve decision-making, and drive innovation across marketing and business teams.","The ideal candidate will have a bachelor’s degree in business, computer science, or a related field, along with 3–5 years of experience in data storage, extraction, and governance. Alternatively, candidates with a high school diploma or GED and 7–9 years of relevant experience will also be considered. Preferred qualifications include strong communication and stakeholder management skills, experience with CRM systems, marketing automation platforms, and customer data platforms (CDPs). Familiarity with Agile Scrum methodology and the ability to contribute to technical writing, policy development, and cross-functional collaboration are also valuable. A proactive attitude, technical acumen, and the ability to work hands-on in a dynamic environment are essential.","{' GED': 'MISC', ' Agile Scrum': 'MISC'}"
224,Wells Fargo,Data Analyst,"At Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do and who embrace diversity, equity and inclusion in a workplace where everyone feels valued and inspired. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.

The Strategy, Digital and Innovation (SDI) team forges the strategic direction of Wells Fargo, it provides and manages our digital foundation and common capabilities, and transforms our business models to meet evolving customer needs and grow the company. The investments we are making will help the company create innovative digital banking experiences, and make it easier for customers to achieve their financial goals.

About This Role

Wells Fargo is seeking a Lead Digital Product Manager for our Enterprise Payments team. Delivering convenient, secure, and fast payments capabilities to our customers is core to what we do for our consumer customers and corporate clients. We have significant capabilities across our consumer and wholesale businesses and working across our businesses as one Wells Fargo is critical for our success.

In This Role, You Will

Lead the development and execution of complex payments data business plans, programs and initiatives which have impact across the enterprise with broad impactAct as key participant in large-scale planningReview and analyze complex payments data strategy for product/functionality/experience areaInfluence payments strategy for the business line requiring in-depth evaluation of multiple factors including intangibles or unprecedented factorsMake decisions in payments strategy for product/functionality/experience area requiring strong understanding of the business, policies, procedures and/or compliance requirementsLead a broad team of payments professionals to meet deliverables and drive new initiativesStrategically collaborate and consult with peers, colleagues, and mid-level to senior managers to resolve issues and achieve goalsPotentially lead projects, teams or serve as a peer mentorDemonstrate data products and technology thought leadershipCollaborate with WFC stakeholders to build strong sponsorship of payments data use casesCollaborate with a team of product managers and product owners to execute the payments data product strategyEmploy design thinking methodologies: customer discovery, product discovery, product definition, product planning, and agile developmentDefine features, use cases, and dashboards that execute on the payments data vision and aligns with the data products strategyProvide business inputs to payments analytics team, both for dashboarding and coordinating ad hoc requests from line of business stakeholdersProvide additional detail to the payments data roadmap, based on stakeholder input, value based prioritization, and current payments trendsCollaborate with technology, architecture, data science, and data management stakeholders to promote effective deliverySupport product manager in delivering payments data roadmapDevelop a deep understanding of data, analytics, and payments execution needs for LOB stakeholdersProvide insights into payments data asset intake and prioritization processSupport competitive market and trend analysis assessments to incorporate and prioritize key findings into product backlogsDefine and refine user stories, ensuring acceptance criteria is clearly understood by the team

Required Qualifications:

5+ years of payments product management experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education

Desired Qualifications:

5+ years' experience in designing customer facing technology and/or data productsExperience with tools to create mockups of increasing fidelity (e.g., Figma)Experience with financial services products and value drivers; experience with payments, treasury management, and wholesale banking preferredExperience with open banking and data sharing, especially for consumer products covered by Regulation E, Regulation Z, and digital walletsExperience designing open banking capabilities that securely transmit customer and financial transaction dataExperience with consumer protection requirements, product terms and conditions, and customer complaint management is beneficialStrong communication and facilitation skills, leading to the ability to influence senior product owners and product managers within customer facing lines of businessStrong PowerPoint presentation skills, with an emphasis on creating presentations for executive audiencesExperience building innovative capabilities with a multidisciplinary teamProven track record of delivering outcomes while working with stakeholdersAbility to deliver in ambiguous situations, at multiple levels within an organizationExperience with agile product management tools (e.g., Jira, Confluence). Agile or scrum certification preferredPreferred experience leading / managing a cross functional team (e.g., design, business, technology, risk)A BS/BA degree or higher, MBA/MS preferred

Locations for this role: 

 150 E 42nd Street, NY, New York  333 Market Street, San Francisco, CA  Three Wells Fargo Center, Charlotte, NC 

Pay Range for San Francisco, CA & New York, NY:

115,900.00 - 206,100.00 USD Annual

Pay Range

$96,600.00 - $206,100.00

Benefits

Wells Fargo provides all eligible full- and part-time employees with a comprehensive set of benefits designed to protect their physical and financial health and to help them make the most of their financial future. Visit Benefits - Wells Fargo Careers for an overview of the following benefit plans and programs offered to employees.

401(k) PlanPaid Time OffParental LeaveCritical Caregiving LeaveDiscounts and SavingsHealth BenefitsCommuter BenefitsTuition ReimbursementScholarships for dependent childrenAdoption Reimbursement

Posting End Date:

11 Apr 2024

 Job posting may come down early due to volume of applicants. 

We Value Diversity

At Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.

Employees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.

Candidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.

Applicants With Disabilities

To request a medical accommodation during the application or interview process, visit Disability Inclusion at Wells Fargo .

Drug and Alcohol Policy

Wells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.

Reference Number

R-353891-2","As a Lead Digital Product Manager on the Enterprise Payments team at Wells Fargo, you will be responsible for leading the strategic development and execution of complex payments data initiatives that span across the enterprise. Your role will be instrumental in shaping and influencing payments strategy by using customer-centric and data-driven approaches. You will collaborate with cross-functional teams to define and prioritize product features and use cases that enhance the payments data ecosystem, while employing design thinking methodologies to drive innovation. Your responsibilities will also include developing dashboards, defining product roadmaps, ensuring regulatory compliance, and providing business inputs to analytics teams. Additionally, you will lead or mentor project teams, facilitate stakeholder engagement, and deliver high-quality outcomes that align with broader digital and business transformation goals.","The ideal candidate will have at least 5 years of experience in payments product management or equivalent roles in digital banking, with a strong background in customer-facing technology and data products. A deep understanding of financial services, including treasury management, digital wallets, Regulation E and Z, and open banking practices is essential. You should possess excellent communication and presentation skills, including experience presenting to executive audiences. Proficiency in agile tools like Jira and Confluence, along with familiarity in mockup design tools such as Figma, is preferred. A bachelor’s degree is required, while a graduate degree (MBA or MS) and certifications in agile or scrum methodologies are highly desirable. Experience leading cross-functional teams, delivering measurable outcomes, and navigating complex organizational structures will ensure success in this role.","{' Regulation E': 'MISC', ' Z': 'MISC', ' Jira': 'MISC', ' Confluence': 'MISC', ' Figma': 'MISC'}"
225,WEX,Data Engineer,"About The Team/Role

The WEX DevOps Engineer SQL Server Database Administrator will be responsible for all Infrastructure-as-Code for the SQL database environments, as well as automation of tasks to allow for self-service and standardized operations. This role will be part of a team which is responsible for the health and stability of the SQL Server Database platform.

How you‚Äôll make an impact

Use of Terraform, YAML, and Powershell to create needed pipelinesUse of Pipelines to create IAAS and PAAS solutions, including SQL Server, Postgres, MySQLExtensive knowledge of Visual Studio Code and GitBuilding of pipelines to accommodate new operations.Changes to existing pipelines to update or upgrade existing SQL ServersWork within the Azure environment to improve upon current SQL landscape Automation of SQL Server patching processesMentor the DBA team in DevOps strategies and processParticipate in DBA activities as needed 

Experience you‚Äôll bring

5+ years of overall IT experience working with SaaS or web development5+ years of hands-on DevOps experience3-5 years experience with SQL Server database experienceExpert in using Terraform, YAML, and Powershell3+ years of IAAS and PAAS experience in AzureExperience with Azure monitoring and insight servicesExperience with Azure DevOps 

Desired Additional Qualifications

Experience in SQL Server Installation and configurationExperience with Windows ClusteringExperience with SQL Server Always On Availability GroupsExperience with SQL 2016+Knowledge of SSDT projects and experience with Source Control especially TFS and GitHub in Azure DevOpsKnowledge and experience with industry-standard change and incident management proceduresSelf-starter capable of working independently or in groups

The base pay range represents the anticipated low and high end of the pay range for this position. Actual pay rates will vary and will be based on various factors, such as your qualifications, skills, competencies, and proficiency for the role. Base pay is one component of WEX's total compensation package. Most sales positions are eligible for commission under the terms of an applicable plan. Non-sales roles are typically eligible for a quarterly or annual bonus based on their role and applicable plan. WEX's comprehensive and market competitive benefits are designed to support your personal and professional well-being. Benefits include health, dental and vision insurances, retirement savings plan, paid time off, health savings account, flexible spending accounts, life insurance, disability insurance, tuition reimbursement, and more. For more information, check out the ""About Us"" section.

Salary Pay Range: $103,000.00 - $137,000.00","As a DevOps Engineer and SQL Server Database Administrator at WEX, you will play a critical role in modernizing and automating the company’s database infrastructure. You will design and implement Infrastructure-as-Code solutions using Terraform, YAML, and PowerShell to create and manage pipelines that provision IaaS and PaaS database environments, including SQL Server, Postgres, and MySQL, within the Azure cloud. Your responsibilities will include enhancing and maintaining the current SQL landscape, streamlining SQL Server patching processes through automation, and mentoring the broader DBA team on DevOps strategies and best practices. You will also be expected to participate in DBA activities such as SQL Server installation, configuration, and management of high availability features like Always On Availability Groups. Working in a collaborative team environment, you will support stable, efficient, and scalable database operations.","The ideal candidate will have at least 5 years of IT experience with a strong background in SaaS or web development, along with 3 to 5 years of hands-on experience as a DevOps Engineer and SQL Server DBA. Proficiency in scripting and automation using Terraform, YAML, and PowerShell is essential, as is experience managing both IaaS and PaaS deployments within Microsoft Azure. A strong grasp of Azure monitoring, Azure DevOps, and tools such as Visual Studio Code and Git is necessary. Preferred qualifications include expertise in SQL Server setup and configuration, experience with Windows Clustering and Always On Availability Groups, and familiarity with SSDT projects and source control platforms like TFS and GitHub. A proactive, self-starting mindset and the ability to work independently or as part of a team are key to success in this role.","{' SQL Server': 'MISC', ' Terraform': 'MISC', ' YAML': 'MISC', ' PowerShell': 'MISC', ' Microsoft Azure': 'MISC', ' Azure': 'MISC', ' Azure DevOps': 'MISC', ' Visual Studio Code': 'MISC', ' Git': 'MISC', ' Windows': 'MISC'}"
227,UBS,Data Analyst,"Job Reference #
290341BR

Job Type
Full Time

Your role
Do you want to design and build next generation business applications using the latest technologies? Are you self-assured at iteratively refining user requirements and removing any ambiguity? Do you have a curious nature, always interested in how to innovate?

We‚Äôre looking for a Data Analytics and BI Lead to:

 Design and implement technology solutions that will solve business problems and strengthen our position as digital pioneers in financial services leverage the latest cloud technologies to provide the best solution to complex business problems design, plan and deliver resilient reporting solutions using Microsoft Fabric and Power Platform provide technical expertise and recommendations in assessing new software projects and initiatives to support and enhance our existing applications.

Your team
You‚Äôll be working in the Risk Technology team in Weehawken NJ. The Risk Technology organization at UBS, delivers quality, innovative solutions that support our Group Functions business partners in achieving their operational goals. Technology is at the very heart of UBS.‚ÄØ‚ÄØAs a team of talented women and men, we have a critical role to play in building, delivering and maintaining the systems, services and infrastructure that power our business.‚ÄØ Technology is about people and every person has a crucial role to play on the UBS Technology team.

Your expertise

 BS or MS in Computer Science or Information Technology highly desired. Ideally, 15+ years of hands-on experience in the following areas of expertise (financial services experiences is a plus): Hands on Experience as a lead software engineer in a globally distributed team delivering enterprise reporting solutions. Experience in solution design, data modelling and database design Ability to design and architect novel technology solutions and lead a team of developers Have strong hands-on experience on using Microsoft BI/Analytics technology stack (SSIS/SSAS/SSRS/Power BI) Experience in Microsoft Azure cloud platform, building modern data pipelines and data models. Experience with data analytics platforms Microsoft Fabric or Azure Synapse/Databricks

About Us
UBS is the world‚Äôs largest and the only truly global wealth manager. We operate through four business divisions: Global Wealth Management, Personal & Corporate Banking, Asset Management and the Investment Bank. Our global reach and the breadth of our expertise set us apart from our competitors..

We have a presence in all major financial centers in more than 50 countries.

How We Hire

This role requires an assessment on application. Learn more about how we hire: www.ubs.com/global/en/careers/experienced-professionals.html

Join us
At UBS, we embrace flexible ways of working when the role permits. We offer different working arrangements like part-time, job-sharing and hybrid (office and home) working. Our purpose-led culture and global infrastructure help us connect, collaborate, and work together in agile ways to meet all our business needs.

From gaining new experiences in different roles to acquiring fresh knowledge and skills, we know that great work is never done alone. We know that it's our people, with their unique backgrounds, skills, experience levels and interests, who drive our ongoing success. Together we‚Äôre more than ourselves. Ready to be part of #teamUBS and make an impact?

Disclaimer / Policy Statements
UBS is an Equal Opportunity Employer. We respect and seek to empower each individual and support the diverse cultures, perspectives, skills and experiences within our workforce.","As a Data Analytics and BI Lead at UBS, you will design and implement cutting-edge business applications that drive digital transformation within the financial services sector. You will leverage cloud-based tools, particularly Microsoft Fabric and Power Platform, to architect resilient and scalable reporting solutions tailored to complex business requirements. Collaborating closely with globally distributed teams, you will lead the development of data pipelines and data models, ensuring technical excellence and optimal performance. Your role includes refining ambiguous user requirements, assessing new initiatives for technological enhancements, and offering expert recommendations that align with strategic goals. This position places you at the forefront of UBS’s innovation strategy, delivering impactful solutions that empower our risk management and business operations.","The ideal candidate will hold a BS or MS in Computer Science, Information Technology, or a related field, and bring over 15 years of hands-on experience in enterprise reporting and business intelligence within a distributed global team setting. You must demonstrate deep expertise in solution architecture, data modeling, and database design, along with a proven track record of leading teams to implement technology solutions. A strong command of the Microsoft BI/Analytics technology stack (including SSIS, SSAS, SSRS, and Power BI) is essential, as is substantial experience working with Microsoft Azure cloud services. Familiarity with modern data analytics platforms such as Microsoft Fabric, Azure Synapse, and Databricks will distinguish top candidates. Financial services industry experience is a plus, as is a passion for innovation and a collaborative approach to problem-solving.","{' Microsoft BI/Analytics': 'MISC', ' SSIS': 'MISC', ' SSAS': 'MISC', ' Power BI': 'MISC', ' Microsoft Azure': 'MISC', ' Microsoft Fabric': 'MISC'}"
228,TikTok,Data Scientist,"Responsibilities

 TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 
Join us.

The Global e-commerce Data Science team aims to maximize the efficiency of e-commerce transactions, lead product decision-making iterations, and achieve sustainable growth in revenue with data and scientific methods, through quantitative techniques such as mathematical statistics and machine learning. The User Growth Data Science Team fuels TikTok Shops user growth by harnessing data science to optimize ROI and strategize growth initiatives. 

What will you doÔºü
- Work closely with user growth products and operations to translate business needs into data problems to support and guide business development;
- Support AB experiments of user growth strategies and precipitate methodologies;
- Independently complete analysis to provide effective recommendations for strategy iteration. 

Qualifications

 - Bachelor degree in Mathematics, Statistics, Computer Science, or Analytics 
- At least 3 years of Data Science experience
- Causal Inference, Experimentation, Product Analytics, Machine Learning, and Statistics experience
- SQL
- Python or R

Preferred Qualifications:
- User Growth Experience
- Advanced Degree (MS, PhD.) in Mathematics, Statistics, Analytics, etc 
- Business oriented. Have a strong business sense to proactively help UG Product and Operations identify key business challenges using data-driven insights.
- Have strong curiosity and self-driving force, like to accept challenges, Aim for the Highest.
- Have excellent communication skills, an open mind, and positive critical thinking
- Solid technical & knowledge of A/B testing methodologies, can consistently explore and find the best practice
- Insightful data sense and rigorous logical mindset, capable of providing systematic approaches to solve business problems;
- End-to-end ownership: embrace the ownership mindset
- Have a strong ability to work under pressure, have the courage to overcome difficulties, and accept challenges.



TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.


TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2 

Job Information:

„ÄêFor Pay Transparency„ÄëCompensation Description (annually) The base salary range for this position in the selected city is $167537 - $312866 annually.Compensation may vary outside of this range depending on a number of factors, including a candidate‚Äôs qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","As a member of TikTok’s Global E-commerce Data Science team, you will work closely with user growth product and operations teams to translate business needs into actionable data problems, delivering insights that guide strategic decision-making. You will independently lead analyses that shape the direction of user growth strategies, support A/B testing experiments, and develop robust methodologies to improve performance and user acquisition outcomes. With a focus on data-driven optimization, you will play a critical role in evaluating product features and operational initiatives, ensuring scalable, efficient, and sustainable growth across the TikTok Shop platform.","The ideal candidate holds at least a bachelor’s degree in Mathematics, Statistics, Computer Science, or Analytics and brings a minimum of three years of experience in data science, particularly in areas such as causal inference, experimentation, product analytics, and machine learning. Proficiency in SQL and a statistical programming language such as Python or R is required. Candidates with user growth experience, an advanced degree (MS or PhD), and a business-oriented mindset will be strongly preferred. Additional strengths include strong curiosity, a proactive problem-solving approach, excellent communication skills, and a solid understanding of A/B testing methodologies. The role also demands a data-driven mindset, logical reasoning, and the ability to own projects from concept through execution.","{' SQL': 'MISC', ' Python': 'MISC', ' R': 'MISC'}"
229,UST,Data Engineer,"Role Description

Data Platform Engineer Data Mesh/Virtualization

Lead I - Software Engineering

Who We Are

Born digital, UST transforms lives through the power of technology. We walk alongside our clients and partners, embedding innovation and agility into everything they do. We help them create transformative experiences and human-centered solutions for a better world.

UST is a mission-driven group of over 39,000+ practical problem solvers and creative thinkers in over 30+ countries. Our entrepreneurial teams are empowered to innovate, act nimbly, and create a lasting and sustainable impact for our clients, their customers, and the communities in which we live.

With us, you‚Äôll create a boundless impact that transforms your career‚Äîand the lives of people across the world.

Visit us at .

You Are

UST is searching for a Data Platform Engineer who will act creatively to develop applications and select appropriate technical options, optimizing application development, maintenance and performance by employing design patterns and reusing proven solutions, account for others' developmental activities.

The Opportunity

Collaborate with the technical team and PdM to identify, document, plan contingency, track and manage risks and issues until all are resolved.Interpret the application/feature/component design to develop the same in accordance with specifications.Code, debug, test, document and communicate product/component/feature development stages.Validate results with user representatives; integrates and commissions the overall solution.Select appropriate technical options for development such as reusing, improving or reconfiguration of existing components or creating own solutions.Optimizes efficiency, cost and quality.Influence and improve customer satisfaction.

This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.

What You Need

Knowledge and understanding of diverse data platforms and operating systems, including current and emerging technologies. Having Strong Platform engineer(Admin) experience with Data Mesh/Virtualization technologies such as Dremio and Starburst and a deep understanding of database technologies. Understanding of various distributed file and table formats such as Iceberg, Delta, Apache Parquet, and common methods in data transformation Understanding of hardware systems performance: CPU, RAM, storage, network, Linux, JVM, distributed systems performance. Experience in using Spark, Object Storage (Dell ECS preferred), and Metadata. Experience using DevOps-related tools like GIT, Gitlab, Splunk, and Ansible. Knowledge of one or more major Cloud Service Providers ‚Äì MS Azure preferred. Proven strengths in problem-solving and root-causing issues while continuously seeking ways to drive optimization, efficiency, and the bottom line. Clear understanding of Incident management, change management and problem management process. Ability to detect all service-impacting issues, accurate triage, partner communication, impact containment, service restoration, and post-incident follow-up. Knowledge in scripting: Python, etc.

Compensation can differ depending on factors including but not limited to the specific office location, role, skill set, education, and level of experience. As required by applicable law, UST provides a reasonable range of compensation for roles that may be hired in various U.S. markets as set forth below.

Role Location: Remote

Compensation Range: $73,000-$109,000

Our full-time, regular associates are eligible for 401K matching, and vacation accrual and are covered from day 1 for paid sick time, healthcare, dental, vision, life, and disability insurance benefits. Depending on the role, some associates may also be eligible for stock options.

What We Believe

We‚Äôre proud to embrace the same values that have shaped UST since the beginning. Since day one, we‚Äôve been building enduring relationships and a culture of integrity. And today, it's those same values that are inspiring us to encourage innovation from everyone to champion diversity and inclusion, and to place people at the center of everything we do.

Humility

We will listen, learn, be empathetic and help selflessly in our interactions with everyone.

Humanity

Through business, we will better the lives of those less fortunate than ourselves.

Integrity

We honor our commitments and act with responsibility in all our relationships.

Equal Employment Opportunity Statement

UST is an Equal Opportunity Employer.

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.

UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance.

#UST

#CB

Skills

Data Mesh,Virtualization,Metadata","As a Data Platform Engineer – Data Mesh/Virtualization at UST, you will lead the development and optimization of data platform solutions with a specific focus on modern virtualization tools such as Dremio and Starburst. You will design, implement, and manage scalable data solutions using distributed file systems, cloud services, and DevOps methodologies. Your role will involve selecting technical options, troubleshooting performance issues, ensuring platform efficiency, and working closely with product managers and technical teams to resolve risks and deliver high-impact, reliable data services. This position offers the opportunity to be a key contributor in building next-gen data platforms within a mission-driven global organization.","You bring strong administrative experience with Data Mesh/Virtualization platforms (such as Dremio and Starburst), combined with in-depth knowledge of modern database technologies and data formats like Apache Iceberg, Delta Lake, and Parquet. You are proficient in distributed computing environments, including Spark and object storage solutions like Dell ECS. Your background includes working with DevOps tools (GIT, Gitlab, Ansible), cloud platforms (preferably Azure), and scripting (Python). You have a solid grasp of system performance monitoring, incident/change/problem management, and delivering scalable solutions in a Linux-based ecosystem. Your ability to drive efficiency, optimize performance, and maintain high levels of service reliability makes you a valuable asset in any enterprise data environment.","{' Dremio': 'MISC', ' Apache Iceberg': 'MISC', ' Delta Lake': 'MISC', ' Parquet': 'MISC', ' Spark': 'MISC', 'GIT': 'MISC', ' Gitlab': 'MISC', ' Ansible': 'MISC', ' Azure': 'MISC', 'Python': 'MISC', ' Linux': 'MISC', 'based': 'MISC'}"
231,TikTok,Data Scientist,"Responsibilities

 TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. 

Why Join Us
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. 
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. 
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. 
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. 
Join us.

The Global e-commerce Data Science team aims to maximize the efficiency of e-commerce transactions, lead product decision-making iterations, and achieve sustainable growth in revenue with data and scientific methods, through quantitative techniques such as mathematical statistics and machine learning. The User Growth Data Science Team fuels TikTok Shops user growth by harnessing data science to optimize ROI and strategize growth initiatives. 

What will you doÔºü
- Work closely with user growth products and operations to translate business needs into data problems to support and guide business development;
- Support AB experiments of user growth strategies and precipitate methodologies;
- Independently complete analysis to provide effective recommendations for strategy iteration. 

Qualifications

 - Bachelor degree in Mathematics, Statistics, Computer Science, or Analytics 
- At least 3 years of Data Science experience
- Causal Inference, Experimentation, Product Analytics, Machine Learning, and Statistics experience
- SQL
- Python or R

Preferred Qualifications:
- User Growth Experience
- Advanced Degree (MS, PhD.) in Mathematics, Statistics, Analytics, etc 
- Business oriented. Have a strong business sense to proactively help UG Product and Operations identify key business challenges using data-driven insights.
- Have strong curiosity and self-driving force, like to accept challenges, Aim for the Highest.
- Have excellent communication skills, an open mind, and positive critical thinking
- Solid technical & knowledge of A/B testing methodologies, can consistently explore and find the best practice
- Insightful data sense and rigorous logical mindset, capable of providing systematic approaches to solve business problems;
- End-to-end ownership: embrace the ownership mindset
- Have a strong ability to work under pressure, have the courage to overcome difficulties, and accept challenges.



TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.


TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2 

Job Information:

„ÄêFor Pay Transparency„ÄëCompensation Description (annually) The base salary range for this position in the selected city is $176355 - $329333 annually.Compensation may vary outside of this range depending on a number of factors, including a candidate‚Äôs qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.","TikTok is seeking a Data Scientist to join its Global E-Commerce Data Science team, with a focus on user growth. In this role, you’ll work closely with product and operations teams to convert business needs into data-driven strategies that enhance growth and optimize ROI. You’ll independently lead analytical projects, support A/B testing methodologies, and provide actionable recommendations based on your findings. The goal is to fuel TikTok Shop’s user expansion by leveraging techniques such as causal inference, machine learning, and advanced statistical analysis.","Candidates must have at least a bachelor's degree in Mathematics, Statistics, Computer Science, or a related field, and a minimum of three years of data science experience. Proficiency in SQL and either Python or R is required, along with a solid foundation in experimentation, product analytics, and statistical modeling. Preferred qualifications include experience in user growth analytics, an advanced degree, strong business acumen, and the ability to take end-to-end ownership of projects. TikTok emphasizes curiosity, critical thinking, communication skills, and the ability to thrive under pressure.","{' SQL': 'MISC', ' Python': 'MISC', ' R': 'MISC'}"
232,Sanofi,Data Engineer,"iMove, the Sanofi VIE Program, is available to citizens of the European Economic Area (EU + Norway, Liechtenstein and Iceland) aged between 18 and 28.

PLEASE NOTE that since this program is primarily an international development program, candidates cannot apply to a VIE assignment in their own country of citizenship.

PLEASE NOTE that applications that are only submitted in French cannot be considered by our non-French speaking partners at Sanofi worldwide. Therefore, only applications that are submitted in English will be considered. Please make sure to apply with your personal email address.

At Sanofi diversity and inclusion is foundational to how we operate and is embedded in our Core Values. We respect the diversity of our people, their backgrounds and experiences. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our employees, patients and customers.

We are looking for a candidate for a VIE mission:

Strategic Planning and Data Quality - VIE Contract (W/M)

Target start date: 01/08/2024

Responsibilities:

Actively participate on the Data Quality Audit initiative (DQA) panel that is a new module to be evaluated and tested which will enable you to examine the accuracy of your data.Use exiting software and scripts to extract valuable insights on project quality.Develop and maintain reporting solutions through Business Intelligence tools to allow for automation and alerts when potential discrepancies are noted.Support project review to ensure optimal critical path, key project objectives and over all data quality compared to internal processes.Participate in upskilling initiatives aimed at developing data visualization, Generative Artificial Intelligence (AI) and Business Intelligence (BI) best practices.Collaborate in the development of various data analyses and quality modules to support planning and reporting needs.Provide feedback to development, UAT and summarize results in presentations with Head of Strategic Planning and during meetings with cross-functional teams in an international environment.

Key ‚ÄúMUST HAVE‚Äù competencies, skills & experiences:

Master‚Äôs degree in Bio and Medical Engineering, Health Sciences and/or Data Science. Experience in Project Management, Planning Systems (Planisware a plus), Data quality, programming and/or machine learning.Strong knowledge of Strategic Project Planning and Drug Development in a healthcare company.Strong understanding Planisware Enterprise tool and Data Base.Data Quality analysis and problem solving.Knowledge in BI tools (Tableau, Power BI) and AI app ideally (such as PLAI).Ability to decrypt and translate business problematic into a technical solution.Team focused.Autonomous.Curiosity and self-learner.Analytical mindset, pragmatic, results oriented.Good communication skills and ability to work in an international and multi-cultural environment.Fluent in French and English (verbal and writing).

Pursue progress. Discover extraordinary.

Pursue progress, discover extraordinary

Better is out there. Better medications, better outcomes, better science. But progress doesn‚Äôt happen without people ‚Äì people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let‚Äôs be those people.

At Sanofi, we provide equal opportunities to all regardless of race, colour, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, ability or gender identity.

Watch our ALL IN video and check out our Diversity Equity and Inclusion actions at sanofi.com!","The Strategic Planning and Data Quality VIE Contract at Sanofi is an exciting international opportunity tailored for young professionals from the European Economic Area (excluding their country of citizenship). Starting in August 2024, this VIE role is centered on enhancing data quality and strategic planning within a global, cross-functional environment. Responsibilities include actively contributing to the Data Quality Audit (DQA) initiative, using software and scripts to generate insights, and developing automated BI reporting solutions to monitor and address data discrepancies. The position also involves supporting project reviews to optimize planning objectives, participating in skill development initiatives around data visualization and AI, and presenting findings to leadership and international teams.","Candidates must hold a Master’s degree in Bio/Medical Engineering, Health Sciences, or Data Science, and should have relevant experience in project management, data quality, programming, or machine learning. Proficiency in planning systems like Planisware, BI tools such as Tableau and Power BI, and ideally AI applications (e.g., PLAI) is highly valued. Strong analytical and problem-solving skills, autonomy, curiosity, and the ability to communicate effectively in both French and English are essential. This opportunity offers the chance to grow in a diverse, inclusive, and purpose-driven organization focused on innovation in global healthcare.","{' Planisware': 'MISC', ' Power BI': 'MISC', ' PLAI': 'MISC', ' French': 'MISC', ' English': 'MISC'}"
233,Cogent Communications,Data Engineer,"Company: 

Cogent Communications is a global, Tier 1 facilities-based ISP, consistently ranked as one of the top five networks in the world and is publicly traded on the NASDAQ Stock Market under the ticker symbol CCOI. Cogent specializes in providing businesses with high speed Internet access and Ethernet transport services. Cogent's facilities-based, all-optical IP network backbone provides IP services globally. Since its inception, Cogent has unleashed the benefits of IP technology, building one of the largest and highest capacity IP networks in the world. This network enables Cogent to offer large bandwidth connections at highly competitive prices. Cogent also offers superior customer support by virtue of its end-to-end control of service delivery and network monitoring. A competitive base salary and a full benefits package including; Health, Dental, Vision, Paid Time Off ( PTO), Short- and Long-Term Disability, Life Insurance, Holidays, Parental Leave, 401 ( k) plan with employer match, stock options, and an Employee Assistance Program. Most benefits take effect within 30 days of employment, and some require a waiting period.

 Job Summary: 

The SQL Server DBA will be responsible for the implementation, configuration, maintenance, performance and support of critical SQL Server DB systems, to ensure the availability and consistent performance of our corporate and business applications. This is a ‚Äúhands-on‚Äù position requiring solid technical skills, as well as excellent interpersonal and communication skills.

The successful candidate will be responsible for the development and support of different versions of SQL server and other database technologies like MySQL, Oracle, etc., ensuring their optimal functioning ( security, health, performance, etc.).

The successful candidate must be capable of working independently or collaboratively with other team members.

 Essential Duties and Responsibilities: 

Manage SQL Server databases and other RDBMS through different product lifecycle from development to mission-critical production systemsInstall, Configure and maintain database servers and processes, including monitoring of system health and performance, to ensure high levels of performance, availability, and securitySupport 24x7 operational database support including periodic on-call rotationConduct diagnostic tests and evaluate performance metrics on the databasesMonitor the databases to ensure system health, functionality and remediate problems/issues in a timely mannerMigrate/convert databases from Oracle 11g, 12c and 19c to MS SQL serverExecute & maintain SQL scripts and utility jobs for MS SQL database maintenanceImplement & manage MS SQL database backups and restore, clustering, always on, failover and load balancing technologiesPerform DB refreshes from Prod to lower environmentsMonitor database status, logs, space utilization, extents, locks, blockings and deadlocks and clearing them accordinglyImplement and support MS SQL ( Active/Passive & Active/Active), Multi Node Clustering for four node clustersApply data modeling techniques to ensure that development and implementation support efforts meet integration and performance expectationsIndependently analyze, solve, and correct issues in real time, providing end-to-end problem resolutionRefine and automate regular processes, track issues, and document changesAssist developers and application owners with complex query tuning and optimizationPerform scheduled maintenance and support release deployment activities after hoursShare domain and technical expertise, providing technical mentorship and cross-training to other peers and team membersPerform all other DB related tasks and activities as assigned
 Qualifications: 

3+ years of experience supporting MS SQL Server DatabasesExperience with Performance Tuning and Optimization ( PTO), using native monitoring and troubleshooting toolsExperience with backups, restores and recovery modelsKnowledge of High Availability ( HA) and Disaster Recovery ( DR) options for SQL ServerExperience working with Windows server, including Active DirectoryExperience creating and deploying SSRS, SSIS and SSAS packagesAbility to organize and plan work independentlyAbility to multi-task and context-switch effectively between different activities and teamsExperience with MySQL, Oracle and MariaDB running on LinuxExperience with VMware, NetApp and SSRS a plusAbility to write, keep and maintain SOP, documentation, etc

 Other qualification that would be nice to have include: 

Oracle DB knowledge in a Unix environmentKnowledge with Rubrik MS SQL backup technologyKnowledge with SQL Monitor MS SQL performance monitoring toolKnowledge with Power Script/DBAToolsExcellent written and verbal communicationFlexible, team player, ‚Äúget-it-done‚Äù personality

 Physical Requirements: 

Remains in a sitting/stationary position continually or almost continually during the work dayOperates a computer and performs desk-based computer tasks continually; frequently viewing a computer screenPrefer the ability to lift, carry, push, pull objects and/or equipment that weighs up to 50 pounds on rare occasions

 COVID-19 Policy: 

Cogent has adopted a mandatory vaccination and booster policy which requires all U.S. employees to be fully vaccinated with one booster against COVID-19. Prior to beginning employment, new employees must provide proof of vaccination or apply for and receive an accommodation to be exempt from the policy.

By submitting an application or resume for this position, I understand that is an in-office position and agree to abide Cogent‚Äôs mandatory vaccination policy.

To apply for the MS SQL, Database Administrator position, please submit your resume and cover letter to careers@cogentco.com .

 Cogent Communications is an Equal Opportunity Employer.","The SQL Server Database Administrator will be responsible for managing and maintaining SQL Server databases and other RDBMS platforms across development and mission-critical production environments. This includes installing, configuring, and monitoring database servers to ensure high performance, availability, and security. Key tasks involve supporting 24/7 operations, performing database migrations (particularly from Oracle to SQL Server), managing backups and restores, optimizing queries, and implementing high availability and disaster recovery solutions. The DBA will also participate in database refreshes, troubleshoot performance issues, automate regular processes, and collaborate closely with development and application teams. Additionally, the role includes documenting procedures, supporting scheduled maintenance, and mentoring peers on best practices.","The ideal candidate will have a minimum of 3 years of experience supporting Microsoft SQL Server databases, with strong skills in performance tuning, backup and recovery strategies, and high availability configurations. Experience with Windows Server, Active Directory, and creating/deploying SSRS, SSIS, and SSAS packages is essential. Familiarity with MySQL, Oracle, and MariaDB in Linux environments is a plus. Additional knowledge of tools such as Rubrik, SQL Monitor, PowerShell, and DBA Tools is desirable. Excellent written and verbal communication skills, the ability to work independently or in a team, and strong organizational abilities are also key to success in this role.","{' Microsoft SQL Server': 'MISC', ' Windows Server': 'MISC', ' Active Directory': 'MISC', ' SSRS': 'MISC', ' SSIS': 'MISC', ' SSAS': 'MISC', ' MySQL': 'MISC', ' MariaDB': 'MISC', ' Linux': 'MISC', ' Rubrik': 'MISC', ' SQL Monitor': 'MISC', ' PowerShell': 'MISC', ' DBA Tools': 'MISC'}"
235,Nityo Infotech,Data Analyst,"Responsibilities: 
¬∑ Client Engagement Act as the primary point of contact for the client managing daily interactions and building strong trust based relationships ¬∑ Project Delivery Oversee the delivery of data services projects ensuring they meet quality standards deadlines and budget requirements ¬∑ Coordinate with both internal teams and the client to ensure smooth project execution. ¬∑ Technical Leadership Provide technical guidance in the data space using AWS cloud services to suggest innovative solutions and improvements to the client s data management and analytics capabilities Opportunity.¬∑ Development Proactively identify and pursue new business opportunities and engagements with the client following up diligently and driving the process to closure.¬∑ Communication Maintain impeccable standards of communication both spoken and written to clearly articulate complex technical concepts and value propositions to the client Collaboration ¬∑ Work closely with internal teams including technical guides and business development to align on client needs and market trends ensuring our offerings remain driven and responsive 
Required Skills:
¬∑ Expertise in AWS Strong understanding of AWS cloud services Kinesis S3 Redshift DynamoDB Athena Aurora DB etc architectures and data management tools Collibra etc Data Technology ¬∑ Proficiency Solid background in data technologies including databases ETL tools data warehousing and analytics platforms Business Insight ¬∑ Ability to identify business opportunities and understand the client s industry and data needs ¬∑ Exceptional verbal and written communication skills with the ability to engage effectively at all levels of the client organization Project Management Confirmed experience in managing data projects with a track record of delivering on time and within budget","As the primary point of contact for the client, you will manage daily interactions and foster strong, trust-based relationships. You will oversee the delivery of data services projects, ensuring they meet quality, timeline, and budget expectations. This includes coordinating between internal teams and the client to facilitate smooth execution, while also providing technical guidance in AWS cloud services. Your role will include identifying opportunities to enhance the client’s data management and analytics strategies through innovative solutions. Additionally, you will be expected to identify and pursue new business opportunities, following up diligently and helping drive them to closure.","The ideal candidate will have strong expertise in AWS cloud services such as Kinesis, S3, Redshift, DynamoDB, Athena, and Aurora DB, along with familiarity with tools like Collibra. A solid technical background in data technologies—including databases, ETL tools, data warehousing, and analytics platforms—is essential. You should possess a keen understanding of business needs, enabling you to identify opportunities and tailor solutions accordingly. Strong verbal and written communication skills are crucial for engaging stakeholders across all levels of an organization. Proven experience in managing data projects and consistently delivering them on time and within budget is required.",{' Collibra': 'MISC'}
236,Chmura Economics & Analytics,Data Engineer,"Founded in 1998, Chmura Economics & Analytics is headquartered in Richmond, Virginia‚Äôs historic Shockoe Slip with a regional office in Cleveland, Ohio. Chmura provides labor market software (JobsEQ), consulting, and data so you can make informed decisions that grow your community or organization. Our PhD economists, data scientists, and strategic planners are your guide to the labor market. Chmura understands that good data is the backbone of critical thinking. We are committed to delivering the highest quality products and services to each and every client. Our vision is be the nation's preferred provider of economic research, software, and data solutions. 
Chmura Economics & Analytics, LLC (‚ÄúChmura‚Äù) has exciting opportunity for a full-time Data Engineer to join our growing team. This role will implement and optimize data solutions for a wide variety of complex big data sets, and troubleshoot data issues to effectively triage timely solutions.
ResponsibilitiesImplement, maintain, and continuously optimize data processing solutions for a wide variety of complex big data sets.Architect, design, develop, and maintain data integration solutions as they relate to all stages of extract, transform, and load (ETL) pipelines.Build internal tooling that serves to improve upon the ability to create, test, build, serve, compare, and optimize complex data models and their related data sets.Troubleshoot data issues and effectively triage timely solutions.Contribute to and maintain documentation as it relates to new and existing data models, processes, storage, and optimization techniques.
RequirementsExperience in at least one of these relevant programming languages: C#, Python, Java, etc.Experience with Elasticsearch, MongoDB, or other NoSQL experienceExperience with containerization platforms (Docker, Kubernetes, etc)Experience with schema design and writing queries for SQL Server, Postgres or similarAzure experienceKanban/Agile experienceFamiliarity with machine learning and NLP is nice to have but not requiredAt least 2 years. This is not a ‚Äújunior‚Äù position.

Chmura is not able to provide sponsorship for this role. We back our colleagues with the following benefits/programs: 
Competitive base salaries Comprehensive medical, dental, and vision benefitsLife Insurance and Disability Insurance benefits, 100% of premium paid by ChmuraParking and Transit Program Up to a 4% Company Match on retirement savings planPaid parental leave for expecting parents, regardless of gender, offered for pregnancy, adoption or surrogacy Free and confidential support for counseling, personal and work-related issues through our employer-sponsored service with Cigna (Employee Assistance Program)Employee Development ProgramTuition Reimbursement Program
Chmura is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, physical and mental disability, genetic information, marital status, sexual orientation, gender identity/assignment, citizenship, pregnancy or maternity, protected veteran status, or any other status prohibited by applicable national, federal, state or local law. Chmura promotes a drug-free workplace. Chmura will consider for employment, qualified applicants with a criminal history in a manner consistent with the requirements of applicable federal, state, and local laws and regulations regarding criminal background inquiries, including, to the extent applicable, following applicable federal, state, and local laws and regulations regarding criminal background inquiries. 
#LI-Hybrid #LI-CHMURA","As a Data Engineer at Chmura Economics & Analytics, you will be responsible for implementing, maintaining, and optimizing data processing solutions for a wide variety of complex big data sets. Your duties include designing and developing data integration solutions, particularly across all stages of ETL pipelines. You will also build internal tools to improve data model testing, optimization, and deployment. Troubleshooting data-related issues and promptly resolving them is a key part of the role, as well as contributing to and maintaining documentation for existing and new data models, storage, and optimization techniques.","Candidates must have at least two years of experience in a similar role and proficiency in at least one programming language such as C#, Python, or Java. Familiarity with NoSQL databases like Elasticsearch or MongoDB, containerization platforms (Docker, Kubernetes), and cloud services (particularly Azure) is essential. Experience with SQL-based databases (e.g., SQL Server or Postgres) and an understanding of schema design and queries is also required. A background in Agile/Kanban environments is beneficial, and familiarity with machine learning or NLP is a plus, though not required. This is not a junior-level position, and Chmura does not offer visa sponsorship for this role.","{' C#': 'MISC', ' Python': 'MISC', ' Java': 'MISC', ' NoSQL': 'MISC', ' SQL Server': 'MISC', ' Postgres': 'MISC'}"
237,Ignitec Inc,Data Engineer,"Join Our Vision:We are a GenAI startup in stealth mode, at the forefront of revolutionizing the healthcare and life sciences industries. Our mission is to harness the transformative power of Artificial Intelligence, Automation, and Analytics (A3) to drive unparalleled economic value and innovation in healthcare. By blending state-of-the-art technology with human ingenuity, mathematical rigor, and thoughtful design, we are expanding rapidly. This is a unique chance to join an innovative team and impact an industry vital to human well-being from the ground floor.
Job Description:As a Data Engineer specializing in OCR technology within our team, you will play a crucial role in managing and extracting valuable data from diverse and complex healthcare-specific documents such as electronic medical records (EMR), lab reports, and autopsy reports. These documents often come in highly variant and inconsistent formats, and your expertise will help us standardize and extract critical information, supporting our goals of enhancing diagnostic precision and patient care.
Responsibilities:Develop and refine OCR systems tailored for extracting data from highly variant and inconsistent healthcare documents, including EMRs, lab reports, and autopsy findings.Utilize Python and prominent open-source libraries (e.g., Tesseract, PyTesseract, OpenCV) to implement effective data extraction algorithms capable of handling specific nuances of healthcare data.Work closely with data scientists to clean, organize, and make extracted data accessible for advanced analytics and AI-driven health models.Enhance our data processing pipelines by integrating bespoke OCR solutions, ensuring robust data integrity and compliance with healthcare regulations.Contribute to the deployment of OCR solutions in cloud environments, focusing on scalability, security, and compliance with healthcare standards (e.g., HIPAA).Engage in full-stack development initiatives to integrate OCR technology into user-facing applications, improving the accessibility and usability of extracted data.Implement continuous integration and continuous deployment (CI/CD) practices to streamline development, testing, and deployment of OCR and data processing modules.
Required Skills:Deep expertise in Python and its libraries for data handling and image processing.Proven experience in developing OCR solutions, particularly for processing complex healthcare documents.Strong background in data engineering with a focus on maintaining data integrity and compliance within the healthcare sector.Familiarity with healthcare data privacy standards such as HIPAA.Experience with cloud platforms (AWS, Azure) and understanding of their application in a regulated industry.Knowledge of full-stack development and modern DevOps practices is a plus.
Qualifications:Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Data Science, Bioinformatics, or a related field.At least 3 years of relevant experience in data engineering or a similar role within the healthcare or life sciences industry.Excellent analytical and problem-solving skills, with a strong attention to detail.Effective communication and collaboration skills, capable of working in a dynamic and fast-paced environment.","As a Data Engineer focused on OCR technology, you will be instrumental in developing tailored solutions for extracting data from complex and inconsistent healthcare documents such as EMRs, lab reports, and autopsy findings. Using Python and libraries like Tesseract, PyTesseract, and OpenCV, you will create algorithms that address the unique challenges of healthcare data. You’ll also collaborate with data scientists to clean and structure extracted data for use in advanced analytics and AI-driven models. Furthermore, you will enhance data pipelines, integrate OCR into full-stack applications, ensure HIPAA compliance, and support deployment in secure cloud environments using CI/CD practices.","The ideal candidate will have a Bachelor’s or Master’s degree in Computer Science, Data Science, Bioinformatics, or a related field, along with a minimum of 3 years of relevant experience in data engineering within healthcare or life sciences. You should possess deep expertise in Python, a strong track record in OCR solution development, and an understanding of healthcare data standards and regulations. Familiarity with cloud platforms like AWS or Azure is essential, and experience in full-stack development and modern DevOps practices is a plus. Strong analytical, communication, and collaboration skills are crucial for thriving in our fast-paced, innovative environment.",{' Python': 'MISC'}
238,Emancro,Data Engineer,"Machine Learning Operations and Data EngineerThe CompanyEmancro‚Äôs mission is to build general-purpose hospital logistics robots that perform a wide variety of tasks such as organizing and distributing medication and medical supplies within hospitals, and many more tasks in the future. In this way, robots are freeing up medical staff‚Äôs time and enable better and more resilient patient care.We are an ambitious and rapidly growing team pushing the boundaries of what is possible in robotics, leveraging recent, cutting-edge breakthroughs in machine learning-enabled, data-driven robotics.
The RoleStart date: As soon as possible, no later than June 1st 2024Location: Berkeley, CA, in person
Work ComponentsDesign, develop, and maintain scalable data pipelines and ETL processes to extract, transform, and load data at large scale (in the order of 100sTB)Setting up and maintaining cloud-database (e.g. DynamoDB, Postgres etc.)Manage containerized environments (e.g., Docker, Kubernetes) for running machine learning workloads.Setting up and Maintaining Cloud multi-GPU training infrastructure (GCP, AWS, Azure) with Pytorch and JaxSetting up and Maintaining MLOps frameworks, e.g. ClearML, ZenML etc.Implement CI/CD pipelines and automation tools to streamline the model development and deployment process.Deploying ML Models on the cloud for low-latency production/serving
Key QualificationsExpert knowledge of using and configuring GCP (Vertex), AWS, Azure Python: 5+ years of experienceMachine Learning libraries: Pytorch, JaxDevelopment tools: Bash, GitData Science frameworks: DatabricksAgile Software developmentCloud Management: Slurm, KubernetesData Logging: Weights and BiasesOrchestration, Autoscaling: Ray, ClearnML, WandB etc.
Optional QualificationsExperience training LLMs and VLMsML for Robotics, Computer Vision etc.Developing Browser Apps/Dashboards, both frontend and backend Javascript, React, etc. ÔªøEmancro is committed to equal employment opportunities regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status.","As a Machine Learning Operations and Data Engineer at Emancro, you will play a pivotal role in developing and maintaining large-scale data pipelines and ETL systems capable of handling hundreds of terabytes of robotics data. You’ll manage cloud-based databases such as DynamoDB and Postgres, as well as containerized environments (Docker, Kubernetes) to support scalable ML workloads. You'll be responsible for setting up and managing multi-GPU training infrastructure on platforms like GCP, AWS, and Azure using tools such as PyTorch and JAX. Your work will also include deploying MLOps frameworks (e.g., ClearML, ZenML), implementing CI/CD pipelines, and deploying ML models for production use.","The ideal candidate will have 5+ years of experience in Python and strong expertise in cloud platforms (GCP, AWS, Azure), container orchestration (Docker, Kubernetes), and MLOps tools such as Weights & Biases, Ray, and ClearML. Proficiency in Git, Bash, and data science frameworks like Databricks is essential. Experience with ML libraries like PyTorch and JAX, as well as data infrastructure and orchestration tools like Slurm and CI/CD pipelines, is critical. Bonus qualifications include experience with LLMs/VLMs, robotics-focused ML applications (e.g., computer vision), and web development using JavaScript or React. This is a full-time, in-person role based in Berkeley, CA, starting no later than June 1, 2024.","{' Python': 'MISC', ' Git': 'MISC', ' Bash': 'MISC', ' Databricks': 'MISC', ' PyTorch': 'MISC', ' JAX': 'MISC', ' JavaScript': 'MISC', ' React': 'MISC'}"
240,Amiga Informatics,Data Scientist,"Role: Data Science ConsultantLocation: US RemoteType: Full-time
ÔªøClient: Join a top data management consultancy in the Analytics Business division! An exciting opportunity to solve a range of problems, work closely with senior leaders, and make a real impact on our growth. Here's what you'll do:Work closely with clients to understand what they need and offer solutions that hit the mark.Lead sessions to figure out what customers want and map out plans to make it happen.Partner with Product and Business leads to run tests and learn what works best.Figure out the best ways to measure how well products and businesses are doing, making sure it fits with what stakeholders need.Set up ways to track data that help the team make good decisions.Make sure the offshore team understands what needs to be done and work closely with them to get projects done.Create presentations and share our ideas with senior executives in a way they can understand and get behind.
What you will need:6-10 years of experience in data science and analytics, working directly with customers.A degree in Computer Science, Engineering, Statistics, or a related field.Experience with A/B testing and statistical analysis.A knack for working with internal teams and guiding them on data science and analytics.Great communication skills, with the ability to work well with clients and internal teams.Strong skills in Python or R, plus SQL.The ability to manage multiple projects in a fast-paced environment. If you are interested in this position, apply directly to the link. We are an equal-opportunity employer and value diversity at our company. All qualified applicants will receive consideration for employment without regard to race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, disability, or age","In this role, you’ll engage directly with clients to understand their business challenges, lead requirement-gathering sessions, and collaborate with cross-functional teams to develop data-driven solutions. You’ll partner with product and business leaders to run experiments, set up performance metrics aligned with stakeholder goals, and drive actionable insights. Your responsibilities will also include ensuring clear communication with offshore teams, managing project deliverables, and presenting findings to senior executives in an impactful and accessible manner.","To thrive in this Data Science Consultant role, you should bring 6–10 years of experience in data science and analytics, with a strong track record of working directly with clients to deliver impactful solutions. A degree in Computer Science, Engineering, Statistics, or a related field is essential. Proficiency in Python or R and SQL is required, alongside a solid foundation in A/B testing and statistical analysis. The ideal candidate is not only technically strong but also possesses excellent communication and interpersonal skills, allowing them to effectively collaborate with clients and internal teams, guide data-driven decision-making, and present findings to executive audiences. The ability to manage multiple projects in a fast-paced, client-facing environment is key.","{' Python': 'MISC', ' R': 'MISC', ' SQL': 'MISC'}"
242,Ignitec Inc,Data Engineer,"Join Our Vision:We are a GenAI Company in stealth mode, at the forefront of revolutionizing the healthcare and life sciences industries. Our mission is to harness the transformative power of Artificial Intelligence, Automation, and Analytics (A3) to drive unparalleled economic value and innovation in healthcare. By blending state-of-the-art technology with human ingenuity, mathematical rigor, and thoughtful design, we are expanding rapidly. This is a unique chance to join an innovative team and impact an industry vital to human well-being from the ground floor.
Job Description:As a Data Engineer specializing in OCR technology within our team, you will play a crucial role in managing and extracting valuable data from diverse and complex healthcare-specific documents such as electronic medical records (EMR), lab reports, and autopsy reports. These documents often come in highly variant and inconsistent formats, and your expertise will help us standardize and extract critical information, supporting our goals of enhancing diagnostic precision and patient care.
Responsibilities:Develop and refine OCR systems tailored for extracting data from highly variant and inconsistent healthcare documents, including EMRs, lab reports, and autopsy findings.Utilize Python and prominent open-source libraries (e.g., Tesseract, PyTesseract, OpenCV) to implement effective data extraction algorithms capable of handling specific nuances of healthcare data.Work closely with data scientists to clean, organize, and make extracted data accessible for advanced analytics and AI-driven health models.Enhance our data processing pipelines by integrating bespoke OCR solutions, ensuring robust data integrity and compliance with healthcare regulations.Contribute to the deployment of OCR solutions in cloud environments, focusing on scalability, security, and compliance with healthcare standards (e.g., HIPAA).Engage in full-stack development initiatives to integrate OCR technology into user-facing applications, improving the accessibility and usability of extracted data.Implement continuous integration and continuous deployment (CI/CD) practices to streamline development, testing, and deployment of OCR and data processing modules.
Required Skills:Deep expertise in Python and its libraries for data handling and image processing.Proven experience in developing OCR solutions, particularly for processing complex healthcare documents.Strong background in data engineering with a focus on maintaining data integrity and compliance within the healthcare sector.Familiarity with healthcare data privacy standards such as HIPAA.Experience with cloud platforms (AWS, Azure) and understanding of their application in a regulated industry.Knowledge of full-stack development and modern DevOps practices is a plus.
Qualifications:Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Data Science, Bioinformatics, or a related field.At least 3 years of relevant experience in data engineering or a similar role within the healthcare or life sciences industry.Excellent analytical and problem-solving skills, with a strong attention to detail.Effective communication and collaboration skills, capable of working in a dynamic and fast-paced environment.","To qualify for the Data Science Consultant role, candidates should have 6 to 10 years of hands-on experience in data science and analytics, particularly in client-facing roles. A strong academic background with a degree in Computer Science, Engineering, Statistics, or a related field is essential. Proficiency in programming languages such as Python or R, along with strong SQL skills, is required. Candidates should have proven expertise in A/B testing and statistical analysis, as well as the ability to effectively collaborate with both clients and internal stakeholders. Excellent communication skills are vital, with the capability to simplify complex data insights for executive-level presentations. The ideal candidate will also demonstrate strong organizational skills and the ability to manage multiple projects in a fast-paced, agile environment.","The ideal candidate will hold a Bachelor’s or Master’s degree in Computer Science, Data Science, Bioinformatics, or a related discipline, with at least 3 years of relevant experience in data engineering or a similar role within the healthcare or life sciences industry. Deep expertise in Python and its libraries for image processing and data handling is essential, along with demonstrated experience in developing OCR solutions specifically tailored to complex healthcare documents. A strong understanding of data integrity and compliance, particularly within the framework of healthcare privacy standards such as HIPAA, is crucial.","{' Python': 'MISC', ' HIPAA': 'MISC'}"
244,Vervent,Data Analyst,"Job Type
Full-time
Description
Our ideal candidate is someone who is excited to become a part of an awesome, fast-growing team and must display these three top (required) skills:
 BA/BS degree in finance-related field and/or 2+ years working in finance or related field Strong working knowledge of Microsoft Office (especially Excel) Ability to work in a fast-paced environment and attention to detail. This role includes reviews and reconciliation of financial information.
General Position Summary
The Business Analyst performs professional duties related to the review, assessment and development of business systems and processes as well as new client requirements. This includes reviewing existing processes to develop strong QA procedures as well as maximizing review efficiencies and internal controls through process re-engineering. The Business Analyst will assist with the development of seamless solutions for unique requirements of new clients, delivered and implemented on time and within scope. This role will ensure that all activity, reconciliation, reporting, and analysis is carried out in an effective, timely and accurate manner and will look for continued process improvement and innovation.
Perks
 Medical, FSA & HSA, Dental, Vision + More! 401k - 100% vested once you start contributing. Generous company match! Regular employee health, wellness & engagement activities! Pet Insurance, because fur babies are important to us too!
About Vervent
As one of the pre-eminent Lending as a Service (LaaS) companies, Vervent sets the global standard for outperformance by delivering superior expertise, future-built technology, and meaningful services. We support our industry-leading partners with primary strategic services including Loan & Lease Servicing, Call Center Services, Backup Servicing/Capital Markets Support, Credit Card Servicing, and Card Marketing & Customer Acquisition. Vervent empowers companies to accelerate business, drive compliance, and maximize service.
If you‚Äôre interested in reviewing the full job description, continue reading below‚Ä¶
Primary Responsibilities
Define and document client business functions and processes and ensure adherence to investor guidelines and contractual agreements.Develop and flawlessly execute reconciliation and reporting through coordination with clients and internal resources that embodies the mission and policies of the company.Perform ongoing evaluation of process and reconciliation effectiveness for new client onboarding and portfolio updates for existing clients.Develop strong knowledge of sFTP and Sharefile interfaces and utilize tools such as Excel and Power Pivots to ensure continuous process and efficiency improvements.Build strong working relationships with clients, stakeholders, vendors, and team members through effective communication throughout client life cycle.Deliver analytics on the largest clients using Power BI and EDW tools and communicate results and trends to internal stakeholders.Plan, organize and conduct business process reengineering/improvement projects and/or management reviews thorough gap analysis and develop multiple solutions for identified gaps.Refine tools, techniques, and standardization to ensure repeatable results, enhance company effectiveness, client satisfaction, and overall cost efficiency.
Requirements
Bachelor‚Äôs in business management, Finance, Computer Science, or related field and/or 2-5 years of experience in finance or related field, or combination of relevant experience and education.Ability to communicate effectively with various audiences including clients, team members, and vendors, through written and verbal means.Must possess proven leadership skills with the ability to influence key decision makers and collaborate across business lines.Must demonstrate strong analytical skills and ability to translate data into action.Strong working knowledge of computer software including Microsoft Office and Loan Servicing Software required.
Physical Requirements
The work is of an intellectual nature. While performing the functions of this job, the employee is required to stand and sit for prolonged periods. Specific vision abilities required include close and medium distance vision and the ability to adjust focus. Must be able to hear normal sounds, distinguish sound as voice and communicate through human speech. This position requires the ability to operate a keyboard, computer mouse, telephone, fax, copier, writing tools, and other standard office equipment. On an occasion, an employee will be asked to lift items weighing up to 35 lbs.
Other Duties
Please note this job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities and activities may change at any time with or without notice.
Salary
Salary range for this role is $66,560 - $73,000 per year","The analyst will be responsible for assessing and refining business systems, ensuring accurate reporting, executing reconciliations, and supporting client onboarding and portfolio updates. Responsibilities also include developing analytics using Power BI and EDW tools, maintaining sFTP and Sharefile systems, and ensuring compliance with investor and contractual guidelines.",BA/BS in a finance-related field or 2+ years of professional experience in finance. This role requires a strong command of Microsoft Office—especially Excel—and the ability to manage detailed financial reviews and reconciliations in a fast-paced environment.,"{' Microsoft Office': 'MISC', ' Excel': 'MISC'}"
245,Resource Logistics Inc.,Data Engineer,"Title- SQL Server Database & AWS Cloud EngineerRemoteFull Time
Core skills 12+ yrs hands-on SQL Server Production DBA experience handling very large database systems. Microsoft Certified Solutions Expert (preferred) or Microsoft Certified Solutions Associate in SQL 2014/SQL 2016/2017. 4+ Yrs experience with AWS Service offerings and Components, AWS-CLI, AWS-RDS, AWS Storage, Cloud formation and AWS DB Migrations. 8+ Yrs experience with SQL Server Performance tuning, Capacity planning, Resource usage analysis and Recommendations. 4+ yrs experience with Windows Powershell for SQL Server, Powershell usage-on AWS-CLI. 8+ yrs experience with deploying SSRS, Assemblies/CLRs, Extended Stored Procedures, SSIS, etc. 8+ yrs experience with deploying SQL Replication, Log Shipping, DB Mirroring. Strong experience on Core Industry Standards for SQL Server, Windows AWS and SAN (for ex: NIST, CIS, SOX, PCI etc) Strong experience with AWS EC2 & VMWare technologies and best practices on VMWare/EC2 for SQL Server. Strong experience in process automation, related 3rd party software, as well as in-house solutions. Maintain commitment to professionally grow and share knowledge within the team. Should possess wide sql work experience from SQL 2005 to SQL 2019. Should have worked on Multi-Node Clustered Environments. Strong experience on Core Industry Standards for SQL Server, Windows AWS and SAN (for ex: NIST, CIS, SOX, PCI etc) Strong experience with AWS EC2 & VMWare technologies and best practices on VMWare/EC2 for SQL Server. Strong experience in process automation, related 3rd party software, as well as in-house solutions. Maintain commitment to professionally grow and share knowledge within the team. Should possess wide sql work experience from SQL 2005 to SQL 2019. Should have worked on Multi-Node Clustered Environments. Strong experience with SAN best practices for SQL Server and Storage in AWS (for ex: FSX, EBS) Experience working with AMS & Microsoft Tech Support. Possess working or understanding knowledge of Gitlab and CI/CD Pipeline Education & Training Master's in computer science preferred. Bachelor's in computer science or equivalent. SQL Server certifications. AWS or Azure certification is a plus. SQL Server & AWS related professional training.","The SQL Server Database & AWS Cloud Engineer is a fully remote, full-time role suited for a highly experienced professional with over 12 years of hands-on SQL Server DBA expertise in managing large-scale, production-grade environments. The ideal candidate holds SQL Server certifications (MCSE or MCSA preferred) and brings extensive experience across multiple SQL Server versions (2005–2019). Core responsibilities include performance tuning, capacity planning, SQL Server automation, and deploying key components such as SSRS, SSIS, SQL Replication, and AlwaysOn technologies in clustered environments.","In addition, the role requires 4+ years of strong AWS cloud engineering experience, including proficiency with AWS RDS, EC2, FSX, EBS, CloudFormation, and CLI tools, as well as PowerShell scripting for automation and administration tasks. The engineer should have strong familiarity with industry compliance standards (e.g., NIST, SOX, PCI), SAN best practices, and be capable of working in multi-node clusters and VMware environments. Experience with CI/CD pipelines, GitLab, and coordination with AMS or Microsoft tech support is preferred. A Master’s or Bachelor’s degree in Computer Science, along with relevant SQL Server and cloud certifications, is highly desired to ensure technical excellence and continued professional growth.","{' AWS RDS': 'MISC', ' EC2': 'MISC', ' FSX': 'MISC', ' EBS': 'MISC', ' CloudFormation': 'MISC', ' PowerShell': 'MISC',  ' Microsoft': 'ORG', ' SQL Server': 'MISC'}"
246,Healthfirst,Data Analyst,"The Product Strategy Analyst is passionate and motivated by Healthfirst‚Äôs mission and wants to make a lasting impact in healthcare. This individual will create significant impact by providing the analytical support to the Integrated Products Strategy team to develop, assist in execution, and continuously improve upon a strategy that supports a profitable growth across the Integrated Products market portfolio including Medicaid Advantage Plus and Managed Long-Term Care

Job Description Duties/Responsibilities

Work collaboratively with finance analysis, sales, marketing, Intake & Enrollment, and other departments as necessary to support market growth plans to achieve market growth and profitability objectivesCompile information from multiple sources to prepare and distribute time-sensitive and accurate reporting for internal and external audiencesSupport team in analysis of the financial performance of e Integrated Products, identify favorable and unfavorable trends, develop recommendations to improve trends, communicate recommendations to management through a P&L focused mindsetDesign, create, modify, support and maintain monthly competitive reportsPrepare ad-hoc reporting as required by senior management and external partnersSupport team in creation of models to forecast growth performance and financial outcomesEffectively manage projects by setting clear project milestones and deliverables; clearly communicating goals, objectives and responsibilities. Participate in meetings to gather and specify departmental requirements for such projectsDevelop applications and reports using Microsoft Excel, Tableau and pertinent databases

Minimum Qualifications

Bachelor‚Äôs Degree from accredited institutionSAS, SQL and/or Tableau skills with ability to query, compile, and manipulate large datasetsAdvanced skills in Microsoft ExcelA tendency to take full ownership of a situation or deliverable. This means having pride in one‚Äôs work, being an expert in the area, and a willingness to do whatever it takes to get to a result.Understand and translate highly complex concepts to a wide range of audience. This means the ability to take a complex program or situation and break it down into simpler, constituent parts.Experience in analyzing membership growth and retention trends and identifying drivers Ability to efficiently validate data and analyses to identify potential errors in final resultsHighly analytical person who can demonstrates problem solving and critical thinking skills.Strong public speaking and oral and written communication skills with the ability to translate data to business insights (in other words, you are an analytic storyteller)Team player who contributes to creating a positive work environment and willing to pull their sleeves up to get things done with a bias towards action and prototyping towards a solution.Demonstrate intellectual curiosity and a desire to continue learning and growing. This means you want to go above and beyond to understand the business context.

Preferred Qualifications

Experience working in a health care delivery system or a health insurance companyKnowledge of Medicare and Medicaid programs, health care, and managed carePython skills with ability to create automated data pulls and manipulations

WE ARE AN EQUAL OPPORTUNITY EMPLOYER. Applicants and employees are considered for positions and are evaluated without regard to race, color, religion, gender, gender identity, sexual orientation, national origin, age, genetic information, military or veteran status, marital status, mental or physical disability or any other protected Federal, State/Province or Local status unrelated to the performance of the work involved.

If you have a disability under the Americans with Disability Act or a similar law and want a reasonable accommodation to assist with your job search or application for employment, please contact us by sending an email to careers@Healthfirst.org or calling 212-519-1798 . In your email please include a description of the accommodation you are requesting and a description of the position for which you are applying. Only reasonable accommodation requests related to applying for a position within Healthfirst Management Services will be reviewed at the e-mail address and phone number supplied. Thank you for considering a career with Healthfirst Management Services.

EEO Law Poster and Supplement

All hiring and recruitment at Healthfirst is transacted with a valid ‚Äú@healthfirst.org‚Äù email address only or from a recruitment firm representing our Company. Any recruitment firm representing Healthfirst will readily provide you with the name and contact information of the recruiting professional representing the opportunity you are inquiring about. If you receive a communication from a sender whose domain is not @healthfirst.org, or not one of our recruitment partners, please be aware that those communications are not coming from or authorized by Healthfirst. Healthfirst will never ask you for money during the recruitment or onboarding process.

Hiring Range*:

Greater New York City Area (NY, NJ, CT residents): $67,200 - $97,155All Other Locations (within approved locations): $59,800 - $88,910

As a candidate for this position, your salary and related elements of compensation will be contingent upon your work experience, education, licenses and certifications, and any other factors Healthfirst deems pertinent to the hiring decision.

In addition to your salary, Healthfirst offers employees a full range of benefits such as, medical, dental and vision coverage, incentive and recognition programs, life insurance, and 401k contributions (all benefits are subject to eligibility requirements). Healthfirst believes in providing a competitive compensation and benefits package wherever its employees work and live.

The hiring range is defined as the lowest and highest salaries that Healthfirst in ‚Äúgood faith‚Äù would pay to a new hire, or for a job promotion, or transfer into this role.","The Product Strategy Analyst at Healthfirst plays a critical role in supporting the Integrated Products Strategy team through deep data analysis, modeling, and reporting to drive profitable growth for Medicaid Advantage Plus and Managed Long-Term Care products. This position is highly collaborative, requiring coordination with finance, marketing, sales, and enrollment departments to support business goals. Key responsibilities include compiling and analyzing data, identifying trends in financial and membership performance, developing forecasts and competitive reports, and maintaining dashboards using tools such as Tableau and Excel. The analyst is also expected to handle ad hoc requests and play an active role in project management, contributing to data-driven decision-making and strategic development.","Candidates should have a bachelor’s degree and advanced skills in Excel, SQL, SAS, or Tableau, with experience handling large datasets. The role demands strong problem-solving abilities, analytical storytelling skills, and the capability to communicate complex data insights to diverse audiences. Preference will be given to those with healthcare industry experience, especially in Medicare or Medicaid, and those with Python proficiency. The position offers a salary range of $67,200–$97,155 for the NYC area, along with a competitive benefits package. Healthfirst emphasizes diversity, inclusion, and equal opportunity in its hiring practices.","{' Excel': 'MISC', ' SQL': 'MISC', ' SAS': 'MISC', ' Python': 'MISC'}"
247,Nityo Infotech,Data Analyst,"Job Title: Data Delivery Lead Location: Horsham, PAFTE Responsibilities:  ¬∑ Client Engagement Act as the primary point of contact for the client managing daily interactions and building strong trust based relationships ¬∑ Project Delivery Oversee the delivery of data services projects ensuring they meet quality standards deadlines and budget requirements ¬∑ Coordinate with both internal teams and the client to ensure smooth project execution. ¬∑ Technical Leadership Provide technical guidance in the data space using AWS cloud services to suggest innovative solutions and improvements to the client s data management and analytics capabilities Opportunity.¬∑ Development Proactively identify and pursue new business opportunities and engagements with the client following up diligently and driving the process to closure.¬∑ Communication Maintain impeccable standards of communication both spoken and written to clearly articulate complex technical concepts and value propositions to the client Collaboration ¬∑ Work closely with internal teams including technical guides and business development to align on client needs and market trends ensuring our offerings remain driven and responsive  Required Skills: ¬∑ Expertise in AWS Strong understanding of AWS cloud services Kinesis S3 Redshift DynamoDB Athena Aurora DB etc architectures and data management tools Collibra etc Data Technology ¬∑ Proficiency Solid background in data technologies including databases ETL tools data warehousing and analytics platforms Business Insight ¬∑ Ability to identify business opportunities and understand the client s industry and data needs ¬∑ Exceptional verbal and written communication skills with the ability to engage effectively at all levels of the client organization Project Management Confirmed experience in managing data projects with a track record of delivering on time and within budget","The Data Delivery Lead position based in Horsham, PA is a full-time opportunity requiring a strong blend of technical expertise, project management, and client engagement skills. This role involves acting as the primary point of contact for the client, managing daily communications, and building trusted relationships. The lead will oversee end-to-end project delivery, ensuring timely execution, budget compliance, and high-quality outcomes. They will also provide technical leadership, particularly in the AWS data space, suggesting enhancements to the client’s data infrastructure and analytics capabilities.","To succeed in this role, candidates must demonstrate expertise in AWS services such as Kinesis, S3, Redshift, DynamoDB, Athena, and Aurora DB, alongside a solid foundation in data technologies including ETL tools, data warehousing, and platforms like Collibra. Strong project management experience and the ability to communicate complex technical solutions clearly and persuasively to stakeholders at all levels are essential. In addition to delivery responsibilities, the lead will play a proactive role in identifying new business opportunities, collaborating closely with internal technical and business development teams to align services with client needs and industry trends.",{' AWS': 'MISC'}
248,IT America Inc,Data Engineer,"Role: Data Engineer ‚ÄìW2Location Richmond- 3 days onsite per week.  4+ years of Data Engineering with Python, Spark, PySpark 2) 3+ years of AWS (EMR, Lambda, S3 etc) 3) Automation testing
Onsite in Richmond, VA: Tuesday, Wednesday, Thursday Remote: Monday and Friday
   Nice To Have: + Snowflake + RDB + Big DataSecondary Skills - Nice to Havessnowflakebig dataJob Description- Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies - Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems - Utilize programming languages like Python, Spark, PySpark and Open Source RDBMS and Cloud based data warehousing services such as SnowflakeAdditional Skills & QualificationsThe Card Data and Analytics Team at Capital One is building data features for their depersonalization platform to onboard new external data providers. They want to be able to depersonalize data from their data partners that they can then consume.","The engineer will be responsible for designing, developing, testing, and supporting robust data solutions within an Agile team, particularly focused on enabling Capital One’s depersonalization platform for external data integration. Key responsibilities include building data pipelines, performing automation testing, and working with teams that specialize in machine learning and distributed systems.","his position calls for a candidate with at least four years of experience in data engineering, particularly with Python, Spark, and PySpark, and at least three years of hands-on experience using AWS services such as EMR, Lambda, and S3.","{' Python': 'MISC', ' Spark': 'MISC', ' PySpark': 'MISC'}"
249,EQ Consulting Inc,Data Analyst,"Role: Data Governance Analyst, LeadLocation: Marietta, GA (Hybrid) JOB ASSIGNMENT SUMMARY The Data Governance Analyst Lead is a pivotal role in our organization‚Äôs digital transformation. As a Data Governance Analyst Lead assists with the implementation of master data and data governance strategies across the enterprise. The Data Governance Analyst Lead works with IT leaders from across the company to ensure the quality, security, privacy, and value of our data assets. The Data Governance Analyst Lead is a subject matter expert in digital transformation.
KEY TASKS / RESPONSIBILITIES 30%: Assists team in work assignments, problem resolution, risk mitigation, and producing data value.25%: Proactively identifies and reports Data Quality issues to relevant stakeholders, ensuring timely and effective communication.20%: Assists with the design & development of a Data Governance roadmap and provides reports regarding the progress of sub-committee data teams.20%: Engages actively in discussions with stakeholders, leading the identification and documentation of data quality rules and master data hierarchies such as ‚ÄòCustomer‚Äô or ‚ÄòProduct‚Äô as Critical Data Elements (CDEs) for Master Data Management (MDM) platform use.5%: Ensures risks associated with business activities such as data privacy are effectively identified, measured, monitored, and controlled in accordance with risk and compliance.
EDUCATION / EXPERIENCE Certifications: NoneEducational Requirements: Bachelor‚Äôs Degree Required. Advanced degree in a relevant field (e.g., Data Management, Information Systems) is preferred.Years of Experience: 5-7 years of experience in Information or Data related practices to include: information/data governance, master data management, information management, information architecture, IT, risk, data privacy, data quality analysis, and reporting.
Knowledge / Skills / Abilities: ‚Ä¢ Strong technical and analytical acumen with proven experience in leveraging these skills to drive business outcomes with measurable benefits.‚Ä¢ Confidence to dive into data, understand it inside out and how it connects to our stakeholder‚Äôs businesses. ‚Ä¢ Experience with SQL, data profiling, or defining data quality rules and Master Data Management tools.‚Ä¢ Excellent written and oral communication skills with the confirmed ability to connect with all levels including management and local partners.‚Ä¢ Meaningful experience in MDM, metadata, and Data Governance with knowledge across multiple data domains.

Regards,Imran ShaikTalent Acquisition Specialist | EQ Consulting INC.Email: imran@eqconsultinginc.comPhone: (770) 470-4265","The Data Governance Analyst Lead plays a crucial role in driving digital transformation by supporting the implementation of master data and data governance strategies across the organization. Key responsibilities include leading team efforts, identifying and resolving data quality issues, creating data governance roadmaps, and collaborating with stakeholders to define data quality rules and master data hierarchies. The role also ensures adherence to risk and data privacy regulations, serving as a subject matter expert in critical data elements and MDM platform use.","Candidates must have a Bachelor’s degree (advanced degree preferred) and 5–7 years of experience in data-related fields such as governance, MDM, data quality, or IT risk management. Strong analytical skills, proficiency in SQL, and experience with data profiling and MDM tools are essential. Excellent communication skills and a demonstrated ability to collaborate across teams are also critical, along with a deep understanding of metadata and data domains.",{' SQL': 'MISC'}
250,The Lubrizol Corporation,Data Scientist,"The Lubrizol Corporation, a Berkshire Hathaway company, is a market-driven global company serving customers in more than 100 countries. We own and operate manufacturing facilities in 17 countries, as well as sales and technical offices around the world. Through our global sales and manufacturing networks, we are able to deliver the products and services our customers need, where and when they need them.

At Lubrizol, our mission is straightforward: We improve lives as an essential partner in our customers‚Äô success, delivering efficiency, reliability or wellness to their end users. Read the cover story in Smart Business Magazine to learn how Lubrizol plans to advance its growth.

Data Scientist / Statistician Intern (BA/BS Students)

Who are we?

Lubrizol is an innovative specialty chemical company, owned by Berkshire Hathaway, with technologies that improve the performance of our customers‚Äô products in the global transportation, industrial and consumer markets. At Lubrizol, our mission is straightforward: We improve lives as an essential partner in our customers‚Äô success, delivering efficiency, reliability or wellness to their end users. What does that mean in the real world? Fewer emissions for cleaner air. A smoother, safer drive. Great looking hair. Fibers that breathe and coatings that stay bright. Safer, more comfortable patient care. And that is just to name a few. We‚Äôre always looking for ways to make the best better.

The Data Science & Statistics Team

Operating like a start-up company, but with the backing of a large corporation, this empowered and agile team is charged with creating analytics systems that enable highly effective product development via virtual experimentation, optimization and knowledge discovery. In addition, the team provides data science consulting services to the Lubrizol technical community throughout the world.

We are actively recruiting Data Scientist/Statistician Summer Interns for 2024. Opportunities are available for students pursuing their Bachelor‚Äôs degrees in relevant areas of study.

Potential projects (depending on intern skills and current Lubrizol needs):

Create predictive models by mining complex data for critical formulating or testing insights Implement and assess algorithms in R, Python, SAS, JMP or C#/C++ Collaborate with data science team, as well as, scientists and engineers, to understand their needs, and find creative solutions to meet those needs 

Previous Intern Projects Include

Predictive modeling using Bayesian and machine learning methods R/Shiny tool development to enable model predictions and formulation optimization Creation of an interactive visualization tool for monitoring predictive models 

What tools do you need for success?

Enrolled in a Bachelor‚Äôs program such as statistics, data analytics, machine learningExcellent programming skills with the ability to learn new methods quicklySignificant course work in statistics or data analytics; experience using advanced statistical software such as R or PythonDemonstrated computer programming skills, such as formal course work in C/C++, Java, or PythonExposure to database systems and the ability to efficiently manipulate complex data Strong problem solving and deductive reasoning skillsCuriosity and creativity

Benefits Of Lubrizol‚Äôs Chemistry Internship Programs

Rewarding your hard work!Competitive payHoliday pay for holidays that fall within your work periodFUN! We host a variety of events and activities for our students. Past events include a Cleveland Cavaliers game, paid volunteering days, professional development and networking events, and even a picnic hosted by our CEO!
While headquartered in the United States, Lubrizol is truly a global specialty chemical company. We have a major presence in five global regions and do business in more than 100 countries. Our corporate culture ensures that Lubrizol is one company throughout the world, but you will find each region is a unique place to work, live and play.

Lubrizol is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, race, color, national origin, citizenship, age, religion, marital status, military service, sexual orientation, genetic information, gender identity, or any other characteristic or trait protected by federal, state, or local law.","Lubrizol is seeking highly motivated Data Scientist/Statistician Interns for Summer 2024 to support the Data Science & Statistics team in developing analytics systems and tools that drive innovation in product development. Interns will collaborate with scientists and engineers to create predictive models, implement algorithms, and provide data-driven solutions. Depending on intern skills and team needs, projects may include developing machine learning tools in R or Python, optimizing formulations, or creating interactive data visualizations.","Ideal candidates are enrolled in a Bachelor’s program in statistics, data analytics, or a related field, and have strong programming skills in R, Python, C/C++, or Java. Coursework in statistical modeling or machine learning is required, as well as exposure to database systems and data manipulation. Creativity, problem-solving, and curiosity are key traits for success. Lubrizol offers competitive pay, professional development opportunities, and a fun, supportive internship experience designed to reward talent and prepare students for impactful careers.","{' R': 'MISC', ' Python': 'MISC', ' C/C++': 'MISC', ' Java': 'MISC'}"
251,Charlie Health,Data Analyst,"Why Charlie Health?

Young people across the nation are grappling with a mental health crisis characterized by escalating rates of depression, anxiety, trauma, substance use disorders, and suicide. Individuals who seek support are met by geographical and financial barriers, driving increased urgency for a new approach to behavioral health treatment.

At Charlie Health, our mission is to connect the world to life-saving mental health treatment. Our treatment programs combine curated peer groups, individual therapy, and family therapy into personalized, evidence-based treatment plans to provide long-term healing from home. By prioritizing connections among young people with shared mental health experiences and goals, Charlie Health fosters sustainable healing and achieves industry-leading clinical outcomes, with over 90% of our clients seeing improvement in their most severe mental health symptoms.

Every member of the Charlie Health team is fueled by an unwavering passion for our mission. If you share this commitment, we invite you to join us in making a tangible impact on the mental health landscape.

About This Role

We are seeking a talented and experienced Data Analyst to join our team. The ideal candidate will have a strong analytical mindset, excellent communication skills, and the ability to translate complex data into actionable insights. The Data Analyst will be responsible for collecting, analyzing, and interpreting large datasets to identify trends, patterns, and opportunities that drive business decisions and strategy.

Responsibilities

Collect and clean data from various sources, ensuring its accuracy and completeness.Analyze large datasets using statistical methods and data visualization techniques.Identify trends, patterns, and correlations in data to provide valuable insights and recommendations.Develop and maintain dashboards, reports, and visualizations to communicate findings to stakeholders.Collaborate with cross-functional teams to understand business requirements and provide data-driven solutions.Perform ad-hoc analysis as required to support business needs.Stay updated on industry trends and best practices in data analytics.

Requirements

Proven experience as a Data Analyst or similar role.Proficiency in Tableau and SQL, and experience working with relational databases.Strong analytical skills with the ability to manipulate and interpret complex datasets.Experience with data visualization tools such as Tableau, Power BI, or matplotlib.Knowledge of statistical analysis techniques and tools such as R, Python, or SAS.Excellent communication and presentation skills, with the ability to convey technical concepts to non-technical stakeholders.Attention to detail and ability to work independently as well as part of a team.Experience in industries such as finance, healthcare, or e-commerce is a plus.

Benefits

Charlie Health is pleased to offer comprehensive benefits to all full-time, exempt employees. Read more about our benefits here.

Note: We are not currently considering applicants in CA, CO, NY, and WA for this position. 

Our Values

ConnectionCare deeplyWe care personally about every single person in the Charlie Health ecosystem: our clients, providers, and team members alike.Inspire hopeWe inspire hope with every interaction, reminding our clients that we truly and unconditionally believe in them.CongruenceStay curiousWe ask ‚Äúwhy‚Äù five times before we‚Äôre satisfied with the answer. We don‚Äôt stick to the status quo; we challenge our assumptions and remain humble.Heed the evidenceAbove all, we‚Äôre results-oriented. When we find data that calls our original plan into question, we modify or pivot.CommitmentAct with urgencyWe work as swiftly as possible. The mental health crisis is relentless, and so are we.Don‚Äôt give upOur clients don‚Äôt give up and neither do we. Persistence is our superpower.
Please do not call our public clinical admissions line in regard to this or any other job posting.

Please be cautious of potential recruitment fraud. If you are interested in exploring opportunities at Charlie Health, please go directly to our Careers Page: https://www.charliehealth.com/careers/current-openings. Charlie Health will never ask you to pay a fee or download software as part of the interview process with our company. In addition, Charlie Health will not ask for your personal banking information until you have signed an offer of employment and completed onboarding paperwork that is provided by our People Operations team. All communications with Charlie Health Talent and People Operations professionals will only be sent from @charliehealth.com email addresses. Legitimate emails will never originate from gmail.com, yahoo.com, or other commercial email services.

Recruiting agencies, please do not submit unsolicited referrals for this or any open role. We have a roster of agencies with whom we partner, and we will not pay any fee associated with unsolicited referrals.

At Charlie Health, we value being an Equal Opportunity Employer. We strive to cultivate an environment where individuals can be their authentic selves. Being an Equal Opportunity Employer means every member of our team feels as though they are supported and belong. We value diverse perspectives to help us provide essential mental health and substance use disorder treatments to all young people.

Charlie Health applicants are assessed solely on their qualifications for the role, without regard to disability or need for accommodation.","Charlie Health is seeking a Data Analyst to support its mission of transforming mental health care for young people. The analyst will collect, clean, and analyze large datasets to uncover trends and deliver actionable insights that inform business strategy. Responsibilities include building and maintaining dashboards and reports, collaborating with cross-functional teams to meet business needs, performing ad-hoc analyses, and staying current with best practices in analytics and visualization.","Ideal candidates will have experience in SQL and Tableau, with strong analytical and communication skills. Proficiency in statistical tools such as Python, R, or SAS, along with experience in data visualization and interpreting complex datasets, is essential. The role requires a detail-oriented, independent contributor who thrives in a fast-paced, mission-driven environment. Experience in healthcare, finance, or e-commerce is a plus. This is a remote position (excluding applicants from CA, CO, NY, and WA), offering comprehensive benefits and the opportunity to impact lives through data.","{' SQL': 'MISC', ' Tableau': 'MISC', ' Python': 'MISC', ' R': 'MISC', ' SAS': 'MISC'}"
252,The Lubrizol Corporation,Data Scientist,"The Lubrizol Corporation, a Berkshire Hathaway company, is a market-driven global company serving customers in more than 100 countries. We own and operate manufacturing facilities in 17 countries, as well as sales and technical offices around the world. Through our global sales and manufacturing networks, we are able to deliver the products and services our customers need, where and when they need them.

At Lubrizol, our mission is straightforward: We improve lives as an essential partner in our customers‚Äô success, delivering efficiency, reliability or wellness to their end users. Read the cover story in Smart Business Magazine to learn how Lubrizol plans to advance its growth.

Data Scientist / Statistician Intern (MS/PhD Students)

Who are we?

Lubrizol is an innovative specialty chemical company, owned by Berkshire Hathaway, with technologies that improve the performance of our customers‚Äô products in the global transportation, industrial and consumer markets. At Lubrizol, our mission is straightforward: We improve lives as an essential partner in our customers‚Äô success, delivering efficiency, reliability or wellness to their end users. What does that mean in the real world? Fewer emissions for cleaner air. A smoother, safer drive. Great looking hair. Fibers that breathe and coatings that stay bright. Safer, more comfortable patient care. And that is just to name a few. We‚Äôre always looking for ways to make the best better.

The Data Science & Statistics Team

Operating like a start-up company, but with the backing of a large corporation, this empowered and agile team is charged with creating analytics systems that enable highly effective product development via virtual experimentation, optimization and knowledge discovery. In addition, the team provides data science consulting services to the Lubrizol technical community throughout the world.

We are actively recruiting Data Scientist/Statistician Summer Interns for 2024. Opportunities are available for students pursuing their Masters or PhD degrees in relevant areas of study.

Potential projects (depending on intern skills and current Lubrizol needs):

Create predictive models by mining complex data for critical formulating or testing insights Implement and assess algorithms in R, Python, SAS, JMP or C#/C++ Research and implement new statistical, machine learning and/or optimization approaches (PhD level)Collaborate with data science team, as well as, scientists and engineers, to understand their needs, and find creative solutions to meet those needs 

Previous Intern Projects Include

Predictive modeling using Bayesian and machine learning methods R/Shiny tool development to enable model predictions and formulation optimization Creation of an interactive visualization tool for monitoring predictive models Multitask learning (transfer learning) using co-regionalized Gaussian Processes (PhD level)Multi-objective optimization using genetic algorithms (PhD level)Survival modeling using bagged Cox proportional hazards regression trees (PhD level)Bootstrap variance estimation for complex nonlinear models (PhD level)

What tools do you need for success?

Enrolled in a Masters or PhD program such as statistics, data analytics, machine learningExcellent programming skills with the ability to learn new methods quicklyExposure to database systems and the ability to efficiently manipulate complex data Interest and experience in advanced statistical modeling/machine learning methods (PhD level)Coursework in statistical modeling and data mining methodsCuriosity and creativity

Benefits Of Lubrizol‚Äôs Chemistry Internship Programs

Rewarding your hard work!Competitive payHoliday pay for holidays that fall within your work periodFUN! We host a variety of events and activities for our students. Past events include a Cleveland Cavaliers game, paid volunteering days, professional development and networking events, and even a picnic hosted by our CEO!
While headquartered in the United States, Lubrizol is truly a global specialty chemical company. We have a major presence in five global regions and do business in more than 100 countries. Our corporate culture ensures that Lubrizol is one company throughout the world, but you will find each region is a unique place to work, live and play.

Lubrizol is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to sex, race, color, national origin, citizenship, age, religion, marital status, military service, sexual orientation, genetic information, gender identity, or any other characteristic or trait protected by federal, state, or local law.","The Data Scientist / Statistician Intern at Lubrizol will join an agile and innovative Data Science & Statistics team that supports global product development through virtual experimentation, predictive modeling, and optimization. Interns will collaborate with scientists and engineers to develop creative, data-driven solutions that address real-world challenges. Responsibilities may include mining complex datasets for insights, implementing statistical or machine learning algorithms, creating visualization tools, and researching new methods in predictive modeling, optimization, or survival analysis, depending on individual skill sets and current project needs.","Ideal candidates are currently enrolled in a Master's or PhD program in statistics, data analytics, machine learning, or a related field. Successful interns will demonstrate strong programming skills (R, Python, SAS, JMP, C++), a solid understanding of statistical modeling and data mining, and the ability to manipulate complex datasets. Curiosity, creativity, and a passion for innovation are essential, particularly for those pursuing advanced modeling and algorithm development. This internship offers competitive pay, holiday pay, and access to professional development and networking events.","{'R': 'MISC', ' Python': 'MISC', ' SAS': 'MISC', ' JMP': 'MISC', ' C++': 'MISC'}"
254,PowerToFly,Data Analyst,"OverviewLooking for a self-motivated Junior Data analyst, who will be accountable for the PBNA Data identification, analysis and integration for the global IBP program. This role will adopt and adhere to our clients SAFe agile principles. Ability to provide PBNA IT and Functional knowledge to enable common global designs, data, reporting and analytics and own the mapping of PBNA Data for IBP integration. The role needs to analyze and define PBNA data sources in collaboration with the global groups. Ability to navigate and translate data areas in Legacy and PGT environments in addition to DDH and EDW.
ResponsibilitiesManage the Data object priorities in collaboration with the global groups and define and align on timelines and delivery schedules.Document the data usage and map them to GDO objects required for global IBP program.Drive PBNA IBP data requirements and identification of sources and alignment to global models for global IBP program. Drive the Global Data Object mappings.Define test scripts required to ensure data quality.Document data validation rules based on the data subject areas and sources, ensuring the data quality is maintained. Ensure source data from transactional systems ties in the target. Ensure data is certified using the PBNA data certification process.Ensure data rules and specifications are communicated to the development resources to ensure data is handled and used correctly.Ensure data context and one source of truth for PBNA by partnering with PBNA Functional Leadership (Supply Chain, GTM Operations, Commercial, S&T) and PBNA IT leadership.Ensure historical data is identified and ingested through Enterprise Data as per agreed timeline and requirements.
Compensation and BenefitsThe expected compensation range for this position is between $74,800 - $110,250 based on a full-time schedule.Location, confirmed job-related skills and experience will be considered in setting actual starting salary.Bonus based on performance and eligibility; target payout is 8% of annual salary paid out annually.Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.
Qualifications5+ years of IT experience3+ years of experience in data analytics and data integration expertiseGood data analytical skills.Ability to read data model diagrams and understand data relationships.Ability to navigate database platforms to analyze and map data.Preferably Safe Agile certified.Good understanding of cloud technologies in Azure, ADF, Synapse and DatabricksAbility to query multiple databases like Oracle, Sybase, Hana and Teradata","As a Junior Data Analyst for PBNA's global IBP program, your key responsibilities include identifying, analyzing, and integrating data across legacy and modern systems to support enterprise planning initiatives. You'll collaborate with global teams to define data sources, document usage, drive alignment with global data models, and ensure timely data delivery. A major focus will be on data validation, certification, and maintaining data quality by defining test scripts, validation rules, and source-target consistency. You will also help communicate data requirements to development teams and ensure data alignment with PBNA’s leadership and IT frameworks.","The ideal candidate should have at least 5 years of IT experience, with a minimum of 3 years in data analytics or data integration. Strong analytical skills and the ability to understand and map data models are essential. Proficiency in querying databases such as Oracle, Sybase, Hana, and Teradata, as well as familiarity with cloud tools like Azure, ADF, Synapse, and Databricks, is highly preferred. SAFE Agile certification and the ability to work in a collaborative, fast-paced environment are valuable assets for this role.",{' Oracle': 'ORG'}
255,Deloitte,Data Scientist,"GenAI Senior Developer - Senior Solution Specialist - USDC

Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with our US Delivery Center - we are breaking the mold of a typical Delivery Center.

Our US Delivery Centers have been growing since 2014 with significant, continued growth on the horizon. Interested? Read more about our opportunity below ...

Work you'll do

The Generative AI Engineer will, as part of several client delivery teams, be responsible for developing, designing, and maintaining cutting-edge AI-based systems, ensuring smooth and engaging user experiences. Additionally, the Generative AI Engineer will participate in a wide variety of Natural Language Processing activities, including refining and optimizing prompts to improve the outcome of Large Language Models (LLMs), and code and design review. The kinds of activities performed by the Prompt Engineer will also include, but not be limited to:

Working across client teams to develop and architect Generative AI solutions using ML and GenAIDeveloping and promoting standards across the communityEvaluating and selecting appropriate AI tools and machine learning models for tasks, as well as building and training working versions of those models using Python and other open-source technologiesWorking with leadership and stakeholders to identify AI opportunities and promote strategy.Developing and conducting trainings for users across the Government & Public Services landscape on principles used to develop models and how to interact with models to facilitate their business processes.Building and prioritizing backlog for future machine-learning enabled features to support client business processes.You'll design and build generative models, selecting the most suitable architecture (e.g., GANs, VAEs) based on the desired output (text, images, code). This involves writing code using Python libraries like TensorFlow or PyTorch.Once your model is built, you'll train it on the prepared data, fine-tuning hyperparameters to achieve optimal performance. You'll then evaluate the model's outputs to assess its effectiveness and identify areas for improvement.You'll collaborate with other engineers to integrate your generative AI solution into existing systems or develop new applications. This might involve deploying the model on cloud platforms for scalability.The field of generative AI is rapidly evolving. Staying abreast of the latest research, advancements, and ethical considerations in AI development is an ongoing process.

The TeamArtificial Intelligence & Data Engineering

In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.

The Artificial Intelligence & Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.

Artificial Intelligence & Data Engineering will work with our clients to:

Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platformsLeverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actionsDrive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements

Qualifications

Required:

6+ years of experience programming in Python or R.Knowledge of Python libraries like Pandas, Scikit-Learn, Numpy, NLTK is required5+ years of experience with Natural Language Processing (NLP) and Large Language Models (LLM) 5+ years of experience building and maintaining scalable API solutionsExperience working with RAG technologies and LLM frameworks (Langchain, Claude and LLamaIndex), LLM model registries (Hugging Face), LLM APIs, embedding models, and vector databases (FAISS , Milvus , OpenSearch, Pinecone etc.)Experience working with Retrieval Augmented Thoughts (RAT) and chain of thoughts.Experience building scalable data models and performing complex relational databases queries using SQL (Oracle, MySQL, PostGres), etc.Experience working with cloud computing platforms (e.g., AWS, Azure, Google Cloud) and containerization technologies (e.g., Docker, Kubernetes).Utilize tools such as Docker, Kubernetes, and Git to build and manage AI pipelinesExperience driving DevOps and MLOps practices, covering continuous integration, deployment, and monitoring of AIExperience with machine learning libraries and services like TensorFlow, PyTorch, or Amazon SageMaker.Experience integrating GenAI solution on cloud platform (e.g., AWS, Azure, Google Cloud) 5+ years of experience designing solutions to address client requirements3+ years of experience with the design and implementation (building, containerizing, and deploying end to end automated data and ML pipelines) of automated cloud solutions5+ years of experience in developing algorithms using data science technologies to build analytical models5+ years of data extraction/manipulation experience using scripts specific to AI/ML5+ years of modeling experience using a variety of regression and supervised and unsupervised learning techniques.5+ years of experience in data wrangling/cleansing, statistical modeling, and programming5+ years of extensive experience working in an Agile development environment5+ years of experience for fluency in both structured and unstructured data (SQL, NOSQL)5+ years of production experience with Apache Spark5+ years of hands-on experience with web APIs, CI/CD for ML, and Serverless Deployment3+ years of experience with presentation and data analysis software such as: SAS, R, SPSS, MATLAB, QlikView, Excel and Access1+ years of experience to have familiarity with Linux OS and Windows servers1+ years of experience to have knowledge of Docker, Jenkins, Kubernetes, and other DevOps toolsMust be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the futureMust live in a commutable distance (approximately 100-mile radius) to one of the following Delivery locations: Atlanta, GA; Charlotte, NC; Dallas, TX; Gilbert, AZ; Houston, TX; Lake Mary, FL; Mechanicsburg, PA; Philadelphia, PA; with the ability to commute to assigned location for the day, without the need for overnight accommodationsExpectation to co-locate in your designated Delivery location up to 30% of the time based on business needs. This may include a maximum of 10% overnight client/project travelBachelor's degree, preferably in Computer Sciences, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience

Preferred:

Previous Government Consulting and/or professional services experienceIn depth understanding of AI protocols and standardsUnderstanding of technology risks and the ability to assess and mitigate themDeep knowledge of a specific domain or industry, with a focus on applying NLP/LLM solutions in that contextExperience with debugging and troubleshooting software or solutions design issuesProven ability to stay current with best practices and new technology solutions in the fieldAbility to display both breadth and depth of knowledge regarding functional and technical issuesExperience presenting to clients or other decision makers to present and sell ideas to various audiences (technical and non-technical)Certification from any of the three major cloud platforms (AWS / Azure / GCP) in Cloud Architecture / Engineering / DevOps / ML.Familiarity with Kubeflow or MLflowExperience with machine learning pipelines (Azure ML)Familiarity with the latest Natural Language Processing or Computer Vision related algorithms

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html","The GenAI Senior Developer at Deloitte’s US Delivery Center will work within multidisciplinary teams to develop and integrate AI and NLP solutions using tools such as Python, PyTorch, TensorFlow, and cloud services (AWS, Azure, GCP). Key responsibilities include building and deploying scalable generative AI models and APIs, refining prompt engineering, and integrating large language models (LLMs) using frameworks like LangChain and vector databases (e.g., FAISS, Pinecone). The role involves collaborating with stakeholders, developing and maintaining AI pipelines using DevOps/MLOps best practices, and staying updated on emerging AI trends and ethical considerations.","Candidates must have at least 6 years of experience in software development with a strong foundation in Python or R and familiarity with libraries like Pandas, NumPy, and Scikit-learn. The role also requires deep expertise in NLP, LLMs, cloud computing platforms, containerization (Docker/Kubernetes), and data pipeline orchestration. Experience in developing machine learning models, working with structured/unstructured data, and implementing end-to-end ML solutions is essential. A bachelor's degree in a related field is required, and candidates must reside near and be able to commute to a designated Deloitte Delivery location. Preferred qualifications include cloud certifications, prior consulting experience, and familiarity with tools like MLflow, Kubeflow, and computer vision or NLP algorithms.","{' Python': 'MISC', ' R': 'MISC', ' Pandas': 'MISC', ' NumPy': 'MISC', ' Scikit-learn': 'MISC', ' Kubeflow': 'MISC'}"
256,Vestaf LLC,Data Engineer,"Role : Database Engineer (SQL/AWS/ETL)Location: Columbus, OH Work Mode : hybrid (3 days onsite 2 days WFH)
Job Description:
candidates with Database knowledge & ETL knowledge will get 100% preferenceMust have strong AWS experience ‚Äì Everything is being moved to public cloudWill be doing performance tuning, stored procedures, views, triggers, and indexes ‚Äì Candidate must be strong hereMust have very strong DBMS knowledge on SQL server ‚Äì Postgres (Oracle) ‚ÄìMust have good data modeling experience ‚Äì will be working with architecture team to perform data modelingShould have strong CICD and data warehouse conceptsShould have good ETL experience (Informatica or Abinitio is fine)Looking for 8-10+ years experience
MUST have- cloud - preferably - AWS- DBMS knowledge on SQL Server - postgres- Hands on experience with Stored Proc, views, triggers, indexes. performance tuning- hands - on experience with data modelling
Required qualifications, capabilities, and skills.‚Ä¢ 8 to 10 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus.‚Ä¢ Hands-on practical experience delivering database design, database administration, development, testing, and operational stability.‚Ä¢ Hands-on practical experience on Data Modelling.‚Ä¢ Hands on experience with Stored Proc, views, triggers, indexes. performance tuning.‚Ä¢ 5+ years of experience in Database technologies MS-SQL Server, Postgres, Aurora Postgres‚Ä¢ 2+ plus years of experience in AWS technologies especially Aurora and Amazon RDS‚Ä¢ Proficiency in automation and continuous delivery methods‚Ä¢ Proven understanding of agile methodologies such as CI/CD, Applicant Resiliency, and Security‚Ä¢ Proven experience in understanding requirement related to extraction, transformation, and loading (ETL)‚Ä¢ Formal training or certification on software engineering concepts and 3+ years applied experience.‚Ä¢ Ability to independently design, build, test, and deploy code. Should be able to lead by example and guide the team with his/her technical expertise.‚Ä¢ Ability to identify risks/issues for the project and manage them accordingly.‚Ä¢ Hands-on practical experience in system design, application development, testing, and operational stability‚Ä¢ Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages.‚Ä¢ Proficient in coding in one or more programming languages‚Ä¢ Experience across the whole Software Development Life Cycle‚Ä¢ Proven knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, etc.).‚Ä¢ Python and spark knowledge is plus.
Additional technologies like Liquibase and other automated deployment toolsPreferred qualifications, capabilities, and skills‚Ä¢ Knowledge about Database engineering and Data warehousing Concepts.‚Ä¢ Experience with Agile based project methodology.‚Ä¢ Ability to identify risks/issues for the project and manage them accordingly.‚Ä¢ Knowledge or experience on ETL technologies like Informatica or Ab-initio would be preferable.‚Ä¢ People management skills would be given preference but is not mandatory.
Job responsibilities‚Ä¢ Execute software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems.‚Ä¢ Write secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.‚Ä¢ Produce architecture and design artifacts for complex applications while being accountable for ensuring design constraints are met by software code development.‚Ä¢ Apply knowledge of tools within the Software Development Life Cycle toolchain to improve the value realized by automation.‚Ä¢ Apply technical troubleshooting to break down solutions and solve technical problems of basic complexity.‚Ä¢ Gather, analyze, synthesize, and develop visualizations and reporting from large, diverse data sets in service of continuous improvement of software applications and systems.‚Ä¢ Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.‚Ä¢ Contribute to software engineering communities of practice and events that explore new and emerging technologies.‚Ä¢ Add to team culture of diversity, equity, inclusion, and respect.
Skills:SQLAWSETLCICD","As a Database Engineer, you will be responsible for designing, developing, and maintaining scalable and efficient database solutions. Key duties include performance tuning, writing and optimizing stored procedures, views, triggers, and indexes, and conducting database modeling in collaboration with the architecture team. You will manage data pipelines, ensure stability across MS SQL Server and PostgreSQL environments, and lead the implementation of data warehousing and ETL processes using tools like Informatica or Ab Initio.

The role also involves working with cloud technologies, especially AWS (Aurora, RDS), and applying CI/CD methodologies to streamline deployments. You'll analyze and visualize large datasets, identify and resolve technical issues, ensure data integrity, and contribute to software design and architecture. Additionally, you’ll collaborate with cross-functional teams, guide junior engineers, and support agile development efforts while fostering a culture of continuous improvement, innovation, and inclusion.","The ideal candidate for the Database Engineer role will have 8–10 years of strong hands-on experience with SQL, particularly in SQL Server and PostgreSQL, with additional experience in other RDBMS considered a plus. Expertise in database design, administration, development, and performance tuning is essential, along with a deep understanding of data modeling and writing stored procedures, views, triggers, and indexes. A minimum of 5 years of experience in MS SQL Server and Postgres (including Aurora Postgres), and at least 2 years of hands-on experience with AWS technologies, especially RDS and Aurora, is required. Proficiency in ETL (preferably with Informatica or Ab Initio), data warehousing concepts, automation, and CI/CD pipelines is crucial. The candidate should have a good grasp of Agile methodologies, along with practical experience in the full software development life cycle.","{' SQL': 'MISC', ' SQL Server': 'MISC', ' PostgreSQL': 'MISC', ' MS SQL Server': 'MISC', ' Postgres': 'MISC', ' Aurora Postgres': 'MISC', ' RDS': 'MISC', ' Agile': 'MISC'}"
258,"HealthCare Partners, New York",Data Analyst,"HealthCare Partners, IPA and HealthCare Partners, MSO together comprise our health care delivery system providing enhanced quality care to our members, providers and health plan partners. Active since 1996, HealthCare Partners (HCP) is the largest physician-owned and led IPA in the Northeast, serving the five boroughs and Long Island. Our network includes more than 10,000 primary care and specialist physicians delivering services to over 200,000 members enrolled in Commercial, Medicare and Medicaid products. Our Management Services Organization employs over 200 skilled staff professionals dedicated to ensuring practices deliver the highest quality of care to their patients while efficiently utilizing healthcare resources.
HCP‚Äôs vision is to be recognized by members, providers and payers as the organization that delivers unsurpassed excellence in healthcare to the people of New York and their communities. We pride ourselves on selecting the most qualified candidates who reflect HCP‚Äôs mission of serving our members by facilitating the delivery of quality care.
Interested in joining our successful Garden City Team? We are currently seeking a Data Analyst, Business Intelligence.
Position Summary: The Business Intelligence Data Analyst plays a pivotal role in driving data-driven decision-making processes within the organization. As an intermediate-level data analyst, this position requires a skillset with a strong proficiency in SQL, Python, VBA, SSRS reports, and Power BI. The successful candidate will possess excellent problem-solving skills, the ability to debug and troubleshoot, strong process documentation skills, and a deep understanding of data structures & algorithms.
Essential Position Functions/Responsibilities:Develop and maintain SQL queries to extract, transform, and load data from various sources, ensuring data accuracy and integrity.Utilize advanced SQL techniques to manipulate and transform large datasets efficiently.Design, develop, and deploy SSRS reports for business stakeholders, providing actionable insights and visual representations of data trends.Create and maintain interactive and visually appealing dashboards using Power BI, enabling stakeholders to explore and analyze data effectively.Collaborate with cross-functional teams to gather requirements and provide insights from data analysis, driving strategic decision-making processes.Identify trends, patterns, and opportunities for improvement through advanced data analysis techniques, such as statistical analysis and predictive modeling.Perform ad-hoc analysis to address specific business questions or challenges, generating actionable insights to support decision-making processes.Communicate findings and recommendations to stakeholders clearly and concisely, tailoring communication to both technical and non-technical audiences.Work collaboratively with team members and stakeholders to understand business needs, gather requirements, and ensure alignment between data analysis and business objectives.Other duties and special projects as assigned. 
Qualification Requirements:Skills, Knowledge, AbilitiesStrong data interpretation and critical thinking skills, with the ability to translate complex data into actionable insights.Solid understanding of statistical analysis techniques and their application in data analysis.Experience in developing and deploying SSRS reports, with a focus on creating informative and visually appealing reports.Strong knowledge of Power BI for creating interactive dashboards and visualizations, enhancing data-driven decision-making processes.Excellent communication skills, with the ability to articulate complex ideas to both technical and non-technical stakeholders.Ability to work independently as well as collaboratively in a team environment, demonstrating strong problem-solving skills and attention to detail.
Training/Education:Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field, required.Master‚Äôs degree, preferred.
Experience:Minimum of two years of experience in a similar role, demonstrating proficiency in SQL, Python, VBA, SSRS reports, and Power BI.3-5 years in business analytics or related field, demonstrating progressive experience in data analysis, reporting, and visualization.
Base Comp Range: $90,000 - $110,000 annualBonus - Up to 5% of base salary based on organizational performance
HealthCare Partners, MSO provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, HealthCare Partners, MSO complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation, and training.
The above position information is intended to describe the general nature and level of work being performed by the job incumbent(s) and is not to be considered an all-encompassing description of all responsibilities, duties, and skills required.","The Data Analyst, Business Intelligence at HealthCare Partners plays a vital role in leveraging data to support strategic decision-making across the organization. Responsibilities include developing SQL queries to ensure accurate data extraction and transformation, creating and maintaining SSRS reports, and designing interactive dashboards in Power BI. The analyst collaborates with cross-functional teams to gather business requirements, performs ad hoc analyses, and communicates findings in a clear and concise manner to both technical and non-technical stakeholders. This role also involves identifying trends and patterns in data, utilizing statistical techniques and predictive modeling, and supporting the organization’s mission through data-driven insights and visualizations.","Qualified candidates should hold a Bachelor’s degree in Computer Science, Statistics, Mathematics, or a related field (Master’s preferred), with at least 2 years of relevant experience and a total of 3–5 years in business analytics. Key skills include proficiency in SQL, Python, VBA, SSRS, and Power BI; strong data interpretation, statistical analysis, and visualization capabilities; and the ability to communicate effectively across diverse teams. The ideal candidate is detail-oriented, collaborative, and capable of working independently in a fast-paced environment.","{' SQL': 'MISC', ' Python': 'MISC', ' VBA': 'MISC', ' SSRS': 'MISC', ' Power BI': 'MISC'}"